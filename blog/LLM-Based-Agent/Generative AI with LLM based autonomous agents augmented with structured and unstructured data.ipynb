{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# Generative AI with LLM based autonomous agents augmented with structured and unstructured data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "We will use Neural Search plugin in OpenSearch to implement semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703e3d",
   "metadata": {},
   "source": [
    "### Check PyTorch Version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b532987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fa4b0",
   "metadata": {},
   "source": [
    "###  Install OpenSearch ML Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opensearch-py\n",
    "%pip install langchain\n",
    "%pip install boto3\n",
    "%pip install sqlalchemy>\n",
    "%pip install sqlalchemy-redshift\n",
    "%pip install redshift_connector\n",
    "%pip install ipython-sql==0.4.1\n",
    "%pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {},
   "source": [
    "### Import library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker,json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6607721",
   "metadata": {},
   "source": [
    "## Part 1. Prepare unstructured data in OpenSearch\n",
    "\n",
    "### Prepare SEC Edgar Annual Financial Filings data\n",
    "\n",
    "You can download the dataset from Kaggle. Then upload the downloaded \"archive.zip\" to same folder as this notebook.\n",
    "\n",
    "https://www.kaggle.com/datasets/pranjalverma08/sec-edgar-annual-financial-filings-2021/\n",
    "\n",
    "We have download the dataset and put it into public accessible S3 bucket. You can run the following cell to download the dataset from S3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ws-assets-prod-iad-r-sfo-f61fc67057535f1b.s3.us-west-1.amazonaws.com/df655552-1e61-4a6b-9dc4-c03eb94c6f75/10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd02f6",
   "metadata": {},
   "source": [
    "Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d57e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip 10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d792c7",
   "metadata": {},
   "source": [
    "Read the dataset in JSON format and contruct pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1cf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the folder containing the JSON files\n",
    "folder_path = \"extracted\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "#For this blog post, we only ingest few company informaiton to too too long in data ingestion.\n",
    "company_list=[\"Alteryx, Inc.\", \"MICROSTRATEGY Inc\", \n",
    "              \"Elastic N.V.\", \"MongoDB, Inc.\", \n",
    "              \"Palo Alto Networks Inc\", \"Okta, Inc.\",\n",
    "              \"Datadog, Inc.\", \"Snowflake Inc.\",\n",
    "              \"SALESFORCE.COM, INC.\", \"ORACLE CORP\",\n",
    "              \"MICROSOFT CORP\", \"Palantir Technologies Inc.\"\n",
    "             ]\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.DataFrame([pd.read_json(file_path,typ='series')])\n",
    "        if df.iloc[0]['company'] in company_list:\n",
    "            dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff237f",
   "metadata": {},
   "source": [
    "To display whole DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1298ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a349",
   "metadata": {},
   "source": [
    "### Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with OpenSearch Cluster.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below.\n",
    "\n",
    "#### Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "region = aws_region\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "kms = boto3.client('secretsmanager')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"llm-based-agent\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "aos_credentials = json.loads(kms.get_secret_value(SecretId=outputs['OpenSearchSecret'])['SecretString'])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405e0e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "\n",
    "auth = (aos_credentials['username'], aos_credentials['password'])\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54595346",
   "metadata": {},
   "source": [
    "### Create a index in Amazon Opensearch Service \n",
    "Whereas we previously created an index with 2 fields, this time we'll define the index with 3 fields: the first field ' question_vector' holds the vector representation of the question, the second is the \"question\" for raw sentence and the third field is \"answer\" for the raw answer data.\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the aos_client connection we initiated ealier to create the index in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"item_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,\n",
    "                \"store\": True,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                      \"ef_construction\": 128,\n",
    "                      \"m\": 24\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"item_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f677e0c6",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"10k_financial\"\n",
    "aos_client.indices.create(index=index_name,body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766dd801",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7dfbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfaa9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=f\"https://bedrock-runtime.{aws_region}.amazonaws.com\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v1',client=boto3_bedrock)\n",
    "result = bedrock_embeddings.embed_query(\"This is a content of the document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ba9d6",
   "metadata": {},
   "source": [
    "###  Load the raw data into the Index\n",
    "Next, let's load the financial billing data into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import pandas\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "class PandasDataFrameLoader(BaseLoader):\n",
    "    \n",
    "    def __init__(self,dataframe:pandas.DataFrame):\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        items=[\"item_1\",\"item_1A\",\"item_1B\",\"item_2\",\"item_3\",\"item_4\",\"item_5\",\"item_6\",\"item_7\",\"item_7A\",\"item_8\",\"item_9\",\"item_9A\", \"item_9B\", \"item_10\", \"item_11\", \"item_12\", \"item_13\", \"item_14\", \"item_15\"]\n",
    "        \n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            metadata={}\n",
    "            metadata[\"cik\"]=row['cik']\n",
    "            metadata[\"company_name\"]=row['company']\n",
    "            metadata[\"filing_date\"]=row['filing_date']\n",
    "            for item in items:\n",
    "                content=row[item]\n",
    "                metadata['item'] = item\n",
    "                doc = Document(page_content=content,metadata=metadata)\n",
    "                #print(doc.metadata)\n",
    "                docs.append(doc)\n",
    "        return docs\n",
    "    \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "pd_loader = PandasDataFrameLoader(combined_df)\n",
    "documents = pd_loader.load()\n",
    "#splitted_documnets = pd_loader.load_and_split(text_splitter=text_splitter)\n",
    "splitted_documnets = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb967264",
   "metadata": {},
   "source": [
    "Use Bedrock embedding convert item content into vector and use OpenSearch bulk ingest to store data into OpenSearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6f330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from opensearchpy import helpers\n",
    "\n",
    "previous_company_name=\"\"\n",
    "item_contents=[]\n",
    "for doc in splitted_documnets:\n",
    "    company_name=doc.metadata['company_name']\n",
    "    if previous_company_name != \"\" and previous_company_name != company_name:\n",
    "        print(\"company:\" + company_name + \", item count:\" + str(len(item_contents)))\n",
    "        start = time.time()\n",
    "        embedding_results = bedrock_embeddings.embed_documents(item_contents)\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        print(f\"total time elapsed for Bedrock embedding: {elapsed:.2f} seconds\")\n",
    "        #TODO\n",
    "        data = []\n",
    "        i=0\n",
    "        for content in item_contents:\n",
    "            data.append({\"_index\": index_name,  \"company_name\": previous_company_name, \"item_content\":content, \"item_vector\":embedding_results[i]})\n",
    "            i = i+1\n",
    "        aos_response= helpers.bulk(aos_client, data)\n",
    "        print(f\"Bulk-inserted {aos_response[0]} items.\")\n",
    "        item_contents=[]\n",
    "    \n",
    "    item_contents.append(doc.page_content)\n",
    "    previous_company_name=company_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb13217",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aos_client.indices.delete(index=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c010",
   "metadata": {},
   "source": [
    "## Part 2 - Prepare structured data  in Redshift Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3c50d",
   "metadata": {},
   "source": [
    "Get Redshift Serverless username, password and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_serverless_credentials = json.loads(kms.get_secret_value(SecretId=outputs['RedshiftServerlessSecret'])['SecretString'])\n",
    "redshift_serverless_username=redshift_serverless_credentials['username']\n",
    "redshift_serverless_password=redshift_serverless_credentials['password']\n",
    "redshift_serverless_endpoint =  outputs['RedshiftServerlessEndpoint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c619",
   "metadata": {},
   "source": [
    "connect to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import Session\n",
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ee955",
   "metadata": {},
   "source": [
    "\n",
    "### Populate the Redshift table \n",
    "\n",
    "### Stock symbol table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d123032",
   "metadata": {},
   "source": [
    "create `stock_symbol` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f94e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_symbol (stock_symbol text PRIMARY KEY, company_name text NOT NULL);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9516e",
   "metadata": {},
   "source": [
    "insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1822ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_bucket = outputs[\"s3BucketStock\"]\n",
    "s3_location = f's3://{stock_price_bucket}/stock-price/'\n",
    "print(s3_location)\n",
    "!aws s3 sync ./stock-price/ $s3_location\n",
    "\n",
    "stock_symbol_s3_location = f's3://{stock_price_bucket}/stock-price/stock_symbol.csv'\n",
    "print(stock_symbol_s3_location)\n",
    "quoted_stock_symbol_s3_location = \"'\" + stock_symbol_s3_location + \"'\"\n",
    "print(quoted_stock_symbol_s3_location)\n",
    "print(\"---------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql COPY STOCK_SYMBOL FROM $quoted_stock_symbol_s3_location iam_role default IGNOREHEADER 1 CSV;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de54a9",
   "metadata": {},
   "source": [
    "query `stock_symbol` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9047d6e",
   "metadata": {},
   "source": [
    "### Stock price table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ab163",
   "metadata": {},
   "source": [
    "Create stock price table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540061a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_price (stock_date DATE, stock_symbol text, open_price DECIMAL, high_price DECIMAL, low_price DECIMAL, close_price DECIMAL, adjusted_close_price DECIMAL, volume DECIMAL);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_s3_location = f's3://{stock_price_bucket}/stock-price/MSFT.csv'\n",
    "print(msft_s3_location)\n",
    "quoted_msft_s3_location = \"'\" + msft_s3_location + \"'\"\n",
    "print(quoted_msft_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "crm_s3_location = f's3://{stock_price_bucket}/stock-price/CRM.csv'\n",
    "print(crm_s3_location)\n",
    "quoted_crm_s3_location = \"'\" + crm_s3_location + \"'\"\n",
    "print(quoted_crm_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "orcl_s3_location = f's3://{stock_price_bucket}/stock-price/ORCL.csv'\n",
    "print(orcl_s3_location)\n",
    "quoted_orcl_s3_location = \"'\" + orcl_s3_location + \"'\"\n",
    "print(quoted_orcl_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "snow_s3_location = f's3://{stock_price_bucket}/stock-price/SNOW.csv'\n",
    "print(snow_s3_location)\n",
    "quoted_snow_s3_location = \"'\" + snow_s3_location + \"'\"\n",
    "print(quoted_snow_s3_location)\n",
    "print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65325e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql COPY STOCK_PRICE FROM $quoted_msft_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_crm_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_orcl_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_snow_s3_location iam_role default IGNOREHEADER 1 CSV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf73f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84be705",
   "metadata": {},
   "source": [
    "## Part 3 - Query unstructured data in OpenSearch with vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70403851",
   "metadata": {},
   "source": [
    "Define semantic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, k=10):\n",
    "    print(\"semantic search input: \" + query)\n",
    "    search_vector = bedrock_embeddings.embed_query(query)\n",
    "    query={\n",
    "        \"size\": 10,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    #print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        row=[hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"item_content\"])\n",
    "    return query_result_df\n",
    "\n",
    "def semantic_search_full_field(query, k=5):\n",
    "    search_vector = bedrock_embeddings.embed_query(query)\n",
    "    query={\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    #print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        row=[hit['_id'],hit['_score'],hit['fields']['company_name'][0],hit['fields']['item_category'][0],hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_category\",\"item_content\"])\n",
    "    return query_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f811868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_statements(query):\n",
    "    company_statements = semantic_search(query)\n",
    "    return company_statements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583598e",
   "metadata": {},
   "source": [
    "## Part 4 - Query structred data  in Redshift with `SQLDatabaseChain`\n",
    "A common use of an agent is to look up a record in a database. It would not be practical to include the full database in the context, so you can provide tools that perform actions against the datebase that eliminates hallucinations while maintining the conversational interactions.\n",
    "\n",
    "### SQL Database Chain\n",
    "Langchain has a SQL Database chain to ask questions of a DB to get answers. For details, read this document: https://python.langchain.com/docs/use_cases/qa_structured/sql#case-2-text-to-sql-query-and-execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f8d0e",
   "metadata": {},
   "source": [
    "Initialize Bedrock LLM model with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d17670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from typing import Optional, List, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "#bedrock_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock)\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock)\n",
    "\n",
    "bedrock_llm.model_kwargs = {\"max_tokens_to_sample\":1204,\"temperature\":0.01,\"top_k\":250,\"top_p\":1,\"stop_sequences\":[\"\\\\n\\\\nHuman:\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2f5fa",
   "metadata": {},
   "source": [
    "### Get stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b195f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "url = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(url,include_tables=['stock_symbol'])\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"Human: Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "If the results of the query is empty, answer \\\"I don't know\\\"\n",
    "<format>\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Answer with SQLResult. If SQLResult is empty, asnwer I don't know\"\n",
    "</format>\n",
    "Assistant: Understood, I will use the above format and only provide the answer.\n",
    "\n",
    "Only use the following tables:\n",
    "<tables>\n",
    "CREATE TABLE stock_symbol (\n",
    "\tstock_symbol text PRIMARY KEY,\n",
    "\tcompany_name text NOT NULL\n",
    ")\n",
    "</tables>\n",
    "\n",
    "If someone asks for the table stock symbol table, they really mean the stock_symbol table.\n",
    "<examples>\n",
    "Question: What is the ticker symbol for Amazon in stock symbol table?\n",
    "SQLQuery: SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%Amazon%'\n",
    "SQLResult: AMZN\n",
    "Answer: AMZN\n",
    "\n",
    "Question: What is the ticker symbol for Microsoft in stock ticker table?\n",
    "SQLQuery: SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%Microsoft%'\n",
    "SQLResult: empty\n",
    "Answer: I don't know\n",
    "\n",
    "</examples>\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "\n",
    "llm=bedrock_llm\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm, \n",
    "    db, \n",
    "    verbose=True, \n",
    "    return_intermediate_steps=True, \n",
    "    prompt=PROMPT, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383a78f",
   "metadata": {},
   "source": [
    "Get \"Amazon\" stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for Amazon in stock symbol table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837c85d",
   "metadata": {},
   "source": [
    "Get \"Microsoft\" stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26450db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for MICROSOFT in stock ticker table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6814a",
   "metadata": {},
   "source": [
    "Try to get a non exist company stock symbol, it will return \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for Pan Test in stock ticker table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8e2b9",
   "metadata": {},
   "source": [
    "### Get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4902d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_template = \"\"\"Human: Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "If the results of the query is empty, answer \\\"I don't know\\\"\n",
    "<format>\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Answer with SQLResult. If SQLResult is empty, asnwer I don't know\"\n",
    "</format>\n",
    "Assistant: Understood, I will use the above format and only provide the answer.\n",
    "\n",
    "Only use the following tables:\n",
    "<tables>\n",
    "CREATE TABLE public.stock_price (\n",
    "stock_date DATE, \n",
    "stock_symbol text, \n",
    "open_price DECIMAL, \n",
    "high_price DECIMAL, \n",
    "low_price DECIMAL, \n",
    "close_price DECIMAL, \n",
    "adjusted_close_price DECIMAL, \n",
    "volume DECIMAL);\n",
    "</tables>\n",
    "\n",
    "answer the following question and organize the return data into json format.\n",
    "1. what is the company average open price in the month of July? \n",
    "2. what is the company average close price in the month of July?\n",
    "3. what is the company average high price in the month of July?\n",
    "4. what is the company average low price in the month of July?\n",
    "5. what is the company average adjusted close price in the month of July?\n",
    "6. what is the company average volume in the month of July?\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "stock_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"dialect\"], template=stock_price_template\n",
    ")\n",
    "\n",
    "llm=bedrock_llm\n",
    "\n",
    "stock_price_db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm, \n",
    "    db, \n",
    "    verbose=True, \n",
    "    return_intermediate_steps=True, \n",
    "    prompt=stock_prompt, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a24e7",
   "metadata": {},
   "source": [
    "Get MSFT stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_info = stock_price_db_chain(\"\\n\\nHuman: What is the MSFT stock information? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3366294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_price_info['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba6cc",
   "metadata": {},
   "source": [
    "Define functions:\n",
    "1. if query is stock related, \n",
    "2. get stock ticker from the query\n",
    "3. get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef542cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def is_stock_related_query(query):\n",
    "    template = \"\"\"You are a helpful assistant to judge if the human input is stock related question.\n",
    "    If it is stock related, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":query})['text'].strip()\n",
    "    return stock_related, query\n",
    "    \n",
    "def get_stock_ticker(query):\n",
    "    template = \"\"\"You are a helpful assistant who extract company name from the human input.Please only output the company\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "\n",
    "    company_name=llm_chain(query)['text'].strip()\n",
    "    company_ticker = db_chain(\"\\n\\nHuman: What is the ticker symbol for \" + str(company_name) + \" in stock ticker table? \\n\\nAssistant:\")\n",
    "    return company_name, company_ticker['result']\n",
    "\n",
    "def get_stock_price(ticker):\n",
    "    #get stock price with text to sql in db_chain\n",
    "    data = stock_price_db_chain(\"\\n\\nHuman: What is the \" + str(ticker) + \" stock information ? \\n\\nAssistant:\")\n",
    "    return data['result']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf641d",
   "metadata": {},
   "source": [
    "## Part 5 - Create LLM Based ReAct Agent Augmented with Data in OpenSearch and Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aa700",
   "metadata": {},
   "source": [
    "Define agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentType\n",
    "\n",
    "tools=[\n",
    "    Tool(\n",
    "        name=\"is stock related query\",\n",
    "        func=is_stock_related_query,\n",
    "        description=\"If the query is stock related\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get company ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Get the company stock ticker\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get stock data\",\n",
    "        func=get_stock_price,\n",
    "        description=\"Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the the stock ticker to it \"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get financial statements\",\n",
    "        func=get_financial_statements,\n",
    "        description=\"Use this to get financial statement of the company. With the help of this data companys historic performance can be evaluaated. You should input stock ticker to it\"\n",
    "    ) \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05846e63",
   "metadata": {},
   "source": [
    "define agent prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b17bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_prompt=\"\"\"Human: You are a financial advisor. Give stock recommendations for given query based on following instructions. \n",
    "<instructions>\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "is stock related query: Use when you need to know whether this is stock related query. This tool will output whether human input is stock related and human input. You should input the human input to it.\n",
    "get company ticker: Use when you need to extract company name and stock ticker. This tool will output company name and stock ticker.\n",
    "get stock data: Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the stock ticker to it.\n",
    "get financial statements: Use this to get financial statement of the company. With the help of this data, companys historic performance can be evaluated. You should input the human input to it.\n",
    "</instructions>\n",
    "\n",
    "<steps>\n",
    "Note- if you fail in satisfying any of the step below, Just move to next one\n",
    "1) Use \"is stock related query\" tool to judge if the input query is stock related or not. Output - stock related and input query\n",
    "2) Use \"get company ticker\" tool to get the company name and stock ticker. Output- company name and stock ticker\n",
    "3) Use \"get stock data\" tool to gather stock info. Output- Stock data\n",
    "4) Use \"get financial statements\" tool to get company's historic financial statement. Output- Financial statement\n",
    "5) Analyze the stock based on gathered data and give detail analysis for investment choice. provide numbers and reasons to justify your answer. \n",
    "If there is no output from \"get stock data\" tool, please ouput \"I can not provide stock analyis without stock price information.\".\n",
    "Output- Detailed stock Analysis\n",
    "</steps>\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [is stock related query, get company ticker, get stock data, get financial statements]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a94144",
   "metadata": {},
   "source": [
    "Initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent \n",
    "\n",
    "zero_shot_agent=initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iteration=2,\n",
    "    return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "zero_shot_agent.agent.llm_chain.prompt.template=updated_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426e344",
   "metadata": {},
   "source": [
    "## Part 6 - Use LLM based agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f63ba",
   "metadata": {},
   "source": [
    "### Example 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d8394",
   "metadata": {},
   "source": [
    "Ask the queustion \"Is Microsoft a good investment choice right now?\". The agent will run the following process:\n",
    "\n",
    "1. This is stock relatated question\n",
    "2. get company name\n",
    "3. get stock symbol\n",
    "4. get stock price\n",
    "5. use semantic search get related information from 10k financial filing data\n",
    "\n",
    "Combine all the above information and generate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "response = zero_shot_agent(\"\\n\\nHuman: Is Microsoft a good investment choice right now? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15388c",
   "metadata": {},
   "source": [
    "### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b211d3",
   "metadata": {},
   "source": [
    "\"Is Amazon a good investment choice right now?\". This is stock relation quesiton. However there is no Amazon stock price informaiton in Redshift table. So it will answer \"I can not provide stock analyis without stock price information.\" in the end. The agent will run the following process:\n",
    "\n",
    "1. This is stock relatated question\n",
    "2. get company name\n",
    "3. get stock symbol\n",
    "4. get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f165b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = zero_shot_agent(\"\\n\\nHuman: Is Amazon a good investment choice right now? \\n\\nAssistant:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e8ee",
   "metadata": {},
   "source": [
    "### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cbc80",
   "metadata": {},
   "source": [
    "This is not stock related query. The agent will run the following process:\n",
    "\n",
    "1. This is stock relatated question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = zero_shot_agent(\"\\n\\nHuman: What is SageMaker? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca2b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
