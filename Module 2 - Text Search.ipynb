{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a260e21",
   "metadata": {},
   "source": [
    "# Module 2: Text Search with Amazon OpenSearch Service \n",
    "\n",
    "In this module, we are going to perform a simple search in OpenSearch by matching the individual words in our search query. We will:\n",
    "1. Load data into OpenSearch from the Amazon Product Question and Answer (PQA) dataset. This dataset contains a list of common questions and answers related to products.\n",
    "2. Query the data using a simple query search for find potentially matching questions. We will search the PQA dataset for questions similar to our sample question \"does this work with xbox?\". We expect to find matches in the dataset based on the individual words such as \"xbox\" and \"work\".\n",
    "\n",
    "In subsequent modules, we will then demonstrate how to use semantic search to improve the relvance of the query results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df71ad6",
   "metadata": {},
   "source": [
    "### 1. Install required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1582d18",
   "metadata": {},
   "source": [
    "Before we begin, we need to install some required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf023c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q requests\n",
    "!pip install -q requests-aws4auth\n",
    "!pip install -q opensearch-py\n",
    "!pip install -q tqdm\n",
    "!pip install -q boto3\n",
    "!pip install -q install transformers[torch]\n",
    "!pip install -q transformers\n",
    "!pip install -q sentence-transformers rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467dd76e",
   "metadata": {},
   "source": [
    "### 2. Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3ac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"semantic-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "bucket = outputs['s3BucketTraining']\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192599d8",
   "metadata": {},
   "source": [
    "### 3. Copy the data set locally\n",
    "Before we can run any queries, we need to download the Amazon Product Question and Answer data from : https://registry.opendata.aws/amazon-pqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd10e11",
   "metadata": {},
   "source": [
    "Let's start by having a look at all the files in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a00371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls --no-sign-request s3://amazon-pqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f90419",
   "metadata": {},
   "source": [
    "There are a lot of files here, so for the purposes of this demo, we focus on just the headset data. Let's download the amazon_pqa_headsets.json data locally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74b8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request s3://amazon-pqa/amazon_pqa_headsets.json ./amazon-pqa/amazon_pqa_headsets.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157a87c",
   "metadata": {},
   "source": [
    "### 4. Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with Amazon Opensearch Service domain.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2bbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "\n",
    "#update the region if you're working other than us-east-1\n",
    "region = 'us-east-1' \n",
    "\n",
    "print (aos_host)\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f324821",
   "metadata": {},
   "source": [
    "### 5. Create a index in Amazon Opensearch Service \n",
    "We are defining an index with english analyzer which will strip the common stopwords like `the`, `is`, `a`, `an`, etc..\n",
    "\n",
    "We will use the aos_client connection we initiated ealier to create an index in Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b052b473",
   "metadata": {},
   "outputs": [],
   "source": [
    "headset_default_index = {\n",
    "    \"settings\": {\n",
    "        \"number_of_replicas\": 1,\n",
    "        \"number_of_shards\": 1,\n",
    "        \"analysis\": {\n",
    "          \"analyzer\": {\n",
    "            \"default\": {\n",
    "              \"type\": \"standard\",\n",
    "              \"stopwords\": \"_english_\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "    }\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cbfdf",
   "metadata": {},
   "source": [
    "If for any reason you need to recreate your dataset, you can uncomment and execute the following to delete any previously created indexes. If this is the first time you're running this, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573cf751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aos_client.indices.delete(index=\"headset_pqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5bd09f",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.create(index=\"headset_pqa\",body=headset_default_index,ignore=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a041f9e",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=\"headset_pqa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037debef",
   "metadata": {},
   "source": [
    "### 6. Load the raw data into the Index\n",
    "Next, let's load the headset PQA data we copied locally into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84c7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "def load_pqa_as_json(file_name,number_rows=1000):\n",
    "    result=[]\n",
    "    with open(file_name) as f:\n",
    "        i=0\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            result.append(data)\n",
    "            i+=1\n",
    "            if(i == number_rows):\n",
    "                break\n",
    "    return result\n",
    "\n",
    "\n",
    "qa_list_json = load_pqa_as_json('amazon-pqa/amazon_pqa_headsets.json',number_rows=1000)\n",
    "\n",
    "\n",
    "def es_import(question):\n",
    "    aos_client.index(index='headset_pqa', body=question)\n",
    "        \n",
    "workers = 4 * cpu_count()\n",
    "    \n",
    "process_map(es_import, qa_list_json,chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ddf7aa",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. We should have 1000 hits in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348f45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=\"headset_pqa\", body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d \" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564e873",
   "metadata": {},
   "source": [
    "### 7. Run a \" Simple Text Search\"\n",
    "\n",
    "Now that we've loaded our data, let's run a keyword search for the question \"does this work with xbox?\", using the default OpenSearch query, and display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b17174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"question_text\": \"does this work with xbox?\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=\"headset_pqa\", body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['question_text'],hit['_source']['answers'][0]['answer_text']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8182469e",
   "metadata": {},
   "source": [
    "### 8. Search across multiple fields\n",
    "\n",
    "Search across multiple fields could bring more results and scored based on BM25 relevancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabf931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "      \"query\": \"does this work with xbox?\",\n",
    "      \"fields\": [\"question_text\",\"bullet_point*\", \"answers.answer_text\", \"item_name\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=\"headset_pqa\", body=query)\n",
    "\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['question_text'],hit['_source']['answers'][0]['answer_text']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf288f",
   "metadata": {},
   "source": [
    "### 9. Search with Field preference or boosting\n",
    "\n",
    "When searching across fields, all fields given the same priority by default. But you can control the preference by giving static boost score to each field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e50bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"multi_match\": {\n",
    "      \"query\": \"does this work with xbox?\",\n",
    "      \"fields\": [\"question_text^2\", \"bullet_point*\", \"answers.answer_text^2\", \"item_name^1.5\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=\"headset_pqa\", body=query)\n",
    "\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['question_text'],hit['_source']['answers'][0]['answer_text']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a86ad",
   "metadata": {},
   "source": [
    "### 10. Compound queries with `bool`\n",
    "\n",
    "With `bool` queries, you can give more preference based on other field values/existance. In the below query, it will get higher score if `answer_aggregated` is `netural`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c982cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query={\n",
    "  \"query\": {\n",
    "    \"bool\": {\n",
    "      \"must\": [\n",
    "        {\n",
    "          \"multi_match\": {\n",
    "            \"query\": \"does this work with xbox?\",\n",
    "            \"fields\": [ \"question_text^2\", \"bullet_point*\", \"answers.answer_text^2\",\"item_name^2\"]\n",
    "          }\n",
    "        }\n",
    "      ],\n",
    "      \"should\": [\n",
    "        {\n",
    "          \"term\": {\n",
    "            \"answer_aggregated.keyword\": {\n",
    "              \"value\": \"neutral\"\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=\"headset_pqa\", body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['question_text'],hit['_source']['answers'][0]['answer_text']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62e7a7",
   "metadata": {},
   "source": [
    "### 11. Use custom scoring with function score queries\n",
    "\n",
    "Function score are handy queries to overwrite the default BM-25 scoring. In the below query, it recalculates the score based on how many times the question was answered before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22cdba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "query={\n",
    "  \"query\": {\n",
    "    \"function_score\": {\n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"multi_match\": {\n",
    "                \"query\": \"does this work with xbox?\",\n",
    "                \"fields\": [\"question_text^5\",\"bullet_point*\",\"answers.answer_text^2\", \"item_name^2\" ]\n",
    "              }\n",
    "            }\n",
    "          ],\n",
    "          \"should\": [\n",
    "            {\n",
    "              \"term\": {\n",
    "                \"answer_aggregated.keyword\": {\n",
    "                  \"value\": \"neutral\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "      \"functions\": [\n",
    "        {\n",
    "          \"script_score\": {\n",
    "            \"script\": \"_score * 0.25 * doc['answers.answer_text.keyword'].length\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=\"headset_pqa\", body=query)\n",
    "print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['question_text'],hit['_source']['answers'][0]['answer_text']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"question\",\"answer\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58971cb",
   "metadata": {},
   "source": [
    "### 12. Observe The Results and Refine\n",
    "\n",
    "Congratulations, you've now explored the possiblities of text search on the data in OpenSearch.\n",
    "\n",
    "If you take a look at the results above, you'll notice that the results match one or more of the key words from our question, most commonly the words \"work\" and \"xbox\".  You'll also notices that a lot of these results aren't relevant to our original question, such as \"Does it work on PS3?\" and \"Does it work for computers\". In Module 3, we'll instead use semantic search to make the result more relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0baab8a",
   "metadata": {},
   "source": [
    "### Store Variables Used for the Next Notebook\n",
    "\n",
    "There are a few values you will need for the next notebook, execute the cells below to store them so they can be copied and pasted into the next part of the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecad485",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store outputs\n",
    "%store bucket\n",
    "%store aos_host"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
