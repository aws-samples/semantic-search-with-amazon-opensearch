{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# Generative AI-powered search with Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "---\n",
    "### Using Scenario\n",
    "Form 10-K is a comprehensive report filed annually by a publicly traded company about its financial performance and is required by the U.S. Securities and Exchange Commission (SEC). Some of the information a company is required to document in the 10-K includes its history, organizational structure, financial statements, earnings per share, subsidiaries, executive compensation, and any other relevant data.\n",
    "\n",
    "The SEC mandates that all public companies file regular 10-Ks to keep investors aware of a company's financial condition and to allow them to have enough information before they buy or sell securities issued by that company. The 10-K can appear overly complex at first glance, complete with tables full of data and figures. However, it is so comprehensive that this filing is critical for investors to handle a company's financial position and prospects.\n",
    "\n",
    "Form 10-K is an annual report that provides a comprehensive analysis of the company's financial condition. The Form 10-K is comprised of several parts. These include:\n",
    "\n",
    "- 1 - Business-This describes the company's operations. \n",
    "- 1A - Risk Factors\n",
    "- 1B - Unresolved Staff Comments\n",
    "- 2 - Properties\n",
    "- 3 - Legal Proceedings\n",
    "- 4 - Mine Safety Disclosures\n",
    "- 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "- 6 - Selected Financial Data (prior to February 2021)\n",
    "- 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "- 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "- 8 - Financial Statements and Supplementary Data\n",
    "- 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "- 9A - Controls and Procedures\n",
    "- 9B - Other Information\n",
    "- 10 - Directors, Executive Officers and Corporate Governance\n",
    "- 11 - Executive Compensation\n",
    "- 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "- 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "- 14 - Principal Accountant Fees and Services\n",
    "- 15 - Exhibits and Financial Statement Schedules\n",
    "\n",
    "---\n",
    "\n",
    "Many investors rely of SEC filings to analyze the financial health of a company, and they can certainly be a treasure trove of valuable information. Keyword based search may return some irrelevant information. Even with semantic search, information is overwhelming. Can we leverage generative AI to help us on company financial statements interpertation?\n",
    "\n",
    "\n",
    "In this code talk session, we will show you how to modernize your search application to improve search relevance with Amazon OpenSearch while leveraging generative AI to improve search productivity. The code includes the following topics:\n",
    "- Comparison search relevance between keyword search and semantic search with Amazon OpenSearch.\n",
    "- How to leverage Retrieval Augmented Generation(RAG) improve search productivity.\n",
    "- How to build intelligent agent which orchestrate and execute multistep tasks to automate 10-K filings analysis.\n",
    "- OpenSearch vector store best practices\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Code Structure\n",
    "\n",
    "\n",
    "The code includes the following sections:\n",
    "- [Initialize](#Initialize)\n",
    "- [Part 1: Ingest unstructured data into OpenSearch](#Part-1:-Ingest-unstructured-data-into-OpenSearch)\n",
    "- [Part 2: Different appoach to search](#Part-2:-Different-appoach-to-search)\n",
    "    - [2.1 Keyword search](#2.1-Keyword-search)\n",
    "    - [2.2 Semantic/Vector search](#2.2-Semantic/Vector-search)\n",
    "    - [2.3 Retrieval Augmented Generation(RAG)](#2.3-Retrieval-Augmented-Generation(RAG))\n",
    "- [Part 3: AI agent powered search](#Part-3:-AI-agent-powered-search)\n",
    "    - [3.1 Prepare other tools used by AI agent](#3.1-Prepare-other-tools-used-by-AI-agent)\n",
    "        - [3.1.1 Ingest and query structured data in Redshift](#3.1.1-Ingest-and-query-structured-data-in-Redshift)\n",
    "        - [3.1.2 Download 10-K filing from SEC](#3.1.2-Download-10-K-filing-from-SEC)\n",
    "    - [3.2 Create AI agent](#3.2-Create-AI-agent)\n",
    "    - [3.3 Use AI agent](#3.3-Use-AI-agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703e3d",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666979ee",
   "metadata": {},
   "source": [
    "Make sure PyTorch versin is larger than or equal  2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2e6105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fa4b0",
   "metadata": {},
   "source": [
    "###  Install dependency Python library for OpenSearch, Redshift, Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q opensearch-py\n",
    "%pip install boto3\n",
    "%pip install sqlalchemy>\n",
    "%pip install sqlalchemy-redshift\n",
    "%pip install redshift_connector\n",
    "%pip install ipython-sql==0.4.1\n",
    "%pip install langchain\n",
    "%pip install -U langchain-aws\n",
    "%pip install -U langchain-community\n",
    "%pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {},
   "source": [
    "### Import library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker,json\n",
    "from sagemaker.session import Session\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a732112",
   "metadata": {},
   "source": [
    "## Part 1: Ingest unstructured data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c83fe5",
   "metadata": {},
   "source": [
    "### Get SEC 10-K form files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ws-assets-prod-iad-r-sfo-f61fc67057535f1b.s3.us-west-1.amazonaws.com/df655552-1e61-4a6b-9dc4-c03eb94c6f75/10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a884af",
   "metadata": {},
   "source": [
    "Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d61bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip 10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994effa4",
   "metadata": {},
   "source": [
    "Read the dataset in JSON format and contruct pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the JSON files\n",
    "folder_path = \"extracted\"\n",
    "\n",
    "# Initialize an empty list to store list of company 10-K filing file names\n",
    "company_filing_file_name_list = []\n",
    "\n",
    "#For this session, we only ingest few company information.\n",
    "company_list=[\"Alteryx, Inc.\",\n",
    "              \"MICROSTRATEGY Inc\", \n",
    "              \"Elastic N.V.\", \n",
    "              \"MongoDB, Inc.\", \n",
    "              \"Palo Alto Networks Inc\", \n",
    "              \"Okta, Inc.\",\n",
    "              \"Datadog, Inc.\", \n",
    "              \"Snowflake Inc.\",\n",
    "              \"SALESFORCE.COM, INC.\", \n",
    "              \"ORACLE CORP\",\n",
    "              \"MICROSOFT CORP\", \n",
    "              \"Palantir Technologies Inc.\"\n",
    "             ]\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.DataFrame([pd.read_json(file_path,typ='series')])\n",
    "        if df.iloc[0]['company'] in company_list:\n",
    "            company_filing_file_name_list.append(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_filing_file_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bd148",
   "metadata": {},
   "source": [
    "### Initialize embedding model to vectorize text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf9a5d",
   "metadata": {},
   "source": [
    "**Embeddings** are numerical representations of data, typically used to convert complex, high-dimensional data into a lower-dimensional space where similar data points are closer together. In the context of natural language processing (NLP), embeddings are used to represent words, phrases, or sentences as vectors of real numbers. These vectors capture semantic relationships, meaning that words with similar meanings are represented by vectors that are close together in the embedding space.\n",
    "\n",
    "**Embedding models** are machine learning models that are trained to create these numerical representations. They learn to encode various types of data into embeddings that capture the essential characteristics and relationships within the data. For example, in NLP, embedding models like Word2Vec, GloVe, and BERT are trained on large text corpora to produce word embeddings. These embeddings can then be used for various downstream tasks, such as text classification, sentiment analysis, or machine translation. In this case we'll be using it for semantic similarity\n",
    "\n",
    "We use embedding model to convert questions into vector and use vector similiarity to search semantic similiar 10-K data. The following diagram shows the flow: \n",
    "\n",
    "![Convert Text to Vector](./static/text2vector.png)\n",
    "\n",
    "---\n",
    "\n",
    "![opensearch vector store](./static/opensearch-vector-store.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc400238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=f\"https://bedrock-runtime.{aws_region}.amazonaws.com\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v1',client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(\"This is a content of the document\")\n",
    "result[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11708cbb",
   "metadata": {},
   "source": [
    "### Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with OpenSearch Cluster.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below.\n",
    "\n",
    "#### Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "region = aws_region\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "kms = boto3.client('secretsmanager')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"generative-ai-powered-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "aos_credentials = json.loads(kms.get_secret_value(SecretId=outputs['OpenSearchSecret'])['SecretString'])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b059b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "\n",
    "auth = (aos_credentials['username'], aos_credentials['password'])\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb772",
   "metadata": {},
   "source": [
    "### Create a index in Amazon OpenSearch Service \n",
    "\n",
    "The OpenSearch k-NN plugin introduces a custom data type, the knn_vector, that allows users to ingest their k-NN vectors into an OpenSearch index and perform different kinds of k-NN search. \n",
    "\n",
    "---\n",
    "#### OpenSearch Approximate Nearest Neighbor Algorithms and Engines\n",
    "![ANN algorithm](./static/ann-algorithm.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### HNSW parameter tuning\n",
    "![hnsw parameter tuning](./static/hnsw-parameter-tuning.png)\n",
    "\n",
    "---\n",
    "\n",
    "#### IVF parameter tuning\n",
    "![ivf parameter tuning](./static/ivf-parameter-tuning.png)\n",
    "\n",
    "#### How to select the engine and algorithms\n",
    "![opensearch ann comparison](./static/opensearch-ann-selection.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"item_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,\n",
    "                \"store\": True,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                      \"ef_construction\": 128,\n",
    "                      \"m\": 24\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"item_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9e09e",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60657cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"10k_financial\"\n",
    "\n",
    "exist=False\n",
    "try:\n",
    "    aos_client.indices.get(index=index_name)\n",
    "    exist=True\n",
    "except Exception as e:\n",
    "    exist=False\n",
    "\n",
    "if exist:\n",
    "    print(\"delete existing index before creating new one\")\n",
    "    aos_client.indices.delete(index=index_name)\n",
    "else:\n",
    "    print(\"index does not exist.\")\n",
    "    \n",
    "aos_client.indices.create(index=index_name,body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ad42d",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9f03",
   "metadata": {},
   "source": [
    "###  Load the raw data into the Index\n",
    "Next, let's load the financial billing data into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import pandas\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "class PandasDataFrameLoader(BaseLoader):\n",
    "    \n",
    "    def __init__(self,dataframe:pandas.DataFrame):\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        items=[\"item_1\",\"item_1A\",\"item_1B\",\"item_2\",\"item_3\",\"item_4\",\"item_5\",\"item_6\",\"item_7\",\"item_7A\",\"item_8\",\"item_9\",\"item_9A\", \"item_9B\", \"item_10\", \"item_11\", \"item_12\", \"item_13\", \"item_14\", \"item_15\"]\n",
    "        \n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            metadata={}\n",
    "            metadata[\"cik\"]=row['cik']\n",
    "            metadata[\"company_name\"]=row['company']\n",
    "            metadata[\"filing_date\"]=row['filing_date']\n",
    "            for item in items:\n",
    "                content=row[item]\n",
    "                metadata['item'] = item\n",
    "                doc = Document(page_content=content,metadata=metadata)\n",
    "                #print(doc.metadata)\n",
    "                docs.append(doc)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dcbea",
   "metadata": {},
   "source": [
    "Use Bedrock embedding convert item content into vector and use OpenSearch bulk ingest to store data into OpenSearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from opensearchpy import helpers\n",
    "\n",
    "def ingest_downloaded_10k_into_opensearch(file_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    item_contents=[]\n",
    "    company_name=splitted_documents[0].metadata['company_name']\n",
    "    for doc in splitted_documents:\n",
    "        item_contents.append(doc.page_content)\n",
    "    \n",
    "    print(\"\\ncompany:\" + company_name + \", item count:\" + str(len(item_contents)))\n",
    "    start = time.time()\n",
    "    embedding_results = bedrock_embeddings.embed_documents(item_contents)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    #print(f\"total time elapsed for Bedrock embedding: {elapsed:.2f} seconds\")\n",
    "        \n",
    "    data = []\n",
    "    i=0\n",
    "    for content in item_contents:\n",
    "        data.append({\"_index\": index_name,  \"company_name\": company_name, \"item_content\":content, \"item_vector\":embedding_results[i]})\n",
    "        i = i+1\n",
    "    aos_response= helpers.bulk(aos_client, data)\n",
    "    print(f\"Bulk-inserted {aos_response[0]} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e516be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in company_filing_file_name_list:\n",
    "    ingest_downloaded_10k_into_opensearch(file)\n",
    "    print(\"Ingested :\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee126626",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131f864",
   "metadata": {},
   "source": [
    "## Part 2: Different appoach to search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1007fa",
   "metadata": {},
   "source": [
    "### 2.1 Keyword search\n",
    "---\n",
    "Keyword search refers to finding information one is looking for using terms or words, called \"query\", from among a large body of textual data. It uses exact matching of those terms, popularly called \"keyword match\" without considering the meaning or context behind those words. \n",
    "\n",
    "\n",
    "![Keyword Search](./static/keyword-search-flow.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What Microsoft's research and development organization is responsible for?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db06fec",
   "metadata": {},
   "source": [
    "Run the query and check the search result. Some irrelevant documents are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba47370",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_content\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_content\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content'], hit['highlight']['item_content'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\",\"item_content_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What is Microsoft's main revenue?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeca9e9",
   "metadata": {},
   "source": [
    "Run the query and check the search result. Some irrelevant documents are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_content\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_content\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content'], hit['highlight']['item_content'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\",\"item_content_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019cb4a",
   "metadata": {},
   "source": [
    "### 2.2 Semantic/Vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895095ec",
   "metadata": {},
   "source": [
    "---\n",
    "Semantic search refers to using machine learning to understand the meaning of queries. It improves usefulness of search by understanding the intent and contextual meaning of those terms by bringing results that are hopefully more relevant than simple text search.  \n",
    "\n",
    "![Semantic Search](./static/semantic-search-flow.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![Semantic Search Architecture](./static/semantic-search-architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What Microsoft's research and development organization is responsible for?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3e613",
   "metadata": {},
   "source": [
    "Run the query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1070e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What is Microsoft's main revenue?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e3fd3",
   "metadata": {},
   "source": [
    "Run the query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d6347",
   "metadata": {},
   "source": [
    "### 2.3 Retrieval Augmented Generation(RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cb878",
   "metadata": {},
   "source": [
    "In RAG, external data can be sourced from various data sources, such as document repositories, databases, or APIs. The first step is to convert the documents and the user query into a format that enables comparison and allows for performing relevancy search. To achieve comparability for relevancy search, a document collection (knowledge library) and the user-submitted query are transformed into numerical representations using embedding language models. These embeddings are essentially numerical representations of concepts in text.\n",
    "\n",
    "Next, based on the embedding of the user query, relevant text is identified in the document collection through similarity search in the embedding space. The prompt provided by the user is then combined with the searched relevant text and added to the context. This updated prompt, which includes relevant external data along with the original prompt, is sent to the LLM (Language Model) for processing. As a result, the model output becomes relevant and accurate due to the context containing the relevant external data.\n",
    "\n",
    "The major components of RAG, including embedding, vector databases, augmentation, and generation:\n",
    "\n",
    "\n",
    "- Embedding: Purpose: Embeddings transform text data into numerical vectors in a high-dimensional space. These vectors represent the semantic meaning of the text. Process: The embedding process typically uses pre-trained models (like BERT or a variant) to convert both the input queries and the documents in the database into dense vectors. Role in RAG: Embeddings are crucial for the retrieval component as they allow the model to compute the similarity between the query and the documents in the database efficiently.\n",
    "- Vector Database: Function: A vector database stores the embeddings of a large collection of documents or passages. Construction: It is created by processing a vast corpus (like Wikipedia or other specialized datasets) through an embedding model. Usage in RAG: When a query comes in, the model searches this database to find the documents whose embeddings are most similar to the embedding of the query.\n",
    "- Retrieval (Augmentation): Mechanism: The retrieval part of RAG functions by taking the input query, converting it into a vector using embeddings, and then searching the vector database to retrieve relevant documents. Result: It augments the original query with additional context by selecting documents or passages that are semantically related to the query. This augmented information is essential for generating more informed responses.\n",
    "- Generation: Integration with a Language Model: The generative component, often a large language model like Amazon Titan Text, receives both the original query and the retrieved documents. Response Generation: It synthesizes information from these inputs to produce a coherent and contextually appropriate response. Training and Fine-Tuning: This component is generally pre-trained on vast amounts of text and may be further fine-tuned to optimize its performance for specific tasks or datasets.\n",
    "- End-to-End Training (Optional): Joint Optimization: In RAG, both retrieval and generation components can be fine-tuned together, allowing the system to optimize the selection of documents and the generation of responses simultaneously. Feedback Loop: The model learns not only to generate relevant responses but also to retrieve the most useful documents for any given query.\n",
    "\n",
    "---\n",
    "### Architecture\n",
    "\n",
    "![RAG](./static/RAG_Architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_index_name=\"10k_financial_embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "exist=False\n",
    "try:\n",
    "    aos_client.indices.get(index=langchain_index_name)\n",
    "    exist=True\n",
    "except Exception as e:\n",
    "    exist=False\n",
    "\n",
    "if exist:\n",
    "    print(\"delete existing index before creating new one\")\n",
    "    aos_client.indices.delete(index=langchain_index_name)\n",
    "else:\n",
    "    print(\"index does not exist.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb253682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from typing import Callable\n",
    "\n",
    "os_domain_ep = 'https://'+aos_host\n",
    "\n",
    "\n",
    "def ingest_10k_into_opensearch_with_langchain(file_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    OpenSearchVectorSearch.from_documents(\n",
    "                index_name = langchain_index_name,\n",
    "                documents=splitted_documents,\n",
    "                embedding=bedrock_embeddings,\n",
    "                opensearch_url=os_domain_ep,\n",
    "                http_auth=auth\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a18ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in company_filing_file_name_list:\n",
    "    ingest_10k_into_opensearch_with_langchain(file)\n",
    "    print(\"Ingested :\" + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c77644",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=langchain_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc412439",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimiliarOpenSearchVectorSearch(OpenSearchVectorSearch):\n",
    "    \n",
    "    def relevance_score(self, distance: float) -> float:\n",
    "        return distance\n",
    "    \n",
    "    def _select_relevance_score_fn(self) -> Callable[[float], float]:\n",
    "        return self.relevance_score\n",
    "\n",
    "\n",
    "open_search_vector_store = SimiliarOpenSearchVectorSearch(\n",
    "                                    index_name=langchain_index_name,\n",
    "                                    embedding_function=bedrock_embeddings,\n",
    "                                    opensearch_url=os_domain_ep,\n",
    "                                    http_auth=auth\n",
    "                                    ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981fa91",
   "metadata": {},
   "source": [
    "Initialize Bedrock LLM model with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM, ChatBedrock\n",
    "\n",
    "#bedrock_llm = BedrockLLM(model_id=\"anthropic.claude-v2\", client=boto3_bedrock)\n",
    "bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=boto3_bedrock)\n",
    "#bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\", client=boto3_bedrock)\n",
    "\n",
    "\n",
    "bedrock_llm.model_kwargs = {\"temperature\":0.01,\"top_k\":250,\"top_p\":1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "import langchain\n",
    "\n",
    "bedrock_retriever = open_search_vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        'k': 5,\n",
    "        'score_threshold': 0.005\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4fc3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_qa = RetrievalQA.from_chain_type(\n",
    "    llm=bedrock_llm,\n",
    "    retriever=bedrock_retriever,\n",
    "    chain_type=\"stuff\" #stuff, refine, map_reduce, and map_rerank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What Microsoft's research and development organization is responsible for?\"\n",
    "\n",
    "langchain.debug=True\n",
    "result = rag_qa({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result:\" + result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d01915",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is Microsoft main revenue?\"\n",
    "\n",
    "langchain.debug=False\n",
    "result = rag_qa({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result:\" + result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40648cdd",
   "metadata": {},
   "source": [
    "## Part 3: AI agent powered search\n",
    "\n",
    "![standard rag limitation](./static/rag-limitation.png)\n",
    "\n",
    "### What is an AI agent ?\n",
    "An agentic employs a chain-of-thought reasoning process, where the LLM is prompted to think gradually through a question, interleaving its reasoning with the ability to use external tools such as search engines and APIs. This allows the LLM to retrieve relevant information that can help answer partial aspects of the question, ultimately leading to a more comprehensive and accurate final response. This approach is inspired by the \"Reason and Act\" (ReAct) design introduced in the paper [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629)  which aims to synergize the reasoning capabilities of language models with the ability to interact with external resources and take actions. By combining these two facets, an agentic LLM assistant can provide more informed and well-rounded answers to complex user queries.\n",
    "\n",
    "### Why build an AI agent?\n",
    "In today's digital landscape, enterprises are inundated with a vast array of data sources, ranging from traditional PDF documents to complex SQL and NoSQL databases, and everything in between. While this wealth of information holds immense potential for gaining valuable insights and driving operational efficiency, the sheer volume and diversity of data can often pose significant challenges in terms of accessibility and utilization.\n",
    "\n",
    "This is where the power of agentic LLM assistants comes into play. By leveraging progress in LLM design patterns such as Reason and Act (ReAct) and other traditional or novel design patterns, these intelligent assistants are capable of integrating with an enterprise's diverse data sources. Through the development of specialized tools tailored to each data source and the ability of LLM agents to identify the right tool for a given question, agentic LLM assistants can simplify how you navigate and extract relevant information, regardless of its origin or structure.\n",
    "\n",
    "This enables a rich, multi-source conversation that promises to unlock the full potential of the entreprise data, enabling data-driven decision-making, enhancing operational efficiency, and ultimately driving productivity and growth.\n",
    "\n",
    "\n",
    "### Architecture\n",
    "\n",
    "The following is the overall architecture on agent based finincial filings analysis:\n",
    "\n",
    "![generative ai powered search](./static/architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c010",
   "metadata": {},
   "source": [
    "### 3.1 Prepare other tools used by AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcf6e3",
   "metadata": {},
   "source": [
    "#### 3.1.1 Ingest and query structured data in Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3c50d",
   "metadata": {},
   "source": [
    "Get Redshift Serverless username, password and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_serverless_credentials = json.loads(kms.get_secret_value(SecretId=outputs['RedshiftServerlessSecret'])['SecretString'])\n",
    "redshift_serverless_username=redshift_serverless_credentials['username']\n",
    "redshift_serverless_password=redshift_serverless_credentials['password']\n",
    "redshift_serverless_endpoint =  outputs['RedshiftServerlessEndpoint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c619",
   "metadata": {},
   "source": [
    "Create `stock_symbol` table and populate the table from S3. We will use this table to query company stock ticker by company name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import Session\n",
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();\n",
    "\n",
    "%sql CREATE TABLE IF NOT EXISTS public.stock_symbol (stock_symbol text PRIMARY KEY, company_name text NOT NULL);\n",
    "\n",
    "stock_price_bucket = outputs[\"s3BucketStock\"]\n",
    "s3_location = f's3://{stock_price_bucket}/stock-price/'\n",
    "print(s3_location)\n",
    "!aws s3 sync ./stock-price/ $s3_location\n",
    "\n",
    "stock_symbol_s3_location = f's3://{stock_price_bucket}/stock-price/stock_symbol.csv'\n",
    "quoted_stock_symbol_s3_location = \"'\" + stock_symbol_s3_location + \"'\"\n",
    "\n",
    "%sql COPY STOCK_SYMBOL FROM $quoted_stock_symbol_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "\n",
    "def query_stock_ticker(company_name):\n",
    "    url = URL.create(\n",
    "    drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "    host=redshift_serverless_endpoint, \n",
    "    port=5439,\n",
    "    database='dev',\n",
    "    username=redshift_serverless_username,\n",
    "    password=redshift_serverless_password\n",
    "    )\n",
    "\n",
    "    engine = sa.create_engine(url)\n",
    "    cnn = engine.connect()\n",
    "\n",
    "    strSQL = \"SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%\" + company_name + \"%'\"\n",
    "    stock_ticker=''\n",
    "    try:\n",
    "        result = cnn.execute(strSQL)\n",
    "        df = pd.DataFrame(result)\n",
    "        stock_ticker=df['stock_symbol'][0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return stock_ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34411033",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stock_ticker(\"Amazon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd10bb",
   "metadata": {},
   "source": [
    "#### 3.1.2 Download 10-K filing from SEC\n",
    "---\n",
    "https://sec-api.io\n",
    "\n",
    "Create a new account and get free API key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sec-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78970fd",
   "metadata": {},
   "source": [
    "##### Replace your sec-api key in the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_api_key=\"{security_api_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_api import ExtractorApi, QueryApi\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_filings(ticker):\n",
    "    global sec_api_key\n",
    "\n",
    "    # Finding Recent Filings with QueryAPI\n",
    "    queryApi = QueryApi(api_key=sec_api_key)\n",
    "    query = {\n",
    "      \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\"\",\n",
    "      \"from\": \"0\",\n",
    "      \"size\": \"1\",\n",
    "      \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "    }\n",
    "    response = queryApi.get_filings(query)\n",
    "\n",
    "    # Getting 10-K URL\n",
    "    filing_url = response[\"filings\"][0][\"linkToFilingDetails\"]\n",
    "    filing_type=response['filings'][0]['formType']\n",
    "    cik=response['filings'][0]['cik']\n",
    "    company=response['filings'][0]['companyName']\n",
    "    filing_date=response['filings'][0]['filedAt']\n",
    "    period_of_report=response['filings'][0]['periodOfReport']\n",
    "    filing_html_index=response['filings'][0]['linkToFilingDetails']\n",
    "    complete_text_filing_link=response['filings'][0]['linkToTxt']\n",
    "\n",
    "    # Extracting Text with ExtractorAPI\n",
    "    extractorApi = ExtractorApi(api_key=sec_api_key)\n",
    "    \n",
    "    one_text = extractorApi.get_section(filing_url, \"1\", \"text\")       #Section 1 - Business\n",
    "    onea_text = extractorApi.get_section(filing_url, \"1A\", \"text\")     # Section 1A - Risk Factors\n",
    "    oneb_text = extractorApi.get_section(filing_url, \"1B\", \"text\")     # Section 1B - Unresolved Staff Comments\n",
    "    two_text = extractorApi.get_section(filing_url, \"2\", \"text\")       # Section 2 - Properties\n",
    "    three_text = extractorApi.get_section(filing_url, \"3\", \"text\")     # Section 3 - Legal Proceedings\n",
    "    four_text = extractorApi.get_section(filing_url, \"4\", \"text\")      # Section 4 - Mine Safety Disclosures\n",
    "    five_text = extractorApi.get_section(filing_url, \"5\", \"text\")      # Section 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "    six_text = extractorApi.get_section(filing_url, \"6\", \"text\")       # Section 6 - Selected Financial Data (prior to February 2021)\n",
    "    seven_text = extractorApi.get_section(filing_url, \"7\", \"text\")     # Section 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "    sevena_text = extractorApi.get_section(filing_url, \"7A\", \"text\")   # Section 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "    eight_text = extractorApi.get_section(filing_url, \"8\", \"text\")     # Section 8 - Financial Statements and Supplementary Data\n",
    "    nine_text = extractorApi.get_section(filing_url, \"9\", \"text\")      # Section 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "    ninea_text = extractorApi.get_section(filing_url, \"9A\", \"text\")    # Section 9A - Controls and Procedures\n",
    "    nineb_text = extractorApi.get_section(filing_url, \"9B\", \"text\")    # Section 9B - Other Information\n",
    "    ten_text = extractorApi.get_section(filing_url, \"10\", \"text\")      # Section 10 - Directors, Executive Officers and Corporate Governance\n",
    "    eleven_text = extractorApi.get_section(filing_url, \"11\", \"text\")   # Section 11 - Executive Compensation\n",
    "    twelve_text = extractorApi.get_section(filing_url, \"12\", \"text\")   # Section 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "    thirteen_text = extractorApi.get_section(filing_url, \"13\", \"text\") # Section 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "    fourteen_text = extractorApi.get_section(filing_url, \"14\", \"text\") # Section 14 - Principal Accountant Fees and Services\n",
    "    fifteen_text = extractorApi.get_section(filing_url, \"15\", \"text\")  # Section 15 - Exhibits and Financial Statement Schedules\n",
    "    \n",
    "    data = {}\n",
    "    data['filing_url'] = filing_url\n",
    "    data['filing_type'] = filing_type\n",
    "    data['cik'] = cik\n",
    "    data['company'] = company\n",
    "    data['filing_date'] = filing_date\n",
    "    data['period_of_report'] = period_of_report\n",
    "    data['filing_html_index'] = filing_html_index\n",
    "    data['complete_text_filing_link'] = complete_text_filing_link\n",
    "    \n",
    "    \n",
    "    data['item_1'] = one_text\n",
    "    data['item_1A'] = onea_text\n",
    "    data['item_1B'] = oneb_text\n",
    "    data['item_2'] = two_text\n",
    "    data['item_3'] = three_text\n",
    "    data['item_4'] = four_text\n",
    "    data['item_5'] = five_text\n",
    "    data['item_6'] = six_text\n",
    "    data['item_7'] = seven_text\n",
    "    data['item_7A'] = sevena_text\n",
    "    data['item_8'] = eight_text\n",
    "    data['item_9'] = nine_text\n",
    "    data['item_9A'] = ninea_text\n",
    "    data['item_9B'] = nineb_text\n",
    "    data['item_10'] = ten_text\n",
    "    data['item_11'] = eleven_text\n",
    "    data['item_12'] = twelve_text\n",
    "    data['item_13'] = thirteen_text\n",
    "    data['item_14'] = fourteen_text\n",
    "    data['item_15'] = fifteen_text\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(\"./download_filings\"):\n",
    "        os.makedirs(\"./download_filings\")\n",
    "    \n",
    "    try:\n",
    "        file_name = filing_url.split(\"/\")[-2] + \"-\" + filing_url.split(\"/\")[-1].split(\".\")[0]+\".json\"\n",
    "        download_to = \"./download_filings/\" + file_name\n",
    "        with open(download_to, \"w\") as f:\n",
    "          json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(\"Problem with {url}\".format(url=url))\n",
    "        print(e)\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloaded_file=get_filings(\"AMZN\")\n",
    "#ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf641d",
   "metadata": {},
   "source": [
    "### 3.2 Create AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25aed0",
   "metadata": {},
   "source": [
    "#### Define methods used by AI agent\n",
    "\n",
    "One popular architecture for building agents is ReAct. ReAct combines reasoning and acting in an iterative process - in fact the name \"ReAct\" stands for \"Reason\" and \"Act\".\n",
    "\n",
    "The general flow looks like this:\n",
    "\n",
    "- The model will \"think\" about what step to take in response to an input and any previous observations.\n",
    "- The model will then choose an action from available tools (or choose to respond to the user).\n",
    "- The model will generate arguments to that tool.\n",
    "- The agent runtime (executor) will parse out the chosen tool and call it with the generated arguments.\n",
    "- The executor will return the results of the tool call back to the model as an observation.\n",
    "- This process repeats until the agent chooses to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def is_stock_related_query(human_input):\n",
    "    template = \"\"\"You are a helpful assistant to judge if the human input is stock related question.\n",
    "    If it is stock related, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return stock_related, human_input\n",
    "\n",
    "def get_company_name(human_input):\n",
    "    template = \"\"\"You are a helpful assistant who extract company name from the human input.Please only output the company\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "\n",
    "    company_name=llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return company_name\n",
    "    \n",
    "def semantic_search_and_check(human_input, k=10,with_post_filter=True):\n",
    "\n",
    "    company_name=get_company_name(human_input)\n",
    "    \n",
    "    search_vector = bedrock_embeddings.embed_query(human_input)\n",
    "\n",
    "    no_post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"post_filter\": {\n",
    "           \"match\": { \n",
    "               \"company_name\":company_name\n",
    "           }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    search_query=no_post_filter_search_query\n",
    "    if with_post_filter:\n",
    "        search_query=post_filter_search_query\n",
    "    \n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=search_query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    \n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        hit_company=hit['fields']['company_name'][0]\n",
    "        print(\"semantic search hit company: \" + hit_company)\n",
    "        row=[hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"item_content\"])\n",
    "    return query_result_df\n",
    "\n",
    "def search_for_similiar_content_in_10k_filing(human_input):\n",
    "    company_statements = semantic_search_and_check(human_input)\n",
    "    return company_statements\n",
    "\n",
    "def get_stock_ticker(human_input):\n",
    "    company_name=get_company_name(human_input)\n",
    "    company_ticker = query_stock_ticker(company_name)\n",
    "    return company_name, company_ticker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7b71a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "![OpenSearch KNN Filter](./static/opensearch-knn-filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bfbefb",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Uncomment the line `downloaded_file=get_filings(company_stock_ticker)` if you have sec-api security key so that you can download 10-K from SEC. In the meanwhile, comment the line 'downloaded_file=\"000101872424000008-amzn-20231231.json\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb0b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_10k_filing_from_sec_and_ingest_into_opensearch(company_stock_ticker):\n",
    "    #downloaded_file=get_filings(company_stock_ticker)\n",
    "    downloaded_file=\"000101872424000008-amzn-20231231.json\"\n",
    "    ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06f721",
   "metadata": {},
   "source": [
    "#### Define tools used by agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed114181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "annual_report_tools=[\n",
    "    Tool(\n",
    "        name=\"is_stock_related_query\",\n",
    "        func=is_stock_related_query,\n",
    "        description=\"Use this tool when you need to know whether this is stock related query. This tool will output whether human input is stock related and human input. Human orginal query is the input to this tool.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search_for_similiar_content_in_10k_filing\",\n",
    "        func=search_for_similiar_content_in_10k_filing,\n",
    "        description=\"Use this tool to get financial statement of the company. With the help of this data, companys historic performance can be evaluated. Human orginal query is the input to this tool.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"download_10k_filing_from_sec_and_ingest_into_opensearch\",\n",
    "        func=download_10k_filing_from_sec_and_ingest_into_opensearch,\n",
    "        description=\"Only use this tool when \\\"search_for_similiar_content_in_10k_filing\\\" tool does not return any result. Company stock ticker is the input to this tool.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Only use this tool when you need to call \\\"download_10k_filing_from_sec_and_ingest_into_opensearch\\\" tool. This tool will output company name and stock ticker.\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a089d5",
   "metadata": {},
   "source": [
    "#### Create the ReAct Agent using LLM, tools and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "\n",
    "annual_report_prompt=\"\"\"\n",
    "System: You are a financial advisor. Give stock recommendations for given query based on following instructions. \n",
    "\n",
    "<instructions>\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "<steps>\n",
    "Note- if you fail in satisfying any of the step below, Just move to next one\n",
    "1) Use \"is_stock_related_query\" tool to judge if the input query is stock related or not. If the input query is not stock related query. Ansower \\\"I can not asnwer this question\\\" and terminte the dialog. Output - stock related and input query\n",
    "2) Use \"search_for_similiar_content_in_10k_filing\" tool to get company's historic financial statement. Output- Financial statement\n",
    "3) Use \"download_10k_filing_from_sec_and_ingest_into_opensearch\" tool to download company 10-K filing from SEC and ingest the data into OpenSearch if \"search_for_similiar_content_in_10k_filing\" does not return any result. \n",
    "This tool input is company stock ticker, you need to use \"get_stock_ticker\" tool to get company stock ticker.\n",
    "After downloading company 10-K filing from SEC, you shall use \"search_for_similiar_content_in_10k_filing\" tool to search similiar content in OpenSearch. \n",
    "4) Analyze the stock based on gathered data and give detail analysis for investment choice. Provide numbers and reasons to justify your answer. Output- Detailed stock Analysis\n",
    "</steps>\n",
    "\n",
    "</instructions>\n",
    "\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Human: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "annual_report_prompt = PromptTemplate.from_template(annual_report_prompt)\n",
    "annual_report_agent = create_react_agent(bedrock_llm, annual_report_tools, annual_report_prompt)\n",
    "annual_report_agent_executor = AgentExecutor(agent=annual_report_agent, tools=annual_report_tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d9655",
   "metadata": {},
   "source": [
    "### 3.3 Use AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2dac4",
   "metadata": {},
   "source": [
    "#### Example 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f2a6f",
   "metadata": {},
   "source": [
    "Ask the queustion \"Is Microsoft a good investment choice right now?\". The agent will run the following process:\n",
    "\n",
    "1. is stock related query\n",
    "2. get company name\n",
    "3. use semantic search get related information from 10k financial filing data\n",
    "\n",
    "Combine all the above information and generate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "response = annual_report_agent_executor.invoke({\"input\": \"Is Microsoft a good investment choice right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df626aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55cb9b",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998c94c",
   "metadata": {},
   "source": [
    "\"Is Amazon a good investment choice right now?\". This is stock related quesiton. However there is no Amazon 10-K filing data in OpenSearch. The agent will download Amazon 10-K from SEC by calling SEC API and ingest data into OpenSearch. The agent will run the following process:\n",
    "\n",
    "1. is stock related query\n",
    "2. get company name\n",
    "3. use semantic search get related information from 10k financial filing data\n",
    "4. get stock ticker\n",
    "5. download 10-k data from SEC with API\n",
    "6. use semantic search get related information from 10k financial filing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = annual_report_agent_executor.invoke({\"input\": \"Is Amazon a good investment choice right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb04015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e8ee",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cbc80",
   "metadata": {},
   "source": [
    "This is not stock related query. The agent will run the following process:\n",
    "\n",
    "1. is stock related query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = annual_report_agent_executor.invoke({\"input\": \"What is SageMaker?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cdbf86",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c19ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_query={\n",
    "    \"query\":{\n",
    "           \"match\": { \n",
    "               \"company_name\":\"Amazon\"\n",
    "           }\n",
    "    }\n",
    "}\n",
    "\n",
    "aos_client.delete_by_query(index=index_name, body=delete_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65fdb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query={\n",
    "    \"query\":{\n",
    "           \"match\": { \n",
    "               \"company_name\":\"Amazon\"\n",
    "           }\n",
    "    }\n",
    "}\n",
    "\n",
    "aos_client.search(index=index_name, body=search_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2128348",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_10k_filing_from_sec_and_ingest_into_opensearch('AMZN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8e10d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
