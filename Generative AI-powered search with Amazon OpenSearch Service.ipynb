{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# Generative AI-powered search with Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "---\n",
    "### Using Scenario\n",
    "[Form 10-K](https://www.sec.gov/files/form10-k.pdf) is an annual report that public companies in the United States are required to file with the Securities and Exchange Commission (SEC). This comprehensive report provides detailed information about the company's financial performance over the past year, including the company's history and organizational structure, its financial statements such as the balance sheet, income statement, and cash flow statement, metrics like earnings per share, information on the company's subsidiaries, details on executive compensation, and any other material data about the company's operations and financial condition.\n",
    "\n",
    "The SEC requires all publicly traded companies to regularly file 10-K reports in order to keep investors informed about the company's financial condition. This allows investors to have sufficient information before making decisions to buy or sell the company's securities. While the 10-K may appear overly complex at first, with its many tables of data and figures, this level of comprehensive detail is critical for investors to properly understand the company's financial position and future prospects.\n",
    "\n",
    "The Form 10-K is comprised of several parts; these include:\n",
    "\n",
    "| Item | Description |\n",
    "| ---- | ----------- |\n",
    "|1|Business (This describes the company's operations.)|\n",
    "|1A| Risk Factors |\n",
    "|1B| Unresolved Staff Comments |\n",
    "|1C| Cybersecurity |\n",
    "|2| Properties |\n",
    "|3| Legal Proceedings |\n",
    "|4| Mine Safety Disclosures (if appropriate) |\n",
    "|5| Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities |\n",
    "|6| Selected Financial Data (prior to February 2021) |\n",
    "|7| Management’s Discussion and Analysis of Financial Condition and Results of Operations |\n",
    "|7A| Quantitative and Qualitative Disclosures About Market Risk |\n",
    "|8| Financial Statements and Supplementary Data |\n",
    "|9| Changes in and Disagreements With Accountants on Accounting and Financial Disclosure |\n",
    "|9A| Controls and Procedures |\n",
    "|9B| Other Information |\n",
    "|9C| Disclosure Regarding Foreign Jurisdictions that Prevent Inspections |\n",
    "|10| Directors, Executive Officers and Corporate Governance |\n",
    "|11| Executive Compensation |\n",
    "|12| Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters |\n",
    "|13| Certain Relationships and Related Transactions, and Director Independence |\n",
    "|14| Principal Accountant Fees and Services |\n",
    "|15| Exhibits and Financial Statement Schedules |\n",
    "|16| Form 10–K Summary (optional) |\n",
    "\n",
    "\n",
    "Many investors rely on SEC filings, such as the 10-K report, to analyze the financial health of a company. These filings can be a treasure trove of valuable information. However, searching for specific data within these comprehensive documents can be challenging. Keyword-based searches may return some irrelevant information, and even semantic search methods can still lead to an overwhelming amount of data. Can we leverage generative AI to help us interpret company financial statements?\n",
    "\n",
    "\n",
    "In this Code Talk, we will demonstrate how to modernize your search application to improve the relevance of search results. We will do this by utilizing Amazon OpenSearch, a popular search and analytics service. Additionally, we will explore how to leverage generative AI technology to enhance search productivity and make the search experience more efficient and effective for users. The code includes the following topics:\n",
    "- Comparison of search relevance between keyword-based search and semantic search using Amazon OpenSearch\n",
    "- Leveraging Retrieval Augmented Generation (RAG), a generative AI approach, to improve search productivity\n",
    "- Building an intelligent agent that can orchestrate and execute multi-step tasks to automate the analysis of 10-K financial filings\n",
    "- Best practices for utilizing the vector store capabilities within the OpenSearch platform to power advanced search and analysis solutions\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Code Structure\n",
    "\n",
    "The code includes the following sections:\n",
    "- [Initialize the Notebook](#Initialize-the-Notebook)\n",
    "- [Part 1: Ingest unstructured data into OpenSearch](#Part-1:-Ingest-unstructured-data-into-OpenSearch)\n",
    "- [Part 2: A different appoach to search](#Part-2:-A-different-appoach-to-search)\n",
    "    - [2.1 Keyword search](#2.1-Keyword-search)\n",
    "    - [2.2 Vector/Semantic search](#2.2-Vector/Semantic-search)\n",
    "    - [2.3 Retrieval Augmented Generation(RAG)](#2.3-Retrieval-Augmented-Generation(RAG))\n",
    "- [Part 3: AI agent powered search](#Part-3:-AI-agent-powered-search)\n",
    "    - [3.1 Prepare other tools used by AI agent](#3.1-Prepare-other-tools-used-by-AI-agent)\n",
    "        - [3.1.1 Ingest and query structured data in Redshift](#3.1.1-Ingest-and-query-structured-data-in-Amazon-Redshift)\n",
    "        - [3.1.2 Download SEC 10-K filing from SEC-API.io](#3.1.2-Download-SEC-10-K-filing-from-SEC-API.IO)\n",
    "    - [3.2 Create AI agent](#3.2-Create-an-AI-agent)\n",
    "    - [3.3 Use the financial statements analysis AI agent](#3.3-Use-the-financial-statements-analysis-AI-agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703e3d",
   "metadata": {},
   "source": [
    "## Initialize the Notebook\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4feec713-5dbd-44a4-8ec4-4ceb6f289dac",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Install Python libraries (and dependencies) for OpenSearch, Redshift and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3c3755-6d49-4347-b2c4-c15d78dd662a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Install the following:\n",
    "- [opensearch-py](https://docs.opensearch.org/docs/latest/clients/python-low-level/) - The OpenSearch low-level Python client, called opensearch-py, provides a set of wrapper methods that allow you to interact with your OpenSearch cluster more easily in Python. Instead of having to manually send raw HTTP requests to specific URLs, you can create an OpenSearch client instance for your cluster and then call the built-in functions provided by the client library. This makes working with the OpenSearch REST API much more natural and straightforward when using Python.\n",
    "- [PyTorch](https://pytorch.org/) - a Python package that provides two key high-level features: tensor computation capabilities similar to the popular NumPy library, but with the added benefit of strong acceleration for running these computations on GPUs; and supports the building of deep neural network models, which is enabled by its tape-based autograd system.\n",
    "- [requests-aws4auth](https://github.com/tedder/requests-aws4auth) - AWS authentication for the Python Requests library\n",
    "- [boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html) - AWS SDK for Python, which allows developers to write software that makes use of AWS Services\n",
    "- [SQLAlchemy](https://www.sqlalchemy.org/) - is an open-source toolkit for the Python programming language that is designed to facilitate efficient and high-performing database access. Its primary function is to help Python applications interact with relational databases more easily. SQLAlchemy accomplishes this by making it simpler for developers to create, update, and query database tables within their Python applications.\n",
    "- [Amazon RedShift Python connector](https://docs.aws.amazon.com/redshift/latest/mgmt/python-driver-install.html) - by using the Amazon Redshift connector for Python, you can integrate work with the AWS SDK for Python (Boto3), and also pandas and Numerical Python (NumPy).\n",
    "- [iPython-SQL](https://github.com/catherinedevlin/ipython-sql) - connect to a database, using SQLAlchemy URL connect strings, and issue standard SQL commands within a Jupyter Notebook.\n",
    "- [LangChain](https://python.langchain.com) - a framework that helps developers build applications powered by large language models (LLMs). It provides a set of tools and abstractions that simplify the process of integrating LLMs into various types of applications and workflows. See [What is LangChain?](https://aws.amazon.com/what-is/langchain/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1c491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -q opensearch-py\n",
    "%pip install -q torch\n",
    "%pip install -q requests-aws4auth\n",
    "%pip install -q boto3\n",
    "%pip install -q sqlalchemy\n",
    "%pip install -q sqlalchemy-redshift\n",
    "%pip install -q redshift_connector\n",
    "%pip install -q ipython-sql==0.4.1\n",
    "%pip install -q langchain==0.3.1\n",
    "%pip install -q langchain-aws==0.2.1\n",
    "%pip install -q langchain-community==0.3.1\n",
    "%pip install -q sec-api\n",
    "print(\"Done installing dependencies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import modules and packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56adaa8c-7a81-4dd5-90fc-024c4f83eb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppress various warnings and INFO messages during demonstration\n",
    "# Comment out the following to see full warning and INFO messaging\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger().setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688f4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, JSON, Markdown, Latex\n",
    "from langchain_aws import BedrockEmbeddings, BedrockLLM, ChatBedrock\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.agents import AgentExecutor, create_xml_agent, Tool\n",
    "from langchain.chains import LLMChain, RetrievalQA\n",
    "from langchain_community.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from opensearchpy import helpers, OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from requests_aws4auth import AWS4Auth\n",
    "from sagemaker.session import Session\n",
    "from sec_api import ExtractorApi, QueryApi\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import Session\n",
    "from typing import Any, Dict, Callable, List, Optional, Sequence\n",
    "from uuid import uuid4\n",
    "import boto3\n",
    "import json\n",
    "import langchain\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "import sqlalchemy as sa\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a732112",
   "metadata": {},
   "source": [
    "## Part 1: Ingest unstructured data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c83fe5",
   "metadata": {},
   "source": [
    "### Download a sample of SEC 10-K filing documents\n",
    "\n",
    "Let's get a collection of SEC 10-K financial reports from various companies. (We have already obtained a collection of these reports, put them into an Amazon S3 bucket and converted the HTML (hypertext markup) versions into JSON format, which makes them easier to work with.)\n",
    "\n",
    "The demonstration files in the Amazon S3 bucket are from the year 2020/2021. However, you can retrieve more recent years of 10-K filings directly from the [SEC's Electronic Data Gathering, Analysis, and Retrieval (EDGAR) system](https://www.sec.gov/search-filings). \n",
    "\n",
    "> A Form 10-K is public information. Companies that are publicly traded in the United States are required by law to file a 10-K annual report with the Securities and Exchange Commission (SEC). These 10-K filings, containing detailed financial and operational information about the companies, are then made publicly available by the SEC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9192e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget -q https://ws-assets-prod-iad-r-sfo-f61fc67057535f1b.s3.us-west-1.amazonaws.com/df655552-1e61-4a6b-9dc4-c03eb94c6f75/10k-financial-filing.zip\n",
    "!unzip -o -q 10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff7403",
   "metadata": {},
   "source": [
    "### Load the documents into OpenSearch\n",
    "Amazon OpenSearch is effective at dynamically inferring the data types of fields in your documents. This allows it to perform flexible full-text searches, including the ability to handle misspellings and variations in the search terms (known as \"fuzziness\"), while still returning relevant results based on the intended meaning (known as \"type tolerance\"). \n",
    "\n",
    "\n",
    "We will obtain the Amazon OpenSearch Serverless endpoint from the \"Outputs\" section of the CloudFormation Stack that we previously deployed.\n",
    "\n",
    ">If you do not see the OpenSearch Serverless endpoint listed in the Outputs, you may need to relaunch the CloudFormation Stack deployment from [here](https://github.com/aws-samples/semantic-search-with-amazon-opensearch/tree/generative-ai-powered-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c19e8a-3942-457d-a832-9a5328fa79e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cfn = boto3.client('cloudformation')\n",
    "sec = boto3.client('secretsmanager')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"generative-ai-powered-search\"\n",
    "\n",
    "try:\n",
    "    outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "    aoss_endpoint = outputs['OpenSearchServerlessCollectionEndpoint']\n",
    "    aoss_host = aoss_endpoint.split(\"//\")[1]\n",
    "    print(f\"Amazon OpenSearch Serverless endpoint: {aoss_endpoint}.\")\n",
    "except KeyError:\n",
    "    print(f\"Unable to locate the Amazon OpenSearch Serverless endpoint.  It could be that the stackname {cloudformation_stack_name} was incorrect, or you may need to redeploy the solution from https://github.com/aws-samples/semantic-search-with-amazon-opensearch/tree/generative-ai-powered-search\", file=sys.stderr) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3513aef",
   "metadata": {},
   "source": [
    "Next, let's create an OpenSearch client (a wrapper through opensearch-py) that will connect to our Amazon OpenSearch Serverless endpoint. We will use this client for the remainder of this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb5edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "service = \"aoss\"\n",
    "aws_region = boto3.Session().region_name\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, aws_region, service)\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{\"host\": aoss_host, \"port\": 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b91db9",
   "metadata": {},
   "source": [
    "Let's now create a new index in OpenSearch with the name `10k_financial_raw`. (If you have already created this index previously, go ahead and delete the existing index before creating a new one.)\n",
    "\n",
    "By simply creating an empty index in OpenSearch, the index schema will be dynamically extended as the system encounters new attributes in the data being indexed. This allows for flexible handling of the varying content found in the 10-K financial reports. See [Dynamic Mapping in Mappings and fields, in the OpenSearch documentation](https://docs.opensearch.org/docs/latest/field-types/#dynamic-mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c28384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_index_name=\"10k_financial_raw\"\n",
    "\n",
    "try:\n",
    "    aos_client.indices.get(index=raw_index_name)\n",
    "    # The index already exists, delete it\n",
    "    print(\"Deleting existing index before creating new one.\")\n",
    "    aos_client.indices.delete(index=raw_index_name)\n",
    "except Exception as e:\n",
    "    print(\"Index does not currently exist.\")\n",
    "    \n",
    "aos_client.indices.create(index=raw_index_name,ignore=400)\n",
    "print(\"Index created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8de9d0",
   "metadata": {},
   "source": [
    "Now we will load the JSON versions of the 10-K financial reports into the index we just created. To add multiple documents to the index efficiently, we will use OpenSearch's Bulk API. This allows us to send a single request to OpenSearch containing batches of documents we want to index, rather than sending them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fad94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the directory path to where we unziped/extracted the 10-K filings\n",
    "directory_path =  \"extracted\"\n",
    "batch_size = 50\n",
    "# Initialize a list to store the documents\n",
    "documents = []\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "    # Read the file contents\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "        docJSON = json.loads(file_contents)\n",
    "        docJSON[\"_index\"] = raw_index_name\n",
    "        documents.append(docJSON)\n",
    "    \n",
    "    # If the batch size is reached, index the documents\n",
    "    if len(documents) == batch_size:\n",
    "        aos_response= helpers.bulk(aos_client, documents)\n",
    "        print(f\"Indexed {len(documents)} documents in a batch.\")\n",
    "        documents = []\n",
    "\n",
    "# Index the remaining documents\n",
    "if documents:\n",
    "    aos_response= helpers.bulk(aos_client, documents)\n",
    "    print(f\"Indexed {len(documents)} additional documents.\")\n",
    "\n",
    "print(\"Done loading SEC 10-K filing documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53e5f5",
   "metadata": {},
   "source": [
    "We can check the total number of documents that have been indexed into our OpenSearch index by performing a search across all the documents.\n",
    "\n",
    ">We should wait 1-2 minutes before checking the document count to allow time for the OpenSearch shards to fully refresh and provide a consistent result. This ensures we get an accurate count of the documents that have been successfully indexed.\n",
    "\n",
    "We will print out the number of hits, or matching documents, from the OpenSearch response:\n",
    "```JSON\n",
    "{\n",
    "  \"hits\": {\n",
    "    \"total\": {\n",
    "      \"value\": 191,\n",
    "      \"relation\": \"eq\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc36ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = aos_client.search(index=raw_index_name, body={\"size\": 0, \"query\": { \"match_all\": {}}})\n",
    "\n",
    "print(\"Search matching all returned %d documents.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131f864",
   "metadata": {},
   "source": [
    "## Part 2: A different appoach to search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1007fa",
   "metadata": {},
   "source": [
    "### 2.1 Keyword search\n",
    "---\n",
    "Keyword search is a technique for finding information within a large body of textual data. The user provides a \"query\" - a term or set of words they are looking for. The search engine then uses various methods to analyze the text and identify the relevant information.\n",
    "\n",
    "The process involves tokenization, where the text is split into individual words or \"tokens\". The search engine then scores the results based on factors like:\n",
    "\n",
    "- How many times the search term appears in each document\n",
    "- How common the search term is across the entire dataset\n",
    "- The proximity of the search terms within the document\n",
    "\n",
    "With this data, the search engine can handle \"fuzzy\" matches. This allows users to search using phonetically similar terms or words that are misspelled, and still find the relevant information.\n",
    "\n",
    "The keyword search performs well for exact matches as well. Overall, it provides a flexible way for users to find the information they are looking for within a large amount of textual data.\n",
    "\n",
    "Let's search through our collection of business filing data to find companies that are located in the state of Illinois (`state_location.keyword` = \"IL\"), by constructing an OpenSearch query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\"],\n",
    "    \"query\": {\n",
    "        \"bool\" :{\n",
    "            \"filter\" : [{\n",
    "                    \"match\" :{\n",
    "                        \"state_location.keyword\" : \"IL\"\n",
    "                    }\n",
    "                }]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4a6d2a-1487-4f5c-9307-1417c75edf16",
   "metadata": {
    "tags": []
   },
   "source": [
    " #### Query breakdown\n",
    "\n",
    "- `_source`: This specifies the fields that should be returned in the search results. In this case, it will return the \"company\", \"filing_date\", and \"state_location\" fields.\n",
    "- `query`: This defines the actual search query.\n",
    "- `bool`: This is a [compound query](https://docs.opensearch.org/docs/latest/query-dsl/compound/index/) that combines multiple individual queries. In this case, it's using a \"filter\" to narrow down the results.\n",
    "- `filter`: This applies an additional [filter](https://docs.opensearch.org/docs/latest/search-plugins/filter-search/) to the results. It will only return documents that match the criteria defined in the filter.\n",
    "- `match`: This is a type of query that looks for documents where the specified field matches the given value.\n",
    "- `state_location.keyword`: This refers to the \"keyword\" version of the \"state_location\" field. OpenSearch has both \"text\" and \"keyword\" field types, and the \"keyword\" type is often used for exact matches. See [Keyword Search in the OpenSearch documentation](https://docs.opensearch.org/docs/latest/search-plugins/keyword-search/) for details.\n",
    "\n",
    ">It is worth noting that we are using a relatively inexpensive query, avoiding more expensive types like `fuzzy`, `prefix`, `range`, `regexp`, `wildcard` or `query_string` because the two-letter state abbreviations should be well-constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0298491-3e6b-47e2-a56b-53fc3605508b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = aos_client.search(index=raw_index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df[[\"company\",\"filing_date\",\"state_location\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89ec2a",
   "metadata": {},
   "source": [
    "> We are using the Pandas DataFrame object to make the results from our OpenSearch query more easily viewable and manageable within the Jupyter Notebook environment. This technique is commonly used when working with large datasets retrieved from OpenSearch, as it allows for more convenient manipulation and analysis of the data using Python.\n",
    "\n",
    "In addition, we can perform a search that spans multiple fields, and have the search engine highlight the matching parts within the results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\", \"item_1\"],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\" :[\n",
    "                {\n",
    "                    \"multi_match\" :{\n",
    "                        \"query\" : \"travel\",\n",
    "                        \"fields\" :[\"item_1\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bc8e2f-a3c0-4e75-b8bc-693c006dc3a0",
   "metadata": {},
   "source": [
    "#### Query breakdown\n",
    "\n",
    "- `bool`: For our compound query, this time we will use \"must\" clause, which means all the conditions inside it must be met, and\n",
    "- `multi_match`: This is a type of query that looks for matches across multiple fields. In this case, it's searching for the term \"travel\" in the \"item_1\" field, which in the SEC 10-K filing is the \"Business\" section which gives investors and regulators an overview of the company's core business operations, competitive landscape, and any significant regulatory or operational factors that could impact the business. Also notice that \"item_1\" has been added to our `_source` as well.\n",
    "- `highlight`: This section specifies how the search results should be highlighted.\n",
    "  - `pre_tags` and `post_tags`: These define the HTML tags that will be used to wrap the highlighted text, in this case, `<em>` and `</em>`.\n",
    "  - `fields`: This specifies which fields should be highlighted. In this case, it's just the \"item_1\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=raw_index_name, body=query)\n",
    "query_result=[]\n",
    "print(\"Search returned %d documents.\" % res['hits']['total']['value'])\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location'],hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "HTML(query_result_df[[\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"]].rename(columns={\"company\": \"Company\", \"filing_date\":\"Filing Date\",\"item_1_highlight\":\"10-K Form Item 1 with Highlighted term 'travel'\"}).to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfeb69",
   "metadata": {},
   "source": [
    ">Note: For the sake of clarity, I have taken the liberty to rename some of the column names in the search results. This is to make the information more easily understandable.\n",
    "\n",
    "We can also perform a phrase match, where the search terms must appear together in the specific order that we provide. In this case, we are looking for companies that mention the phrase \"machine learning\" in their business description or narrative.\n",
    "\n",
    "We can add additional filters to further narrow down the search results. For example, we could filter the results to only include companies that are located in the state of California. An example of this type of filtered search is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\", \"item_1\"],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\" :[\n",
    "                {\n",
    "                    \"match_phrase\" :{\n",
    "                        \"item_1\" : \"machine learning\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"filter\" :[\n",
    "                {\n",
    "                    \"term\": {\n",
    "                        \"state_location.keyword\" : \"CA\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=raw_index_name, body=query)\n",
    "query_result=[]\n",
    "print(\"Search returned %d documents.\" % res['hits']['total']['value'])\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location'],hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "HTML(query_result_df[[\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"]].rename(columns={\"company\": \"Company Name\",\"filing_date\":\"Filing Date\",\"state_location\":\"State\",\"item_1_highlight\":\"10-K Form Item 1 with Highlighted Terms\"}).to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2447c",
   "metadata": {},
   "source": [
    "The full text search functionality works well with structured data, providing features like fuzzy matching, typo tolerance, and proximity searching. It can also highlight the matching text in the search results.\n",
    "\n",
    "However, when searching unstructured natural language data, a pure keyword-based search approach may not always yield the most relevant results. It can sometimes return a long tail of less relevant documents.\n",
    "\n",
    "Let's run the query and examine the search results. We will likely see that some irrelevant documents get returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba47370",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What are the operating expenses of Adobe?\"\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_1\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_*\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=raw_index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['item_1'], hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"item_1\",\"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "HTML(query_result_df[[\"_score\",\"company\", \"item_1_highlight\"]].rename(columns={\"_score\": \"Relevance Score\",\"company\":\"Company Name\",\"item_1_highlight\":\"10-K Form Item 1 with Highlighted Terms\"}).to_html(escape=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeca9e9",
   "metadata": {},
   "source": [
    "Run the query and check the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets execute another query example\n",
    "query_text=\"What is Adobe's main revenue source?\"\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_1\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=raw_index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['item_1'], hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"item_1\",\"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "HTML(query_result_df[[\"_score\",\"company\", \"item_1_highlight\"]].rename(columns={\"_score\": \"Relevance Score\",\"company\":\"Company Name\",\"item_1_highlight\":\"10-K Form Item 1 with Highlighted Terms\"}).to_html(escape=False))\n",
    "\n",
    "# you should notice a few results not relevant to the query!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407471f",
   "metadata": {},
   "source": [
    "The search results you see here are generated using term statistics and ranking functions. These techniques estimate the relevance of each document based on probabilistic retrieval frameworks applied across the large text dataset we are searching.\n",
    "\n",
    "![Keyword Search](./static/keyword-search-flow.drawio.svg)\n",
    "\n",
    "The irrelevant results we're seeing from our more natural language-based queries provide a good opportunity to explore the benefits of vector or semantic search approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019cb4a",
   "metadata": {},
   "source": [
    "### 2.2 Vector/Semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895095ec",
   "metadata": {},
   "source": [
    "---\n",
    "In a vector search approach, both the documents and the search queries are represented as high-dimensional numerical vectors, rather than just as raw text strings.\n",
    "\n",
    "The underlying principle behind vector search is that semantically similar documents or queries can be mapped to vectors that are positioned close together within the vector space. This is the case even if the actual textual content of the documents and queries doesn't have much lexical (word-level) overlap.\n",
    "\n",
    "Here's a bit more detail on how vector search works:\n",
    "\n",
    "1. Document Indexing\n",
    "  - The search engine takes the text content of each document and converts it into a high-dimensional vector.\n",
    "  - This vector representation encodes the semantic meaning of the document's content, based on techniques like word embeddings.\n",
    "  - The vector for each document is then stored in the search index.\n",
    "  \n",
    "2. Query Formulation\n",
    "  - When a user submits a search query, the search engine converts that query text into a vector as well.\n",
    "  - The query vector represents the semantic meaning that the user is searching for.\n",
    "\n",
    "3. Relevance Ranking\n",
    "  - The search engine compares the query vector to all the document vectors in the index.\n",
    "  - It calculates the \"distance\" or similarity between the query vector and each document vector.\n",
    "  - Documents with vectors that are closer (more similar) to the query vector are ranked as more relevant.\n",
    "  \n",
    "4. Result Retrieval\n",
    "  - The search engine returns the most relevant documents, based on the vector similarity scores.\n",
    "  - Even if the query terms don't exactly match the document text, semantically similar documents can still be surfaced.\n",
    "\n",
    "\n",
    "The key advantage of vector search is its ability to uncover semantically relevant content that would be missed by traditional text-based keyword searches. This makes vector search particularly useful for tasks like question answering, e-commerce product search, and finding similar documents or images.\n",
    "\n",
    "The vector search approach relies on underlying machine learning models that need to be trained on large datasets. However, this investment upfront can pay off by significantly improving the quality and relevance of the search results, compared to search methods that only look for exact lexical (word-level) matches.\n",
    "\n",
    "![Semantic Search](./static/semantic-search-flow.drawio.svg)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![Semantic Search Architecture](./static/semantic-search-architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf9a5d",
   "metadata": {},
   "source": [
    "**Embeddings** are numerical representations of data, typically used to convert complex, high-dimensional data into a lower-dimensional space where similar data points are closer together. In the context of natural language processing (NLP), embeddings are used to represent words, phrases, or sentences as vectors of real numbers. These vectors capture semantic relationships, meaning that words with similar meanings are represented by vectors that are close together in the embedding space.\n",
    "\n",
    "**Embedding models** are machine learning models that are trained to create these numerical representations. They learn to encode various types of data into embeddings that capture the essential characteristics and relationships within the data. For example, in NLP, embedding models like Word2Vec, GloVe, and BERT are trained on large text corpora to produce word embeddings. These embeddings can then be used for various downstream tasks, such as text classification, sentiment analysis, or machine translation. In this case we'll be using it for semantic similarity.\n",
    "\n",
    "We utilize an embedding model to convert the user's questions into a vector representation. We then use the vector similarity between the question vector and the vectors representing the 10-K data to identify semantically similar content: \n",
    "\n",
    "<!-- ![Convert Text to Vector](./static/text2vector.png) -->\n",
    "\n",
    "---\n",
    "\n",
    "![opensearch vector store](./static/opensearch-vector-store.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the JSON files\n",
    "folder_path = \"extracted\"\n",
    "\n",
    "# Initialize an empty list to store list of company 10-K filing file names\n",
    "company_filing_file_name_list = []\n",
    "\n",
    "#For this session, we only ingest few company information.\n",
    "company_list=[\"Zoom Video Communications, Inc.\",\n",
    "              \"MICROSTRATEGY Inc\", \n",
    "              \"PagerDuty, Inc\", \n",
    "              \"Unity Software Inc.\", \n",
    "              \"Autodesk, Inc.\",\n",
    "              \"ADOBE INC.\",\n",
    "              \"DOCUSIGN, INC.\",\n",
    "              \"Okta, Inc.\",\n",
    "              \"Datadog, Inc.\",\n",
    "              \"INTUIT INC\",\n",
    "              \"AUTOMATIC DATA PROCESSING INC\",\n",
    "              \"SALESFORCE.COM, INC.\", \n",
    "              \"BOX INC\",\n",
    "              \"Asana, Inc\", \n",
    "              \"Palantir Technologies Inc.\"\n",
    "             ]\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.DataFrame([pd.read_json(file_path,typ='series')])\n",
    "        if df.iloc[0]['company'] in company_list:\n",
    "            company_filing_file_name_list.append(file_path)\n",
    "            print(f\"Using file {file_path} for company {df.iloc[0]['company']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a09018-122b-4132-85f6-9e7f5ad706e7",
   "metadata": {},
   "source": [
    "#### Prepare to use the Amazon Titan embeddings model within Amazon Bedrock\n",
    "Before proceeding, it's important to verify that you have requested and been granted access to the Titan Text Embeddings V2 model (or an alternative model, if you have chosen to use a different one). If you do not have the necessary access permissions, you will likely encounter an error when attempting to ingest the data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc400238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=f\"https://bedrock-runtime.{aws_region}.amazonaws.com\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v2:0',client=boto3_bedrock)\n",
    "#bedrock_embeddings = BedrockEmbeddings(model_id='cohere.embed-multilingual-v3',client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb772",
   "metadata": {},
   "source": [
    "### Create a index in Amazon OpenSearch Service collection\n",
    "\n",
    "The [OpenSearch k-NN (k-nearest neighbors) plugin](https://docs.opensearch.org/docs/latest/field-types/supported-field-types/knn-vector/) introduces a custom data type called 'knn_vector'. This allows users to ingest their k-NN vector representations into an OpenSearch index. Once the vectors are indexed, the plugin enables users to perform various types of k-NN search operations on the data. \n",
    "\n",
    "<!-- ---\n",
    "#### OpenSearch Approximate Nearest Neighbor Algorithms and Engines\n",
    "![ANN algorithm](./static/ann-algorithm.png)\n",
    "\n",
    "--- -->\n",
    "\n",
    "<!-- #### HNSW parameter tuning\n",
    "![hnsw parameter tuning](./static/hnsw-parameter-tuning.png) -->\n",
    "\n",
    "<!-- ---\n",
    "\n",
    "#### IVF parameter tuning\n",
    "![ivf parameter tuning](./static/ivf-parameter-tuning.png)\n",
    "\n",
    "#### How to select the engine and algorithms\n",
    "![opensearch ann comparison](./static/opensearch-ann-selection.png)  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"item_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024\n",
    "            },\n",
    "            \"item_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9e09e",
   "metadata": {},
   "source": [
    "#### Index mapping for k-NN breakdown\n",
    "\n",
    "- `settings`: This section defines the index-level settings.\n",
    "  - \"index.knn\": This setting is set to **True**, which enables the k-NN functionality for this index.\n",
    "- `mappings`: This section defines the field mappings for the index.\n",
    "  - `properties`: This defines the individual fields and their configurations.\n",
    "    - \"item_vector\": This is a field that will store the k-NN vector representations.\n",
    "      - `type`: The field type is set to `knn_vector`, which is a custom data type introduced by the OpenSearch k-NN plugin.\n",
    "      - `dimension`: The vector dimension is set to **1024**, meaning each vector will have 1024 elements.\n",
    "    - \"item_content\": This is a text field that will store the actual content of the items.\n",
    "      - `type`: The field type is set to `text`.\n",
    "      - `store`: This is set to **True**, which means the field content will be stored and can be retrieved.\n",
    "    - \"company_name\": This is another text field that will store the company name.\n",
    "      - `type`: The field type is set to `text`.\n",
    "      - `store`: This is also set to **True**, allowing the company name to be retrieved.\n",
    "\n",
    "Using the above index definition, we can now create the index in Amazon OpenSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60657cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_name=\"10k_financial_semantic\"\n",
    "\n",
    "try:\n",
    "    aos_client.indices.get(index=vector_index_name)\n",
    "    # The index already exists, delete it\n",
    "    print(\"Deleting existing index before creating new one.\")\n",
    "    aos_client.indices.delete(index=vector_index_name)\n",
    "except Exception as e:\n",
    "    print(\"Index does not currently exist.\")\n",
    "    \n",
    "aos_client.indices.create(index=vector_index_name,body=knn_index,ignore=400)\n",
    "print(\"Index created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7736b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_name=\"10k_financial_semantic\"\n",
    "print(json.dumps(aos_client.indices.get(index=vector_index_name), indent=4))\n",
    "# you can verify the mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9f03",
   "metadata": {},
   "source": [
    "###  Load the raw data into the Index\n",
    "Over the next few cells we will load the raw data into the index we have just created.\n",
    "\n",
    "We start by creating a pandas DataFrame loader helper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasDataFrameLoader(BaseLoader):\n",
    "    \n",
    "    def __init__(self,dataframe:pd.DataFrame):\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        items=[\"item_1\",\"item_1A\",\"item_1B\",\"item_2\",\"item_3\",\"item_4\",\"item_5\",\"item_6\",\"item_7\",\"item_7A\",\"item_8\",\"item_9\",\"item_9A\", \"item_9B\", \"item_10\", \"item_11\", \"item_12\", \"item_13\", \"item_14\", \"item_15\"]\n",
    "        \n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            metadata={}\n",
    "            # you can use as many metadata possible\n",
    "            metadata[\"cik\"]=row['cik']\n",
    "            metadata[\"company_name\"]=row['company']\n",
    "            metadata[\"filing_date\"]=row['filing_date']\n",
    "            for item in items:\n",
    "                content=row[item]\n",
    "                metadata['item'] = item\n",
    "                doc = Document(page_content=content,metadata=metadata)\n",
    "                docs.append(doc)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dcbea",
   "metadata": {},
   "source": [
    "We will then create a function that does the following for each company of interest:\n",
    "- uses `RecursiveCharacterTextSplitter` to split documents into 8,000 character chunks, with a 200 character overlap between each chunk. The `chunk_size` parameter sets the maximum size (in characters) for each text chunk; `chunk_overlap` specifies the number of characters that should overlap between adjacent chunks. This helps ensure that context is preserved across chunk boundaries.\n",
    "- sends the \"splitted\" documents to Bedrock to develop into a vector\n",
    "- add the company name, documents and the vector to the index using an OpenSearch Bulk operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_downloaded_10k_into_opensearch(file_name, index_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    \n",
    "    ## call this out\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    item_contents=[]\n",
    "    company_name=splitted_documents[0].metadata['company_name']\n",
    "    for doc in splitted_documents:\n",
    "        item_contents.append(doc.page_content)\n",
    "    \n",
    "    print(\"\\nFor company \" + company_name + \" ingested \" + str(len(item_contents)) + \" items into Bedrock.\")\n",
    "    start = time.time()\n",
    "    embedding_results = bedrock_embeddings.embed_documents(item_contents)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(f\"Time elapsed for Bedrock embedding: {elapsed:.2f} seconds\")\n",
    "        \n",
    "    data = []\n",
    "    i=0\n",
    "    for content in item_contents:\n",
    "        data.append({\"_index\": index_name,  \"company_name\": company_name, \"item_content\":content, \"item_vector\":embedding_results[i]})\n",
    "        i = i+1\n",
    "    aos_response= helpers.bulk(aos_client, data)\n",
    "    print(f\"Bulk-inserted {aos_response[0]} items into the OpenSearch index with the Bedrock embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b893cf9c-3e22-4b80-9f72-b316502f2416",
   "metadata": {},
   "source": [
    "Now we iterate through our companies of interest array (`company_filing_file_name_list`) and process them through our function and class we've created.  This will result in the index being loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e516be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data in to OpenSearch Serverless collection. Note: This would take some time to complete\n",
    "for file in company_filing_file_name_list:\n",
    "    ingest_downloaded_10k_into_opensearch(file, vector_index_name)\n",
    "    print(\"Ingested file:\" + file)\n",
    "print(\"**Completed ingesting 10-K Form filing data.**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee126626",
   "metadata": {},
   "source": [
    "To validate the load, you can query the number of documents in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=vector_index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Search matching all returned %d documents.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b37d4f-c7a2-4888-a865-600e6e0e9d0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "It may be of some interest to see an example of what a single 10-K Form document looks like within the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5106147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(res['hits']['hits'][1]['_source'], indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616a737-01ee-4ef1-8773-b0e4d5c5329b",
   "metadata": {},
   "source": [
    "Now that we have set up the vector search system, let's repeat the same queries we used previously. This will allow us to assess whether the new approach has improved the relevance of the search results, compared to the irrelevant results we encountered before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the same query as before...\n",
    "query_text=\"What are the operating expenses of Adobe?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3e613",
   "metadata": {},
   "source": [
    "Run the query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cb43b-e710-4e26-9b13-1d2d848fbba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=vector_index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df[[\"_score\",\"company_name\",\"item_content\"]].rename(columns={\"_score\":\"Relevance score\", \"company_name\":\"Company name\", \"item_content\":\"Operating expenses?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1070e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now the other low-performing query...\n",
    "query_text=\"What is Adobe's main revenue?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e3fd3",
   "metadata": {},
   "source": [
    "Run the next query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=vector_index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df[[\"_score\",\"company_name\",\"item_content\"]].rename(columns={\"_score\":\"Relevance score\", \"company_name\":\"Company name\", \"item_content\":\"Main revenue?\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d6347",
   "metadata": {},
   "source": [
    "### 2.3 Retrieval Augmented Generation(RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cb878",
   "metadata": {},
   "source": [
    "You can leverage Large Language Models to directly generate answers for the user, rather than just returning the retrieved documents. By using the relevant documents as context when generating the answers, this approach can help minimize the risk of the model 'hallucinating' or fabricating information.\n",
    "\n",
    "This method is known as Retrieval Augmented Generation, or RAG for short. In RAG, the external data used to generate the answers can come from a variety of sources, such as document repositories, databases, or APIs.\n",
    "\n",
    "The first step in this process is to convert both the documents and the user's query into a format that allows for effective comparison and relevancy search. This is achieved by transforming the document collection (the 'knowledge library') and the user-submitted query into numerical vector representations using embedding language models. These vector embeddings numerically encode the semantic concepts present in the text.\n",
    "\n",
    "Next, based on the embedding of the user query, relevant text is identified in the document collection through similarity search in the embedding space. The prompt provided by the user is then combined with the searched relevant text and added to the context. This updated prompt, which includes relevant external data along with the original prompt, is sent to the LLM (Language Model) for processing. As a result, the model output becomes relevant and accurate due to the context containing the relevant external data.\n",
    "\n",
    "The major components of RAG, including embedding, vector databases, augmentation, and generation:\n",
    "\n",
    "- **Embedding**: Purpose: Embeddings transform text data into numerical vectors in a high-dimensional space. These vectors represent the semantic meaning of the text. Process: The embedding process typically uses pre-trained models (like BERT or a variant) to convert both the input queries and the documents in the database into dense vectors. Role in RAG: Embeddings are crucial for the retrieval component as they allow the model to compute the similarity between the query and the documents in the database efficiently.\n",
    "- **Vector Database**: Function: A vector database stores the embeddings of a large collection of documents or passages. Construction: It is created by processing a vast corpus (like Wikipedia or other specialized datasets) through an embedding model. Usage in RAG: When a query comes in, the model searches this database to find the documents whose embeddings are most similar to the embedding of the query.\n",
    "- **Retrieval (Augmentation)**: Mechanism: The retrieval part of RAG functions by taking the input query, converting it into a vector using embeddings, and then searching the vector database to retrieve relevant documents. Result: It augments the original query with additional context by selecting documents or passages that are semantically related to the query. This augmented information is essential for generating more informed responses.\n",
    "- **Generation**: Integration with a Language Model: The generative component, often a large language model like Amazon Titan Text, receives both the original query and the retrieved documents. Response Generation: It synthesizes information from these inputs to produce a coherent and contextually appropriate response. \n",
    "- **Training and Fine-Tuning**: This component is generally pre-trained on vast amounts of text and may be further fine-tuned to optimize its performance for specific tasks or datasets.\n",
    "- **End-to-End Training (Optional)**: Joint Optimization: In RAG, both retrieval and generation components can be fine-tuned together, allowing the system to optimize the selection of documents and the generation of responses simultaneously. Feedback Loop: The model learns not only to generate relevant responses but also to retrieve the most useful documents for any given query.\n",
    "\n",
    "---\n",
    "### Architecture\n",
    "\n",
    "![RAG](./static/RAG_Architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_index_name=\"10k_financial_embedding\"\n",
    "\n",
    "try:\n",
    "    aos_client.indices.get(index=langchain_index_name)\n",
    "    # The index already exists, delete it\n",
    "    print(\"Deleting existing index before creating new one.\")\n",
    "    aos_client.indices.delete(index=langchain_index_name)\n",
    "except Exception as e:\n",
    "    print(\"Index does not currently exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f5be25-7870-4447-a748-038591af4286",
   "metadata": {},
   "source": [
    "We will need a new [LangChain](https://python.langchain.com/api_reference/index.html) version of our ingestion function:\n",
    "- as before, we will use [`RecursiveCharacterTextSplitter`](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html) with the same parameters before\n",
    "- this time, however, we will use LangChain's [`OpenSearchVectorSearch`](https://python.langchain.com/docs/integrations/vectorstores/opensearch/) class. This allows the LangChain application to perform advanced vector-based searches on the indexed data, rather than relying solely on keyword-based searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, aws_region, service, session_token=credentials.token)\n",
    "\n",
    "def ingest_10k_into_opensearch_with_langchain(file_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    OpenSearchVectorSearch.from_documents(\n",
    "                index_name = langchain_index_name,\n",
    "                documents=splitted_documents,\n",
    "                embedding=bedrock_embeddings,\n",
    "                opensearch_url=aoss_endpoint,\n",
    "                http_auth=awsauth,\n",
    "                timeout=600,\n",
    "                use_ssl=True,\n",
    "                verify_certs=True,\n",
    "                connection_class=RequestsHttpConnection,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a18ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this step, we're indexing the selected companies 10K files in to Amazon OpenSearch Serverless with LangChain\n",
    "## This will take a little while to load all the chunks\n",
    "\n",
    "for file in company_filing_file_name_list:\n",
    "    ingest_10k_into_opensearch_with_langchain(file)\n",
    "    print(\"Ingested file \" + file)\n",
    "print(\"Finished ingesting files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c77644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our index\n",
    "print(json.dumps(aos_client.indices.get(index=langchain_index_name), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3579f5-8bf0-4fcb-aa01-61795b0f5330",
   "metadata": {},
   "source": [
    "We will create another `OpenSearchVectorSearch`, this time for Bedrock's use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb70ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_search_vector_store = OpenSearchVectorSearch(\n",
    "                                    index_name=langchain_index_name,\n",
    "                                    embedding_function=bedrock_embeddings,\n",
    "                                    opensearch_url=os_domain_ep,\n",
    "                                    http_auth=awsauth,\n",
    "                                    timeout=600,\n",
    "                                    use_ssl=True,\n",
    "                                    verify_certs=True,\n",
    "                                    connection_class=RequestsHttpConnection,\n",
    "                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981fa91",
   "metadata": {},
   "source": [
    "Initialize Bedrock LLM model with Claude, and set our parameters (see [Influence response generation with inference parameters in the Amazon Bedrock User's Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/inference-parameters.html)):\n",
    "- `temperature`: 0.001: The ***temperature*** parameter controls the randomness or diversity of the model's generated output. A lower temperature value (e.g., 0.001) results in the model generating more \"safe\" and conservative output, with less variation. This is often useful when you want the model to produce more focused and coherent responses.\n",
    "\n",
    "- `top_k`: 300: The ***top-k*** parameter limits the number of most likely tokens that the model considers when generating the next token in the sequence. Setting this to a higher value (e.g., 300) allows the model to consider a wider range of possible next tokens, potentially leading to more diverse output.\n",
    "\n",
    "- `top_p`: 1: The ***top-p*** (or \"nucleus sampling\") parameter is a complementary technique to **top-k** sampling. It sets a threshold for the cumulative probability of the most likely tokens, rather than a fixed number. A value of 1 means the model will consider all possible tokens, without any additional filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\", client=boto3_bedrock)\n",
    "bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=boto3_bedrock)\n",
    "#bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-opus-20240229-v1:0\", client=boto3_bedrock)\n",
    "\n",
    "bedrock_llm.model_kwargs = {\"temperature\":0.001,\"top_k\":300,\"top_p\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212b804",
   "metadata": {},
   "source": [
    ">Note: This prompt has been designed specifically for the [Anthropic Claude 3](https://aws.amazon.com/bedrock/anthropic/) language model. If you use a different large language model, the output results may vary. For example, the guardrails or safeguards customized for your application's requirements and responsible AI policies may have an impact on the model's responses.\n",
    "\n",
    "We will create a [Retriever](https://python.langchain.com/docs/concepts/retrievers/), which is a component in the LangChain library used for retrieving relevant documents (in this case, from OpenSearch).  We will direct the Retriever to return documents based on a minimum similarity score threshold, rather than a fixed number of top-k results with `search_type=\"similarity_score_threshold\"`; as well as limit the number of returned documents to five (`'k': 5` in the `search_kwargs`, and keep the similarity threshold to 0.005.\n",
    "\n",
    "The key purpose of this configuration is to ensure that the Retriever returns semantically relevant documents, rather than just returning the top-k results based on a simple ranking. By using a similarity score threshold, the Retriever will only return documents that meet a minimum relevance bar.\n",
    "\n",
    "We'll also create a [RetrievalQA](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html), a component used for question-answering tasks that leverages a combination of a language model and a retriever from the LangChain library. It can then be used to perform question-answering tasks, where it will:\n",
    "- Use the `bedrock_retriever` to fetch the most relevant documents based on the input question.\n",
    "- Pass those retrieved documents, along with the question, to the `bedrock_llm` language model.\n",
    "- Generate an answer based on the combination of the retrieved documents and the language model's capabilities.\n",
    "\n",
    ">Note: we are using the \"stuff\" `chain_type`, which simply feeds the retrieved documents directly into the LLM for question-answering.  Other options are: \n",
    "> - \"refine\": the initial set of relevant documents is retrieved using the provided retriever, and the LLM generates an initial answer based on the retrieved documents. It then analyzes the quality of the initial answer and identifies gaps or areas that need further refinement, for which additional relevant documents are retrieved to address the identified gaps. The LLM then refines the answer based on the additional documents. This process of answer generation, quality analysis, and document retrieval/refinement can iterate multiple times until a satisfactory answer is produced.\n",
    "> - \"map_reduce\": summarize each document on its own in a \"map\" step and then \"reduce\" the summaries into a final summary\n",
    "> - \"map_rerank\": split the input text into smaller, more manageable document chunks; then generate a score or relevance metric for each document chunk. The document chunks are ranked based on their scores, and the document chunk with the maximum (i.e., highest) score is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_retriever = open_search_vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",  ## ensure we return semantically relevant / instead of top_K\n",
    "    search_kwargs={\n",
    "        'k': 5,\n",
    "        'score_threshold': 0.005\n",
    "    }\n",
    ")\n",
    "rag_qa = RetrievalQA.from_chain_type(\n",
    "    llm=bedrock_llm,\n",
    "    retriever=bedrock_retriever,\n",
    "    chain_type=\"stuff\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e7c07-8a5a-431f-96ec-3eb27b5acf32",
   "metadata": {},
   "source": [
    "Let's re-ask our revenue question, and see if we have improved the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is Adobe's main revenue??\"\n",
    "\n",
    "langchain.debug=False #switch to see debug information tracing development of result\n",
    "result = rag_qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c951931d-0ab6-4511-86b2-ae760dc9c027",
   "metadata": {},
   "source": [
    "Let's examine the output from the LangChain processing to see if we have generated a coherent and human-readable result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_result = result[\"result\"].replace(\"$\",\"\\\\\\$\")\n",
    "display(Markdown(\"### Result\\n\" + rag_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17745b8f",
   "metadata": {},
   "source": [
    "### Standard RAG limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f076f000",
   "metadata": {},
   "source": [
    "The standard Retrieval Augmented Generation (RAG) approach can be used for comparison questions between documents, but it has some notable limitations:\n",
    "- Comparison-Specific Capabilities: RAG models are not specifically designed for comparison tasks and may lack the specialized capabilities required to generate high-quality comparative outputs. This includes the ability to identify and highlight the most relevant comparison points between the documents.\n",
    "- Efficiency and Effectiveness: Due to the lack of targeted comparison capabilities, standard RAG models may not be the most efficient or effective approach for these types of tasks. Other techniques, such as multi-document summarization or question-answering systems, may be better suited.\n",
    "\n",
    "Here are some example use cases that illustrate the limitations of standard RAG for comparison questions:\n",
    "##### Comparison Questions:\n",
    "- \"Compare the financial statements of Adobe and Autodesk.\"\n",
    "    - The RAG model would first need to retrieve the relevant financial statements for each company using semantic search.\n",
    "    - It would then need to extract the key comparison points from the financial data and generate a coherent comparative analysis, which may be challenging without specialized comparison capabilities.\n",
    "\n",
    "##### Out-of-Knowledge-Base Information:\n",
    "- \"Is Adobe a good investment choice right now?\"\n",
    "    - To answer this question, the RAG model would be limited to the information available in its knowledge base, which may not include the most up-to-date financial data or other relevant details needed to make an investment recommendation.\n",
    "    - Additional information from external sources, such as a relational database or data warehouse, would be required to provide a more comprehensive and informed response.\n",
    "\n",
    "##### Out-of-Date Knowledge Base:\n",
    "- \"Is Amazon a good investment choice right now?\"\n",
    "    - If the RAG model's knowledge base does not contain the latest financial statements or other relevant information about Amazon, it may not be able to provide a meaningful response to this question.\n",
    "    - In this case, the model would need to be updated with the latest data, such as by ingesting the most recent 10-K filings from the internet, before it could generate a well-informed response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e0c176",
   "metadata": {},
   "source": [
    "#### Comparision question to standard RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2d891b-e57e-4f61-8232-fd921722d7cd",
   "metadata": {},
   "source": [
    "Let's present our RAG implementation with a comparison question, and see what result we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f77ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Compare Adobe and Asana company financial statements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ef917",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug=False #switch to see debug information tracing development of result\n",
    "result = rag_qa({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_result = result[\"result\"].replace(\"$\",\"\\\\\\$\")\n",
    "display(Markdown(\"### Result\\n\" + rag_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b897c",
   "metadata": {},
   "source": [
    "![standard rag limitation](./static/rag-limitation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524ec42",
   "metadata": {},
   "source": [
    "![advanced rag ](./static/advanced-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419c470d-b5e4-46b1-9b3a-7e65e1c0506e",
   "metadata": {},
   "source": [
    "Yan, Shi-Qi, et al.\n",
    "*Corrective Retrieval Augmented Generation*. 2024\n",
    "https://arxiv.org/pdf/2401.15884\n",
    "\n",
    "Jeong, Soyeong, et al. \n",
    "*Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity*. 2024\n",
    "https://arxiv.org/pdf/2403.14403"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40648cdd",
   "metadata": {},
   "source": [
    "## Part 3: AI agent powered search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a90985",
   "metadata": {},
   "source": [
    "### What is an AI agent ?\n",
    "An agentic model employs a chain-of-thought reasoning process. In this approach, the large language model (LLM) is prompted to think through a question step-by-step, interleaving its reasoning with the ability to use external tools like search engines and APIs. This allows the LLM to retrieve relevant information that can help answer different aspects of the question. Ultimately, this leads to a more comprehensive and accurate final response.\n",
    "\n",
    "This approach is inspired by the \"Reason and Act\" (ReAct) design introduced in the paper [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629). ReAct aims to combine the reasoning capabilities of language models with the ability to interact with external resources and take actions.\n",
    "\n",
    "By combining these two facets - internal reasoning and external interaction - an agentic LLM assistant can provide more informed and well-rounded answers to complex user queries.\n",
    "\n",
    "![agent components](./static/agent-components.png)\n",
    "\n",
    "### Why build an AI agent?\n",
    "In today's digital landscape, enterprises are inundated with a vast array of data sources. These range from traditional PDF documents to complex SQL and NoSQL databases, and everything in between. While this wealth of information holds immense potential for gaining valuable insights and driving operational efficiency, the sheer volume and diversity of data can pose significant challenges in terms of accessibility and utilization.\n",
    "\n",
    "This is where the power of agentic LLM assistants comes into play. By leveraging progress in LLM design patterns such as Reason and Act (ReAct) and other traditional or novel approaches, these intelligent assistants can integrate with an enterprise's diverse data sources. Through the development of specialized tools tailored to each data source, and the ability of LLM agents to identify the right tool for a given question, agentic LLM assistants can simplify how users navigate and extract relevant information, regardless of its origin or structure.\n",
    "\n",
    "This enables a rich, multi-source conversation that promises to unlock the full potential of enterprise data. It can support data-driven decision-making, enhance operational efficiency, and ultimately drive productivity and growth.\n",
    "\n",
    "![agent powered search advantage](./static/agent-powered-search-advantage.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928610e",
   "metadata": {},
   "source": [
    "### AI Agent powered search reference architecture\n",
    "\n",
    "![AI Agent powered search reference architecture](./static/reference-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63eff43",
   "metadata": {},
   "source": [
    "\n",
    "### Lab Architecture\n",
    "\n",
    "For demonstration purposes, we will use an Amazon SageMaker notebook to run the code. The following diagram illustrates the overall architecture of this lab:\n",
    "\n",
    "![AI Agent powered search architecture](./static/architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc1107",
   "metadata": {},
   "source": [
    "\n",
    "### Data Flow\n",
    "\n",
    "The user submits a query (**3** and **4**). The first AI agent will judge if the query is related to financial statements (**4.1**). If so, the AI agent will use vector search to retrieve similar financial statements for the company from an OpenSearch index (**4.2**).\n",
    "\n",
    "If there are no financial statements for the company in the index, the AI agent will download the data from the internet by calling the SEC API, ingest the data into the OpenSearch index (**4.4**), and then perform the search again (**4.2**).\n",
    "\n",
    "If there are related financial statements, the AI agent will check if the query is stock price-related. If so, the AI agent will query a Redshift database to retrieve the company's stock price data (**4.3**).\n",
    "\n",
    "Finally, the large language model (LLM) will generate the response using all the collected data.\n",
    "\n",
    "The overall data flow is as follows:\n",
    "\n",
    "![AI Agent powered search data flow](./static/ai-agent-search-data-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c010",
   "metadata": {},
   "source": [
    "### 3.1 Prepare other tools used by AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcf6e3",
   "metadata": {},
   "source": [
    "#### 3.1.1 Ingest and query structured data in Amazon Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3c50d",
   "metadata": {},
   "source": [
    "To begin, we will retrieve the credentials needed to access the Amazon Redshift Serverless database that was previously created using the CloudFormation stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_serverless_credentials = json.loads(sec.get_secret_value(SecretId=outputs['RedshiftServerlessSecret'])['SecretString'])\n",
    "redshift_serverless_username    = redshift_serverless_credentials['username']\n",
    "redshift_serverless_password    = redshift_serverless_credentials['password']\n",
    "redshift_serverless_endpoint    = outputs['RedshiftServerlessEndpoint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c619",
   "metadata": {},
   "source": [
    "In this part of the workshop, we will:\n",
    "- Connect to the Amazon Redshift Serverless database (\"dev\").\n",
    "- Create a table within the database called `stock_symbol`.\n",
    "- Copy local workshop files into the Amazon S3 bucket that was created earlier using the CloudFormation stack. This simulates a remote source of stock information.\n",
    "- Ingest the data from the S3 bucket into the `stock_symbol` table.\n",
    "- Create a convenience function that can return the stock symbol for a given company name. This will use the SQL case-insensitive LIKE operator to perform the lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();\n",
    "\n",
    "%sql CREATE TABLE IF NOT EXISTS public.stock_symbol (stock_symbol text PRIMARY KEY, company_name text NOT NULL);\n",
    "\n",
    "stock_price_bucket = outputs[\"s3BucketStock\"]\n",
    "s3_location = f's3://{stock_price_bucket}/stock-price/'\n",
    "print(s3_location)\n",
    "!aws s3 sync ./stock-price/ $s3_location\n",
    "\n",
    "stock_symbol_s3_location = f's3://{stock_price_bucket}/stock-price/stock_symbol.csv'\n",
    "\n",
    "quoted_stock_symbol_s3_location = \"'\" + stock_symbol_s3_location + \"'\"\n",
    "\n",
    "%sql COPY STOCK_SYMBOL FROM $quoted_stock_symbol_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "\n",
    "\n",
    "url = URL.create(\n",
    "    drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "    host=redshift_serverless_endpoint, \n",
    "    port=5439,\n",
    "    database='dev',\n",
    "    username=redshift_serverless_username,\n",
    "    password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "engine = sa.create_engine(url)\n",
    "redshift_connection = engine.connect()\n",
    "    \n",
    "def query_stock_ticker(company_name):\n",
    "    strSQL = \"SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%\" + company_name + \"%'\"\n",
    "    stock_ticker = ''\n",
    "    try:\n",
    "        result = redshift_connection.execute(strSQL)\n",
    "        df = pd.DataFrame(result)\n",
    "        stock_ticker=df['stock_symbol'][0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return stock_ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9bcb45-51fb-4262-bd18-22e7fe60fe4f",
   "metadata": {},
   "source": [
    "Next, let's test the convenience function we created and verify that the `stock_symbol` table has been loaded correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34411033",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stock_ticker(\"adobe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5982d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_price (stock_date DATE, stock_symbol text, open_price DECIMAL, high_price DECIMAL, low_price DECIMAL, close_price DECIMAL, adjusted_close_price DECIMAL, volume DECIMAL);\n",
    "\n",
    "asan_s3_location = f's3://{stock_price_bucket}/stock-price/ASAN.csv'\n",
    "quoted_asan_s3_location = \"'\" + asan_s3_location + \"'\"\n",
    "print(quoted_asan_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "crm_s3_location = f's3://{stock_price_bucket}/stock-price/CRM.csv'\n",
    "quoted_crm_s3_location = \"'\" + crm_s3_location + \"'\"\n",
    "print(quoted_crm_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "adp_s3_location = f's3://{stock_price_bucket}/stock-price/ADP.csv'\n",
    "quoted_adp_s3_location = \"'\" + adp_s3_location + \"'\"\n",
    "print(quoted_adp_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "adsk_s3_location = f's3://{stock_price_bucket}/stock-price/ADSK.csv'\n",
    "quoted_adsk_s3_location = \"'\" + adsk_s3_location + \"'\"\n",
    "print(quoted_adsk_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "box_s3_location = f's3://{stock_price_bucket}/stock-price/BOX.csv'\n",
    "quoted_box_s3_location = \"'\" + box_s3_location + \"'\"\n",
    "print(quoted_box_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "adbe_s3_location = f's3://{stock_price_bucket}/stock-price/ADBE.csv'\n",
    "quoted_adbe_s3_location = \"'\" + adbe_s3_location + \"'\"\n",
    "print(quoted_adbe_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "%sql COPY STOCK_PRICE FROM $quoted_asan_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_crm_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_adp_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_adsk_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_box_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_adbe_s3_location iam_role default IGNOREHEADER 1 CSV;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847b60a-3d52-479a-8c65-7db20b2a3fa9",
   "metadata": {},
   "source": [
    "Let's verify that the stock price information has been properly loaded into the `stock_price` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafccbb1-2aec-4a29-a84b-bf4164b533a8",
   "metadata": {},
   "source": [
    "Next, we will create another convenience function. This function will retrieve stock price information for a given ticker symbol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84643882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to assure we are still connected...\n",
    "engine = sa.create_engine(url)\n",
    "redshift_connection = engine.connect()\n",
    "\n",
    "def query_stock_price(stock_ticker):\n",
    "    strSQL = \"SELECT stock_date, stock_symbol, open_price, high_price, low_price, close_price FROM stock_price WHERE stock_symbol='\" + stock_ticker + \"' limit 100\"\n",
    "    try:\n",
    "        result = redshift_connection.execute(strSQL)\n",
    "        stock_price = pd.DataFrame(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return stock_price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e0ad1-6687-4afe-98c6-8ecdd8b00cbf",
   "metadata": {},
   "source": [
    "And we'll test it as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stock_price('ASAN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd10bb",
   "metadata": {},
   "source": [
    "#### 3.1.2 Download SEC 10-K filing from SEC-API.IO\n",
    "---\n",
    "Data2value, a company based in Germany, develops and sells products in the areas of IT-assisted data analysis and business process optimization. Their most notable product is https://sec-api.io, which offers APIs to access various datasets from the U.S. Securities and Exchange Commission (SEC), including the EDGAR Filing Search for 10-K Forms.\n",
    "\n",
    "For this workshop, you will need to create a free account with Data2value to acquire an API key. This API key will be valid for 100 requests at the time of writing.\n",
    "\n",
    "Once you have acquired the API key, we will follow good practice and place it into AWS Secrets Manager:\n",
    "\n",
    "1. In the AWS Management Console, navigate to the **AWS Secrets Manager** service.\n",
    "\n",
    "2. Click on **Store a new secret** to create a new secret.\n",
    "\n",
    "3. Select **Other type of secrets** as the secret type.\n",
    "\n",
    "4. In the **Select the secret type** section, choose **Key/value**.\n",
    "\n",
    "5. In the **Secret key/value** section, enter the name of your secret as the key (e.g., \"API_KEY\") and the actual API key as the value.  You can leave the **Encryption key** as \"aws/secretsmanager\".  Click **Next**.\n",
    "\n",
    "6. Choose a **Secret name** (e.g., \"sec-api.io\") and enter any **Description** you would like. Optionally, you can add tags to the secret for better organization and access control.  We will not need to modify the default for **Resource permissions** or **Replicate secret**.  Click **Next**.\n",
    "\n",
    "7. There will be no need to use the **Configure rotation** section for this workshop, but certainly recommended for security best practices in general (read \"production\"). Click **Next**.\n",
    "\n",
    "8. Review the secret details and click **Store** to save the API Key as a secret.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951ce363-1df8-4089-b28a-e0bf4065e663",
   "metadata": {},
   "source": [
    ">We've already installed the SEC Filing API for Python (`%pip -q install sec-api` in the [Install Python Libraries (and dependencies) for OpenSearch, Redshift and LangChain](#Install-Python-libraries-(and-dependencies)-for-OpenSearch,-Redshift-and-LangChain) section.  The API documentation is available [here](https://sec-api.io/docs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78970fd",
   "metadata": {},
   "source": [
    "Replace the `SecretId` below to the **Secret name** you chose above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624456f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sec_api = json.loads(sec.get_secret_value(SecretId='sec-api.io')['SecretString'])\n",
    "    sec_api_key=sec_api['API_KEY']\n",
    "except sec.exceptions.ResourceNotFoundException:\n",
    "    print(\"Unable to find the stored secret. Check the SecretId and keyname.\",file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d184d64-5801-4651-bbd9-a45ac1f1703c",
   "metadata": {},
   "source": [
    "Next, we will create another convienence function, this time to retrieve the most recent 10-K filing for a given ticker symbol using the SEC API provided by the sec-api.io service.\n",
    "- take a `ticker` parameter, the stock symbol for the company and using the QueryApi (from the sec-api.io API library), search for the most recent 10-K filing. \n",
    "- using the ExtractorApi (also from the sec-api.io) extract metadata about the company filing and store it in a dictionary, such as the filing URL, type, CIK (Central Index Key), name, filing date, period of report, and links to the HTML index and the complete filing text.\n",
    "- convert the dictionary to a JSON string, and save to a file in the `download_filings` directory with a filename of the filing URL (if the `download_filings` directory does not exist, create one!).\n",
    "- then return the filename of the filing for the `ticker`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filings(ticker):\n",
    "    global sec_api_key\n",
    "\n",
    "    # Finding Recent Filings with QueryAPI\n",
    "    queryApi = QueryApi(api_key=sec_api_key)\n",
    "    query = {\n",
    "      \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\"\",\n",
    "      \"from\": \"0\",\n",
    "      \"size\": \"1\",\n",
    "      \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "    }\n",
    "    response = queryApi.get_filings(query)\n",
    "\n",
    "    # Getting 10-K URL\n",
    "    filing_url = response[\"filings\"][0][\"linkToFilingDetails\"]\n",
    "    filing_type=response['filings'][0]['formType']\n",
    "    cik=response['filings'][0]['cik']\n",
    "    company=response['filings'][0]['companyName']\n",
    "    filing_date=response['filings'][0]['filedAt']\n",
    "    period_of_report=response['filings'][0]['periodOfReport']\n",
    "    filing_html_index=response['filings'][0]['linkToFilingDetails']\n",
    "    complete_text_filing_link=response['filings'][0]['linkToTxt']\n",
    "\n",
    "    # Extracting Text with ExtractorAPI\n",
    "    extractorApi = ExtractorApi(api_key=sec_api_key)\n",
    "    \n",
    "    one_text = extractorApi.get_section(filing_url, \"1\", \"text\")       #Section 1 - Business\n",
    "    onea_text = extractorApi.get_section(filing_url, \"1A\", \"text\")     # Section 1A - Risk Factors\n",
    "    oneb_text = extractorApi.get_section(filing_url, \"1B\", \"text\")     # Section 1B - Unresolved Staff Comments\n",
    "    two_text = extractorApi.get_section(filing_url, \"2\", \"text\")       # Section 2 - Properties\n",
    "    three_text = extractorApi.get_section(filing_url, \"3\", \"text\")     # Section 3 - Legal Proceedings\n",
    "    four_text = extractorApi.get_section(filing_url, \"4\", \"text\")      # Section 4 - Mine Safety Disclosures\n",
    "    five_text = extractorApi.get_section(filing_url, \"5\", \"text\")      # Section 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "    six_text = extractorApi.get_section(filing_url, \"6\", \"text\")       # Section 6 - Selected Financial Data (prior to February 2021)\n",
    "    seven_text = extractorApi.get_section(filing_url, \"7\", \"text\")     # Section 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "    sevena_text = extractorApi.get_section(filing_url, \"7A\", \"text\")   # Section 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "    eight_text = extractorApi.get_section(filing_url, \"8\", \"text\")     # Section 8 - Financial Statements and Supplementary Data\n",
    "    nine_text = extractorApi.get_section(filing_url, \"9\", \"text\")      # Section 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "    ninea_text = extractorApi.get_section(filing_url, \"9A\", \"text\")    # Section 9A - Controls and Procedures\n",
    "    nineb_text = extractorApi.get_section(filing_url, \"9B\", \"text\")    # Section 9B - Other Information\n",
    "    ten_text = extractorApi.get_section(filing_url, \"10\", \"text\")      # Section 10 - Directors, Executive Officers and Corporate Governance\n",
    "    eleven_text = extractorApi.get_section(filing_url, \"11\", \"text\")   # Section 11 - Executive Compensation\n",
    "    twelve_text = extractorApi.get_section(filing_url, \"12\", \"text\")   # Section 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "    thirteen_text = extractorApi.get_section(filing_url, \"13\", \"text\") # Section 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "    fourteen_text = extractorApi.get_section(filing_url, \"14\", \"text\") # Section 14 - Principal Accountant Fees and Services\n",
    "    fifteen_text = extractorApi.get_section(filing_url, \"15\", \"text\")  # Section 15 - Exhibits and Financial Statement Schedules\n",
    "    \n",
    "    data = {}\n",
    "    data['filing_url'] = filing_url\n",
    "    data['filing_type'] = filing_type\n",
    "    data['cik'] = cik\n",
    "    data['company'] = company\n",
    "    data['filing_date'] = filing_date\n",
    "    data['period_of_report'] = period_of_report\n",
    "    data['filing_html_index'] = filing_html_index\n",
    "    data['complete_text_filing_link'] = complete_text_filing_link\n",
    "    \n",
    "    data['item_1'] = one_text\n",
    "    data['item_1A'] = onea_text\n",
    "    data['item_1B'] = oneb_text\n",
    "    data['item_2'] = two_text\n",
    "    data['item_3'] = three_text\n",
    "    data['item_4'] = four_text\n",
    "    data['item_5'] = five_text\n",
    "    data['item_6'] = six_text\n",
    "    data['item_7'] = seven_text\n",
    "    data['item_7A'] = sevena_text\n",
    "    data['item_8'] = eight_text\n",
    "    data['item_9'] = nine_text\n",
    "    data['item_9A'] = ninea_text\n",
    "    data['item_9B'] = nineb_text\n",
    "    data['item_10'] = ten_text\n",
    "    data['item_11'] = eleven_text\n",
    "    data['item_12'] = twelve_text\n",
    "    data['item_13'] = thirteen_text\n",
    "    data['item_14'] = fourteen_text\n",
    "    data['item_15'] = fifteen_text\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    if not os.path.exists(\"./download_filings\"):\n",
    "        os.makedirs(\"./download_filings\")\n",
    "    \n",
    "    try:\n",
    "        file_name = filing_url.split(\"/\")[-2] + \"-\" + filing_url.split(\"/\")[-1].split(\".\")[0]+\".json\"\n",
    "        download_to = \"./download_filings/\" + file_name\n",
    "        with open(download_to, \"w\") as f:\n",
    "          json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(\"Problem with {url}\".format(url=url))\n",
    "        print(e)\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43792c-16fa-4c89-b46f-ce1b9e7bb02f",
   "metadata": {},
   "source": [
    "Let's again test, and assure that we can get a 10-K Filing and ingest it into our Amazon OpenSearch Serverless vector index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_file=get_filings(\"AMZN\")\n",
    "ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file, vector_index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf641d",
   "metadata": {},
   "source": [
    "### 3.2 Create an AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25aed0",
   "metadata": {},
   "source": [
    "#### Define methods used by AI agent\n",
    "As mentioned previously, a popular architecture for building intelligent agents is called ReAct. The general flow of the ReAct process is as follows:\n",
    "1. The model will \"think\" about what action to take in response to an input and any previous observations.\n",
    "2. The model will then select an action from the available tools (or choose to respond directly to the user).\n",
    "3. The model will generate arguments or parameters to be passed to the selected tool.\n",
    "4. The agent runtime (executor) will parse out the chosen tool and call it with the generated arguments.\n",
    "5. The executor will return the results of the tool call back to the model as an observation.\n",
    "6. This iterative process of reasoning and acting repeats until the agent chooses to provide a final response to the user.\n",
    "\n",
    "##### Our agent methods/tool pathways\n",
    "- `is_financial_statement_related_query` *from human input*\n",
    "  - Use an LLM to determine if the input provided by the user is related to a company's finacial statement. Returns \"yes\" (it is related to a financial statement) or \"no\".\n",
    "- `is_stock_related_query` *from human input*\n",
    "  - Use an LLM to determine if the input provided by the user is stock-related. Returns \"yes\" (it is related to stock) or \"no\".\n",
    "- `get_company_name` *from human input*\n",
    "  - Use an LLM to find a company name from within a user input\n",
    "- `semantic_search_and_check`\n",
    "  - Perform a sementic search for a company and their filing statements within our Amazon OpenSearch Serverless vector index\n",
    "- `search_for_similiar_content_in_10k_filing` *from human input*\n",
    "  - A wrapper function to call `semantic_search_and_check` with human input\n",
    "- `search_financial_statements_for_company`\n",
    "  - A wrapper function to call `semantic_search_and_check` with a financial statement query\n",
    "- `get_stock_ticker` *from human input*\n",
    "  - A convienence function to call both `get_company_name` and `query_stock_ticker` from human input\n",
    "- `get_stock_price` *for a stock ticker*\n",
    "  - A wrapper function for `query_stock_price`\n",
    "- `download_10k_filing_from_sec_and_ingest_into_opensearch` *for a stock ticker*\n",
    "  - A convenience function to download a given 10-K Filing from *sec-api.io* and ingest the result into our OpenSearch Serverless vector index. Returns if the \"download\" succeeded - essentially if the given stock ticker was found and a 10-K filing was successfully downloaded and ingested into Amazon OpenSearch Serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_financial_statement_related_query(human_input):\n",
    "    template = \"\"\"You are a helpful assistant to judge if the human input is trying to analyze company financial statement.\n",
    "    If the human input is financial statement related question, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\n",
    "    \"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return stock_related\n",
    "\n",
    "def is_stock_related_query(human_input):\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant to judge if the human input is stock related question. \n",
    "    If the human input is stock related question, return \"yes\".Otherwise return \"no\".\n",
    "    \"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return stock_related\n",
    "\n",
    "def get_company_name(human_input):\n",
    "    template = \"\"\"You are a helpful assistant who extract company name from the human input.Please only output the company\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "\n",
    "    company_name=llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return company_name\n",
    "    \n",
    "def semantic_search_and_check(human_input, k=10,with_post_filter=True):\n",
    "\n",
    "    company_name=get_company_name(human_input)\n",
    "    \n",
    "    search_vector = bedrock_embeddings.embed_query(human_input)\n",
    "\n",
    "    no_post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"post_filter\": {\n",
    "           \"match\": { \n",
    "               \"company_name\":company_name\n",
    "           }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    search_query=no_post_filter_search_query\n",
    "    if with_post_filter:\n",
    "        search_query=post_filter_search_query\n",
    "    \n",
    "    res = aos_client.search(index=vector_index_name, \n",
    "                       body=search_query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    \n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        hit_company=hit['fields']['company_name'][0]\n",
    "        print(\"\\nsemantic search hit company: \" + hit_company)\n",
    "        row=[hit['fields']['company_name'][0], hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"company_name\",\"company_financial_statements\"])\n",
    "    return query_result_df\n",
    "\n",
    "def search_for_similiar_content_in_10k_filing(human_input):\n",
    "    company_statements = semantic_search_and_check(human_input)\n",
    "    return company_statements\n",
    "\n",
    "def search_financial_statements_for_company(company_financial_statements_query):\n",
    "    company_statements = semantic_search_and_check(company_financial_statements_query)\n",
    "    return company_statements\n",
    "\n",
    "def get_stock_ticker(human_input):\n",
    "    company_name=get_company_name(human_input)\n",
    "    company_ticker = query_stock_ticker(company_name)\n",
    "    return company_ticker\n",
    "\n",
    "def get_stock_price(stock_ticker):\n",
    "    stock_price = query_stock_price(stock_ticker)\n",
    "    return stock_price\n",
    "\n",
    "def download_10k_filing_from_sec_and_ingest_into_opensearch(stock_ticker):\n",
    "    result = \"download failed.\"\n",
    "    try:\n",
    "        downloaded_file=get_filings(stock_ticker)\n",
    "        ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file, vector_index_name)\n",
    "        time.sleep(60) #wait the data can be searchable\n",
    "        result=\"download succeeded.\"\n",
    "    except Exception as e:\n",
    "        result = \"download failed.\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06f721",
   "metadata": {},
   "source": [
    "#### Define tools for financial statements analysis AI agent\n",
    "Now we will connect our Python functions above as tools for our AI agent to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed114181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "annual_report_tools=[\n",
    "    Tool(\n",
    "        name=\"is_financial_statement_related_query\",\n",
    "        func=is_financial_statement_related_query,\n",
    "        description=\"\"\"\n",
    "        Use this tool when you need to know whether user input query is financial statement analysis related query. Human orginal query is the input to this tool. This tool output is whether human input is financial statement analysis related or not. \n",
    "        If the query is not finance statement related, please answer \\\"I am finiancial statement ansysis assitant. I can not answer question which is not finance related.\\\" and terminate the dialog.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search_financial_statements_for_company\",\n",
    "        func=search_financial_statements_for_company,\n",
    "        description=\"\"\"\n",
    "        Use this tool to get financial statement of the company. This tool output is company financial statements.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Use this tool when you need to get the company stock ticker. Human orginal query is the input to this tool. This tool will output company stock ticker.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"download_10k_filing_from_sec_and_ingest_into_opensearch\",\n",
    "        func=download_10k_filing_from_sec_and_ingest_into_opensearch,\n",
    "        description=\"\"\"\n",
    "        Use this tool to download company financial statements from internet. Company stock ticker is the input to this tool. The tool output is download succeed or not.\n",
    "        Use this tool if and only if \"search_financial_statements_for_company\" output result is empty. After downloading financial statements, you must use \"search_financial_statements_for_company\" tool to search financial statements again.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"is_stock_related_query\",\n",
    "        func=is_stock_related_query,\n",
    "        description=\"Use this tool when you need to know whether user input query is stock related query. Human orginal query is the input to this tool. This tool output is whether human input is stock related or not.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_price\",\n",
    "        func=get_stock_price,\n",
    "        description=\"\"\"\n",
    "        Use this tool to get company stock price data. Company stock ticker is the input to this tool. This tool will output company historic stock price. The output includes 'stock_date', 'stock_ticker', 'open_price', 'high_price', 'low_price', 'close_price' of the company in the latest 100 days.\n",
    "        This tool is mandatory to use if the input query is both finance statement related and stock related. If the output of \"get_stock_price\" is empty, please answer \\\"I cannot provide stock analysis without stock price information.\\\" and terminate the dialog.\n",
    "        \"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a089d5",
   "metadata": {},
   "source": [
    "#### Define prompt for financial statements analysis AI agent \n",
    "We'll provide a prompt template for our AI Agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = f\"\"\"\n",
    "You are finiancial analyst assistant and you will analyze company financial statements and stock data. \n",
    "Leverage the <conversation_history> to avoid duplicating work when answering questions.\n",
    "\n",
    "Available tools:\n",
    "<tools>\n",
    "{{tools}}\n",
    "</tools>\n",
    "\n",
    "\n",
    "To answer, first review the <conversation_history>. If insufficient use tool(s) with the following format:\n",
    "<thinking>Think about which tool(s) to use and why. \"get_stock_price\" tool is mandatory to use if the input query is both finance statements related and stock related.</thinking>\n",
    "<tool>tool_name</tool>\n",
    "<tool_input>input</tool_input>\n",
    "<observation>response</observation>\n",
    "\n",
    "When you are done, provide a final answer in markdown within <final_answer></final_answer>.\n",
    "If <user_input> is stock related and the output of \"get_stock_price\" tool is empty, respond directly within <final_answer> with the exact content \\\"I cannot provide stock analysis without stock price information.\\\".\n",
    "Otherwise, use the following format to organize your <final_answer>:\n",
    "\n",
    "Summary:\n",
    "...\n",
    "\n",
    "Support points:\n",
    "Support point 1: ...\n",
    "Support point 2: ...\n",
    "Support point 3: ...\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "<conversation_history>\n",
    "{chat_history}\n",
    "</conversation_history>\n",
    "\n",
    "User input message:\n",
    "<user_input>\n",
    "{input}\n",
    "</user_input>\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Construct the prompt from the messages\n",
    "messages = [\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", user_message),\n",
    "]\n",
    "\n",
    "financial_statements_analysis_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd5e9",
   "metadata": {},
   "source": [
    "#### Define memory for financial statements analysis AI agent\n",
    "As noted from the prompt template above, we will optimize by keeping a history table in Amazon DynamoDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56da29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamodb = boto3.client('dynamodb')\n",
    "history_table_name = 'conversation-history-memory'\n",
    "\n",
    "try:\n",
    "    response = dynamodb.describe_table(TableName=history_table_name)\n",
    "    print(\"The table \"+history_table_name+\" exists.\")\n",
    "except dynamodb.exceptions.ResourceNotFoundException:\n",
    "    print(\"The table \"+history_table_name+\" does not exist.\")\n",
    "    \n",
    "    dynamodb.create_table(\n",
    "    TableName=history_table_name,\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'SessionId',\n",
    "            'AttributeType': 'S',\n",
    "        }\n",
    "    ],\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'SessionId',\n",
    "            'KeyType': 'HASH',\n",
    "        }\n",
    "    ],\n",
    "    ProvisionedThroughput={\n",
    "        'ReadCapacityUnits': 5,\n",
    "        'WriteCapacityUnits': 5,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    response = dynamodb.describe_table(TableName=history_table_name) \n",
    "    while response[\"Table\"][\"TableStatus\"] == 'CREATING':\n",
    "        time.sleep(1)\n",
    "        print('.', end='')\n",
    "        response = dynamodb.describe_table(TableName=history_table_name) \n",
    "\n",
    "    print(\"\\nAmazon Dynamo DB Table, '\"+response['Table']['TableName']+\"' is created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10032dc",
   "metadata": {},
   "source": [
    "#### Create financial statements analysis AI agent AI using defined Memory (in Amazon DynamoDB), LLM, the tools we have created and the prompt above\n",
    "\n",
    ">Note: to avoid potential conflicts with the \"Human\" keyword in the Anthropic Claude model (*\"Claude enjoys helping humans and sees its role as an intelligent and kind assistant to the people, with depth and wisdom that makes it more than a mere tool.\"*), we use `Hu` as the human prefix.\n",
    "\n",
    "We'll create a couple of additional functions to facilitate working with Memory (specifically, using the `DynamoDBChatMessageHistory` module of LangChain's Chat Message Histories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_memory_with_session(session_id):\n",
    "    chat_memory = DynamoDBChatMessageHistory(table_name=history_table_name,session_id=session_id)    \n",
    "    return chat_memory\n",
    "\n",
    "def get_agentic_chatbot_conversation_chain(session_id, verbose=True):\n",
    "    chat_memory=create_new_memory_with_session(session_id)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        human_prefix=\"Hu\",\n",
    "        chat_memory=chat_memory,\n",
    "        return_messages=False\n",
    "    )\n",
    "\n",
    "    agent = create_xml_agent(\n",
    "        bedrock_llm,\n",
    "        annual_report_tools,\n",
    "        financial_statements_analysis_prompt,\n",
    "        stop_sequence=[\"</tool_input>\", \"</final_answer>\"]\n",
    "    )\n",
    "\n",
    "    agent_chain = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=annual_report_tools,\n",
    "        return_intermediate_steps=False,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=\"Check your output and make sure it conforms!\"\n",
    "    )\n",
    "    return agent_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d9655",
   "metadata": {},
   "source": [
    "### 3.3 Use the financial statements analysis AI agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857aa34-7c62-4459-bbc5-7bdeaf2c486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have left the Amazon Redshift Serverless configuration largely set to the default settings,\n",
    "# it's possible that an hour has elapsed since our last connection. To ensure the connection is \n",
    "# available to run the examples, please execute the following:\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0c85b",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9fada4",
   "metadata": {},
   "source": [
    "For our first example using an AI agent, let's revisit the comparison query. Specifically, we will compare the financial statements of two companies.\n",
    "\n",
    "The data flow should be similar to the following:\n",
    "\n",
    "![example 1](./static/example-1-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Compare Adobe and Autodesk company financial statements\"\n",
    "session_id = str(uuid4())\n",
    "langchain.debug=False\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0853517",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_agent_result1 = response[\"output\"].replace(\"$\",\"\\\\\\$\")\n",
    "display(Markdown(\"### Result\\n\" + ai_agent_result1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55cb9b",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998c94c",
   "metadata": {},
   "source": [
    "Let's now try asking a straightforward question: is a company's stock a good investment choice at the present time? \n",
    "\n",
    "The data flow should be like the following:\n",
    "\n",
    "![example 2](./static/example-2-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Is Adobe a good investment choice right now?\"\n",
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35681071-b4ac-4e9e-9e28-badf9316c39c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ai_agent_result2 = response[\"output\"].replace(\"$\",\"\\\\\\$\")\n",
    "display(Markdown(\"### Result\\n\" + ai_agent_result2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e8ee",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cbc80",
   "metadata": {},
   "source": [
    "Since this is an Amazon presentation showcasing AWS services, it would be appropriate to ask a probing question: Is Amazon's stock a good investment choice at the present time?\n",
    "\n",
    "The data flow should follow this process:\n",
    "\n",
    "![example 3](./static/example-3-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"Is Amazon a good investment choice right now?\"\n",
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_agent_result3 = response[\"output\"].replace(\"$\",\"\\\\\\$\")\n",
    "display(Markdown(\"### Result\\n\" + ai_agent_result3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a27b78-74d4-46e0-b52e-1bf979e676fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
