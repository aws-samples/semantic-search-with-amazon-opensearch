{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# Generative AI-powered search with Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "In this lab, we leverage LangChain framework to implement agent based chatbox application.\n",
    "\n",
    "In RAG, external data can be sourced from various data sources, such as document repositories, databases, or APIs. The first step is to convert the documents and the user query into a format that enables comparison and allows for performing relevancy search. To achieve comparability for relevancy search, a document collection (knowledge library) and the user-submitted query are transformed into numerical representations using embedding language models. These embeddings are essentially numerical representations of concepts in text.\n",
    "\n",
    "Next, based on the embedding of the user query, relevant text is identified in the document collection through similarity search in the embedding space. The prompt provided by the user is then combined with the searched relevant text and added to the context. This updated prompt, which includes relevant external data along with the original prompt, is sent to the LLM (Language Model) for processing. As a result, the model output becomes relevant and accurate due to the context containing the relevant external data.\n",
    "\n",
    "For more informaiton about LangChain RAG, please refer: https://python.langchain.com/docs/use_cases/question_answering/\n",
    "\n",
    "---\n",
    "\n",
    "The lab includes the following steps:\n",
    "- [Initialize](#Initialize)\n",
    "- [Part 1: Ingest unstructured data into OpenSearch](#Part-1:-Ingest-unstructured-data-into-OpenSearch)\n",
    "- [Part 2: Different appoach to search](#Part-2:-Different-appoach-to-search)\n",
    "    - [2.1 Keyword search](#2.1-Keyword-search)\n",
    "    - [2.2 Semantic/Vector search](#2.2-Semantic/Vector-search)\n",
    "    - [2.3 Hybrid search](#2.3-Hybrid-search)\n",
    "    - [2.4 Retrieval Augmented Generation(RAG)](#2.4-Retrieval-Augmented-Generation(RAG))\n",
    "    - [2.5 Conversational search](#2.5-Conversational-search)\n",
    "- [Part 3: Agent powered search](#Part-3:-Agent-powered-search)\n",
    "    - [3.1 Ingest structured data into Redshift](#3.1-Ingest-structured-data-into-Redshift)\n",
    "    - [3.2 Query unstructured data in OpenSearch with vector search](#3.2-Query-unstructured-data-in-OpenSearch-with-vector-search)\n",
    "    - [3.3 Query structured data in Redshift with SQLDatabaseChain](#3.3-Query-structured-data-in-Redshift-with-SQLDatabaseChain)\n",
    "    - [3.4 Create LLM Based ReAct Agent Augmented with Data in OpenSearch and Redshift](#3.4-Create-LLM-Based-ReAct-Agent-Augmented-with-Data-in-OpenSearch-and-Redshift)\n",
    "    - [3.5 Use LLM based agent](#3.5-Use-LLM-based-agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab687aa",
   "metadata": {},
   "source": [
    "### Check PyTorch Version\n",
    "Make sure PyTorch versin is larger than or equal  2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae84dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703e3d",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fa4b0",
   "metadata": {},
   "source": [
    "###  Install OpenSearch ML Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q opensearch-py\n",
    "%pip install langchain\n",
    "%pip install boto3\n",
    "%pip install sqlalchemy>\n",
    "%pip install sqlalchemy-redshift\n",
    "%pip install redshift_connector\n",
    "%pip install ipython-sql==0.4.1\n",
    "%pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {},
   "source": [
    "### Import library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker,json\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf48479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41e572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a732112",
   "metadata": {},
   "source": [
    "## Part 1: Ingest unstructured data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ea78bd",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "Form 10-K is a comprehensive report filed annually by a publicly traded company about its financial performance and is required by the U.S. Securities and Exchange Commission (SEC). Some of the information a company is required to document in the 10-K includes its history, organizational structure, financial statements, earnings per share, subsidiaries, executive compensation, and any other relevant data.\n",
    "\n",
    "The SEC mandates that all public companies file regular 10-Ks to keep investors aware of a company's financial condition and to allow them to have enough information before they buy or sell securities issued by that company. The 10-K can appear overly complex at first glance, complete with tables full of data and figures. However, it is so comprehensive that this filing is critical for investors to handle a company's financial position and prospects.\n",
    "\n",
    "Form 10-K is an annual report that provides a comprehensive analysis of the company's financial condition. The Form 10-K is comprised of several parts. These include:\n",
    "\n",
    "#### Business summary:\n",
    "This describes the company's operations. It would include information about business segments, products and services, subsidiaries, markets, regulatory issues, research and development, competition, and employees, among other details.\n",
    "\n",
    "#### Management Discussion and Analysis:\n",
    "This section allows the company to explain its operations and financial results for the past year.\n",
    "\n",
    "#### Financial statements:\n",
    "The financial statements would include the company's balance sheet, income statement, and cash flow statement.\n",
    "\n",
    "Additional sections: Additional sections may discuss the company's management team and legal proceedings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e96080",
   "metadata": {},
   "source": [
    "### 10K Form\n",
    "\n",
    "- 1 - Business\n",
    "- 1A - Risk Factors\n",
    "- 1B - Unresolved Staff Comments\n",
    "- 1C - Cybersecurity\n",
    "- 2 - Properties\n",
    "- 3 - Legal Proceedings\n",
    "- 4 - Mine Safety Disclosures\n",
    "- 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "- 6 - Selected Financial Data (prior to February 2021)\n",
    "- 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "- 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "- 8 - Financial Statements and Supplementary Data\n",
    "- 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "- 9A - Controls and Procedures\n",
    "- 9B - Other Information\n",
    "- 10 - Directors, Executive Officers and Corporate Governance\n",
    "- 11 - Executive Compensation\n",
    "- 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "- 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "- 14 - Principal Accountant Fees and Services\n",
    "- 15 - Exhibits and Financial Statement Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sec-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f829b2",
   "metadata": {},
   "source": [
    "### SEC API\n",
    "https://sec-api.io/docs/query-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01169b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_api_key=\"510e614fa84ef39a9de2012838bfbef33d4e1f1d60c26d4765441fad945d9adf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cec7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_api import QueryApi\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "queryApi = QueryApi(api_key=sec_api_key)\n",
    "query = {\n",
    "  \"query\": { \"query_string\": { \n",
    "      \"query\": \"formType:\\\"10-K\\\" AND ticker:AMZN\", # only 10-Ks\n",
    "  }},\n",
    "  \"from\": \"0\", # start returning matches from position null, i.e. the first matching filing \n",
    "  \"size\": \"3\"  # return just one filing\n",
    "}\n",
    "\n",
    "response = queryApi.get_filings(query)\n",
    "metadata = pd.DataFrame.from_records(response['filings'])\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a0aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_api import RenderApi\n",
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "# open the file we use to store the filing URLs\n",
    "log_file = open(\"filing_urls.txt\", \"w\")\n",
    "\n",
    "\n",
    "# for each filing, only save the URL pointing to the filing itself \n",
    "# and ignore all other data. \n",
    "# the URL is set in the dict key \"linkToFilingDetails\"\n",
    "urls_list = list(map(lambda x: x[\"linkToFilingDetails\"], response[\"filings\"]))\n",
    "\n",
    "# transform list of URLs into one string by joining all list elements\n",
    "# and add a new-line character between each element.\n",
    "urls_string = \"\\n\".join(urls_list)\n",
    "\n",
    "log_file.write(urls_string)\n",
    "\n",
    "log_file.close()\n",
    "\n",
    "\n",
    "renderApi = RenderApi(api_key=sec_api_key)\n",
    "\n",
    "def download_filing(url):\n",
    "  try:\n",
    "    filing = renderApi.get_filing(url)\n",
    "    file_name = url.split(\"/\")[-2] + \"-\" + url.split(\"/\")[-1] \n",
    "    download_to = \"./filings/\" + file_name\n",
    "    with open(download_to, \"w\") as f:\n",
    "      f.write(filing)\n",
    "    time.sleep(2)\n",
    "  except Exception as e:\n",
    "    print(\"Problem with {url}\".format(url=url))\n",
    "    print(e)\n",
    "    \n",
    "# load URLs from log file\n",
    "def load_urls():\n",
    "  log_file = open(\"filing_urls.txt\", \"r\")\n",
    "  urls = log_file.read().split(\"\\n\") # convert long string of URLs into a list \n",
    "  log_file.close()\n",
    "  return urls\n",
    "\n",
    "\n",
    "def download_all_filings():\n",
    "  print(\"Start downloading all filings\")\n",
    "\n",
    "  download_folder = \"./filings\" \n",
    "  if not os.path.isdir(download_folder):\n",
    "    os.makedirs(download_folder)\n",
    "    \n",
    "  urls = load_urls()\n",
    "  print(\"{length} filing URLs loaded\".format(length=len(urls)))\n",
    "\n",
    "  number_of_processes = 20\n",
    "\n",
    "  with multiprocessing.Pool(number_of_processes) as pool:\n",
    "    pool.map(download_filing, urls)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_all_filings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c83fe5",
   "metadata": {},
   "source": [
    "### Get SEC 10K from downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://ws-assets-prod-iad-r-sfo-f61fc67057535f1b.s3.us-west-1.amazonaws.com/df655552-1e61-4a6b-9dc4-c03eb94c6f75/10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a884af",
   "metadata": {},
   "source": [
    "Unzip the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d61bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip 10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994effa4",
   "metadata": {},
   "source": [
    "Read the dataset in JSON format and contruct pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the folder containing the JSON files\n",
    "folder_path = \"extracted\"\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "#For this session, we only ingest few company information.\n",
    "company_list=[\"Alteryx, Inc.\", \"MICROSTRATEGY Inc\", \n",
    "              \"Elastic N.V.\", \"MongoDB, Inc.\", \n",
    "              \"Palo Alto Networks Inc\", \"Okta, Inc.\",\n",
    "              \"Datadog, Inc.\", \"Snowflake Inc.\",\n",
    "              \"SALESFORCE.COM, INC.\", \"ORACLE CORP\",\n",
    "              \"MICROSOFT CORP\", \"Palantir Technologies Inc.\"\n",
    "             ]\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.DataFrame([pd.read_json(file_path,typ='series')])\n",
    "        if df.iloc[0]['company'] in company_list:\n",
    "            dataframes.append(df)\n",
    "\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8c7b67",
   "metadata": {},
   "source": [
    "To display whole DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed677c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11708cbb",
   "metadata": {},
   "source": [
    "### Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with OpenSearch Cluster.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below.\n",
    "\n",
    "#### Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "region = aws_region\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "kms = boto3.client('secretsmanager')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"generative-ai-powered-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "aos_host = outputs['OpenSearchDomainEndpoint']\n",
    "aos_credentials = json.loads(kms.get_secret_value(SecretId=outputs['OpenSearchSecret'])['SecretString'])\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b059b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "\n",
    "auth = (aos_credentials['username'], aos_credentials['password'])\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{'host': aos_host, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb772",
   "metadata": {},
   "source": [
    "### Create a index in Amazon Opensearch Service \n",
    "Whereas we previously created an index with 2 fields, this time we'll define the index with 3 fields: the first field ' question_vector' holds the vector representation of the question, the second is the \"question\" for raw sentence and the third field is \"answer\" for the raw answer data.\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the aos_client connection we initiated ealier to create the index in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"item_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,\n",
    "                \"store\": True,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                      \"ef_construction\": 128,\n",
    "                      \"m\": 24\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"item_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name=\"10k_financial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9e09e",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60657cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.create(index=index_name,body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ad42d",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8c042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import BedrockEmbeddings\n",
    "\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=f\"https://bedrock-runtime.{aws_region}.amazonaws.com\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v1',client=boto3_bedrock)\n",
    "result = bedrock_embeddings.embed_query(\"This is a content of the document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da62bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9f03",
   "metadata": {},
   "source": [
    "###  Load the raw data into the Index\n",
    "Next, let's load the financial billing data into the index we've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import pandas\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "class PandasDataFrameLoader(BaseLoader):\n",
    "    \n",
    "    def __init__(self,dataframe:pandas.DataFrame):\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        items=[\"item_1\",\"item_1A\",\"item_1B\",\"item_2\",\"item_3\",\"item_4\",\"item_5\",\"item_6\",\"item_7\",\"item_7A\",\"item_8\",\"item_9\",\"item_9A\", \"item_9B\", \"item_10\", \"item_11\", \"item_12\", \"item_13\", \"item_14\", \"item_15\"]\n",
    "        \n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            metadata={}\n",
    "            metadata[\"cik\"]=row['cik']\n",
    "            metadata[\"company_name\"]=row['company']\n",
    "            metadata[\"filing_date\"]=row['filing_date']\n",
    "            for item in items:\n",
    "                content=row[item]\n",
    "                metadata['item'] = item\n",
    "                doc = Document(page_content=content,metadata=metadata)\n",
    "                #print(doc.metadata)\n",
    "                docs.append(doc)\n",
    "        return docs\n",
    "    \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "pd_loader = PandasDataFrameLoader(combined_df)\n",
    "documents = pd_loader.load()\n",
    "#splitted_documnets = pd_loader.load_and_split(text_splitter=text_splitter)\n",
    "splitted_documnets = text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dcbea",
   "metadata": {},
   "source": [
    "Use Bedrock embedding convert item content into vector and use OpenSearch bulk ingest to store data into OpenSearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5401c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from opensearchpy import helpers\n",
    "\n",
    "previous_company_name=\"\"\n",
    "item_contents=[]\n",
    "for doc in splitted_documnets:\n",
    "    company_name=doc.metadata['company_name']\n",
    "    if previous_company_name != \"\" and previous_company_name != company_name:\n",
    "        print(\"company:\" + company_name + \", item count:\" + str(len(item_contents)))\n",
    "        start = time.time()\n",
    "        embedding_results = bedrock_embeddings.embed_documents(item_contents)\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "        print(f\"total time elapsed for Bedrock embedding: {elapsed:.2f} seconds\")\n",
    "        #TODO\n",
    "        data = []\n",
    "        i=0\n",
    "        for content in item_contents:\n",
    "            data.append({\"_index\": index_name,  \"company_name\": previous_company_name, \"item_content\":content, \"item_vector\":embedding_results[i]})\n",
    "            i = i+1\n",
    "        aos_response= helpers.bulk(aos_client, data)\n",
    "        print(f\"Bulk-inserted {aos_response[0]} items.\")\n",
    "        item_contents=[]\n",
    "    \n",
    "    item_contents.append(doc.page_content)\n",
    "    previous_company_name=company_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee126626",
   "metadata": {},
   "source": [
    "To validate the load, we'll query the number of documents number in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0ea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.delete(index=index_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131f864",
   "metadata": {},
   "source": [
    "## Part 2: Different appoach to search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1007fa",
   "metadata": {},
   "source": [
    "### 2.1 Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd062b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6019cb4a",
   "metadata": {},
   "source": [
    "### 2.2 Semantic/Vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed55f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9efd2c64",
   "metadata": {},
   "source": [
    "### 2.3 Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada5542c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "438d6347",
   "metadata": {},
   "source": [
    "### 2.4 Retrieval Augmented Generation(RAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb253682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a39b9219",
   "metadata": {},
   "source": [
    "### 2.5 Conversational search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c9ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40648cdd",
   "metadata": {},
   "source": [
    "## Part 3: Agent powered search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c010",
   "metadata": {},
   "source": [
    "### 3.1 Ingest structured data into Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3c50d",
   "metadata": {},
   "source": [
    "Get Redshift Serverless username, password and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift_serverless_credentials = json.loads(kms.get_secret_value(SecretId=outputs['RedshiftServerlessSecret'])['SecretString'])\n",
    "redshift_serverless_username=redshift_serverless_credentials['username']\n",
    "redshift_serverless_password=redshift_serverless_credentials['password']\n",
    "redshift_serverless_endpoint =  outputs['RedshiftServerlessEndpoint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c619",
   "metadata": {},
   "source": [
    "connect to Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import Session\n",
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4ee955",
   "metadata": {},
   "source": [
    "\n",
    "### Populate the Redshift table \n",
    "\n",
    "### Stock symbol table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d123032",
   "metadata": {},
   "source": [
    "create `stock_symbol` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f94e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_symbol (stock_symbol text PRIMARY KEY, company_name text NOT NULL);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9516e",
   "metadata": {},
   "source": [
    "insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1822ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_bucket = outputs[\"s3BucketStock\"]\n",
    "s3_location = f's3://{stock_price_bucket}/stock-price/'\n",
    "print(s3_location)\n",
    "!aws s3 sync ./stock-price/ $s3_location\n",
    "\n",
    "stock_symbol_s3_location = f's3://{stock_price_bucket}/stock-price/stock_symbol.csv'\n",
    "print(stock_symbol_s3_location)\n",
    "quoted_stock_symbol_s3_location = \"'\" + stock_symbol_s3_location + \"'\"\n",
    "print(quoted_stock_symbol_s3_location)\n",
    "print(\"---------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql COPY STOCK_SYMBOL FROM $quoted_stock_symbol_s3_location iam_role default IGNOREHEADER 1 CSV;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de54a9",
   "metadata": {},
   "source": [
    "query `stock_symbol` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9047d6e",
   "metadata": {},
   "source": [
    "### Stock price table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8ab163",
   "metadata": {},
   "source": [
    "Create stock price table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540061a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_price (stock_date DATE, stock_symbol text, open_price DECIMAL, high_price DECIMAL, low_price DECIMAL, close_price DECIMAL, adjusted_close_price DECIMAL, volume DECIMAL);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73091c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msft_s3_location = f's3://{stock_price_bucket}/stock-price/MSFT.csv'\n",
    "print(msft_s3_location)\n",
    "quoted_msft_s3_location = \"'\" + msft_s3_location + \"'\"\n",
    "print(quoted_msft_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "crm_s3_location = f's3://{stock_price_bucket}/stock-price/CRM.csv'\n",
    "print(crm_s3_location)\n",
    "quoted_crm_s3_location = \"'\" + crm_s3_location + \"'\"\n",
    "print(quoted_crm_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "orcl_s3_location = f's3://{stock_price_bucket}/stock-price/ORCL.csv'\n",
    "print(orcl_s3_location)\n",
    "quoted_orcl_s3_location = \"'\" + orcl_s3_location + \"'\"\n",
    "print(quoted_orcl_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "snow_s3_location = f's3://{stock_price_bucket}/stock-price/SNOW.csv'\n",
    "print(snow_s3_location)\n",
    "quoted_snow_s3_location = \"'\" + snow_s3_location + \"'\"\n",
    "print(quoted_snow_s3_location)\n",
    "print(\"---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65325e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql COPY STOCK_PRICE FROM $quoted_msft_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_crm_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_orcl_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_snow_s3_location iam_role default IGNOREHEADER 1 CSV;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf73f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84be705",
   "metadata": {},
   "source": [
    "### 3.2 Query unstructured data in OpenSearch with vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70403851",
   "metadata": {},
   "source": [
    "Define semantic search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, k=10):\n",
    "    print(\"semantic search input: \" + query)\n",
    "    search_vector = bedrock_embeddings.embed_query(query)\n",
    "    query={\n",
    "        \"size\": 10,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    #print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        row=[hit['fields']['item_content'][0]]\n",
    "        print(row)\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"item_content\"])\n",
    "    return query_result_df\n",
    "\n",
    "def semantic_search_full_field(query, k=5):\n",
    "    search_vector = bedrock_embeddings.embed_query(query)\n",
    "    query={\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    #print(\"Got %d Hits:\" % res['hits']['total']['value'])\n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        row=[hit['_id'],hit['_score'],hit['fields']['company_name'][0],hit['fields']['item_category'][0],hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_category\",\"item_content\"])\n",
    "    return query_result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f811868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_financial_statements(query):\n",
    "    company_statements = semantic_search(query)\n",
    "    return company_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ae672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search_result=get_financial_statements(\"Is Microsoft a good investment choice right now?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "semantic_search_result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583598e",
   "metadata": {},
   "source": [
    "### 3.3 Query structured data in Redshift with SQLDatabaseChain\n",
    "A common use of an agent is to look up a record in a database. It would not be practical to include the full database in the context, so you can provide tools that perform actions against the datebase that eliminates hallucinations while maintining the conversational interactions.\n",
    "\n",
    "#### SQL Database Chain\n",
    "Langchain has a SQL Database chain to ask questions of a DB to get answers. For details, read this document: https://python.langchain.com/docs/use_cases/qa_structured/sql#case-2-text-to-sql-query-and-execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859f8d0e",
   "metadata": {},
   "source": [
    "Initialize Bedrock LLM model with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d17670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from typing import Optional, List, Any\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "#bedrock_llm = Bedrock(model_id=\"anthropic.claude-instant-v1\", client=boto3_bedrock)\n",
    "bedrock_llm = Bedrock(model_id=\"anthropic.claude-v2\", client=boto3_bedrock)\n",
    "\n",
    "bedrock_llm.model_kwargs = {\"max_tokens_to_sample\":1204,\"temperature\":0.01,\"top_k\":250,\"top_p\":1,\"stop_sequences\":[\"\\\\n\\\\nHuman:\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b2f5fa",
   "metadata": {},
   "source": [
    "#### Get stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b195f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "url = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(url,include_tables=['stock_symbol'])\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_DEFAULT_TEMPLATE = \"\"\"Human: Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "If the results of the query is empty, answer \\\"I don't know\\\"\n",
    "<format>\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Answer with SQLResult. If SQLResult is empty, asnwer I don't know\"\n",
    "</format>\n",
    "Assistant: Understood, I will use the above format and only provide the answer.\n",
    "\n",
    "Only use the following tables:\n",
    "<tables>\n",
    "CREATE TABLE stock_symbol (\n",
    "\tstock_symbol text PRIMARY KEY,\n",
    "\tcompany_name text NOT NULL\n",
    ")\n",
    "</tables>\n",
    "\n",
    "If someone asks for the table stock symbol table, they really mean the stock_symbol table.\n",
    "<examples>\n",
    "Question: What is the ticker symbol for Amazon in stock symbol table?\n",
    "SQLQuery: SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%Amazon%'\n",
    "SQLResult: AMZN\n",
    "Answer: AMZN\n",
    "\n",
    "Question: What is the ticker symbol for Microsoft in stock ticker table?\n",
    "SQLQuery: SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%Microsoft%'\n",
    "SQLResult: empty\n",
    "Answer: I don't know\n",
    "\n",
    "</examples>\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=[\"input\", \"dialect\"], template=_DEFAULT_TEMPLATE\n",
    ")\n",
    "\n",
    "llm=bedrock_llm\n",
    "\n",
    "db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm, \n",
    "    db, \n",
    "    verbose=True, \n",
    "    return_intermediate_steps=True, \n",
    "    prompt=PROMPT, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383a78f",
   "metadata": {},
   "source": [
    "Get \"Amazon\" stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db81b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for Amazon in stock symbol table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0837c85d",
   "metadata": {},
   "source": [
    "Get \"Microsoft\" stock symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26450db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for MICROSOFT in stock ticker table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6814a",
   "metadata": {},
   "source": [
    "Try to get a non exist company stock symbol, it will return \"I don't know\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c9f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = db_chain(\"\\n\\nHuman: What is the ticker symbol for Pan Test in stock ticker table? \\n\\nAssistant:\")\n",
    "response['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b8e2b9",
   "metadata": {},
   "source": [
    "#### Get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4902d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_template = \"\"\"Human: Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "If the results of the query is empty, answer \\\"I don't know\\\"\n",
    "<format>\n",
    "Question: \"Question here\"\n",
    "SQLQuery: \"SQL Query to run\"\n",
    "SQLResult: \"Result of the SQLQuery\"\n",
    "Answer: \"Answer with SQLResult. If SQLResult is empty, asnwer I don't know\"\n",
    "</format>\n",
    "Assistant: Understood, I will use the above format and only provide the answer.\n",
    "\n",
    "Only use the following tables:\n",
    "<tables>\n",
    "CREATE TABLE public.stock_price (\n",
    "stock_date DATE, \n",
    "stock_symbol text, \n",
    "open_price DECIMAL, \n",
    "high_price DECIMAL, \n",
    "low_price DECIMAL, \n",
    "close_price DECIMAL, \n",
    "adjusted_close_price DECIMAL, \n",
    "volume DECIMAL);\n",
    "</tables>\n",
    "\n",
    "answer the following question and organize the return data into json format.\n",
    "1. what is the company average open price in the month of July? \n",
    "2. what is the company average close price in the month of July?\n",
    "3. what is the company average high price in the month of July?\n",
    "4. what is the company average low price in the month of July?\n",
    "5. what is the company average adjusted close price in the month of July?\n",
    "6. what is the company average volume in the month of July?\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "stock_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"dialect\"], template=stock_price_template\n",
    ")\n",
    "\n",
    "llm=bedrock_llm\n",
    "\n",
    "stock_price_db_chain = SQLDatabaseChain.from_llm(\n",
    "    llm, \n",
    "    db, \n",
    "    verbose=True, \n",
    "    return_intermediate_steps=True, \n",
    "    prompt=stock_prompt, \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a24e7",
   "metadata": {},
   "source": [
    "Get MSFT stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price_info = stock_price_db_chain(\"\\n\\nHuman: What is the MSFT stock information? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3366294",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stock_price_info['result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba6cc",
   "metadata": {},
   "source": [
    "Define functions:\n",
    "1. if query is stock related, \n",
    "2. get stock ticker from the query\n",
    "3. get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef542cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def is_stock_related_query(query):\n",
    "    template = \"\"\"You are a helpful assistant to judge if the human input is stock related question.\n",
    "    If it is stock related, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":query})['text'].strip()\n",
    "    return stock_related, query\n",
    "    \n",
    "def get_stock_ticker(query):\n",
    "    template = \"\"\"You are a helpful assistant who extract company name from the human input.Please only output the company\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "\n",
    "    company_name=llm_chain(query)['text'].strip()\n",
    "    company_ticker = db_chain(\"\\n\\nHuman: What is the ticker symbol for \" + str(company_name) + \" in stock ticker table? \\n\\nAssistant:\")\n",
    "    return company_name, company_ticker['result']\n",
    "\n",
    "def get_stock_price(ticker):\n",
    "    #get stock price with text to sql in db_chain\n",
    "    data = stock_price_db_chain(\"\\n\\nHuman: What is the \" + str(ticker) + \" stock information ? \\n\\nAssistant:\")\n",
    "    return data['result']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf641d",
   "metadata": {},
   "source": [
    "### 3.4 Create LLM Based ReAct Agent Augmented with Data in OpenSearch and Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aa700",
   "metadata": {},
   "source": [
    "Define agent tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26cfb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentType\n",
    "\n",
    "tools=[\n",
    "    Tool(\n",
    "        name=\"is stock related query\",\n",
    "        func=is_stock_related_query,\n",
    "        description=\"If the query is stock related\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get company ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Get the company stock ticker\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get stock data\",\n",
    "        func=get_stock_price,\n",
    "        description=\"Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the the stock ticker to it \"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get financial statements\",\n",
    "        func=get_financial_statements,\n",
    "        description=\"Use this to get financial statement of the company. With the help of this data company's historic performance can be evaluated. You should input stock ticker to it\"\n",
    "    ) \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05846e63",
   "metadata": {},
   "source": [
    "define agent prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b17bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_prompt=\"\"\"Human: You are a financial advisor. Give stock recommendations for given query based on following instructions. \n",
    "<instructions>\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "is stock related query: Use when you need to know whether this is stock related query. This tool will output whether human input is stock related and human input. You should input the human input to it.\n",
    "get company ticker: Use when you need to extract company name and stock ticker. This tool will output company name and stock ticker.\n",
    "get stock data: Use when you are asked to evaluate or analyze a stock. This will output historic share price data. You should input the stock ticker to it.\n",
    "get financial statements: Use this to get financial statement of the company. With the help of this data, companys historic performance can be evaluated. You should input the human input to it.\n",
    "</instructions>\n",
    "\n",
    "<steps>\n",
    "Note- if you fail in satisfying any of the step below, Just move to next one\n",
    "1) Use \"is stock related query\" tool to judge if the input query is stock related or not. Output - stock related and input query\n",
    "2) Use \"get company ticker\" tool to get the company name and stock ticker. Output- company name and stock ticker\n",
    "3) Use \"get stock data\" tool to gather stock info. Output- Stock data\n",
    "4) Use \"get financial statements\" tool to get company's historic financial statement. Output- Financial statement\n",
    "5) Analyze the stock based on gathered data and give detail analysis for investment choice. provide numbers and reasons to justify your answer. \n",
    "If there is no output from \"get stock data\" tool, please ouput \"I cannot provide stock analysis without stock price information.\".\n",
    "Output- Detailed stock Analysis\n",
    "</steps>\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do, Also try to follow steps mentioned above\n",
    "Action: the action to take, should be one of [is stock related query, get company ticker, get stock data, get financial statements]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Assistant:\n",
    "{agent_scratchpad}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a94144",
   "metadata": {},
   "source": [
    "Initialize agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent \n",
    "\n",
    "zero_shot_agent=initialize_agent(\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    max_iteration=2,\n",
    "    return_intermediate_steps=True,\n",
    "    handle_parsing_errors=True,\n",
    ")\n",
    "\n",
    "zero_shot_agent.agent.llm_chain.prompt.template=updated_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e426e344",
   "metadata": {},
   "source": [
    "### 3.5 Use LLM based agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f63ba",
   "metadata": {},
   "source": [
    "#### Example 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d8394",
   "metadata": {},
   "source": [
    "Ask the queustion \"Is Microsoft a good investment choice right now?\". The agent will run the following process:\n",
    "\n",
    "1. is stock related query\n",
    "2. get company name\n",
    "3. get stock symbol\n",
    "4. get stock price\n",
    "5. use semantic search get related information from 10k financial filing data\n",
    "\n",
    "Combine all the above information and generate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a0fc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "response = zero_shot_agent(\"\\n\\nHuman: Is Microsoft a good investment choice right now? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"intermediate_steps\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb15388c",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b211d3",
   "metadata": {},
   "source": [
    "\"Is Amazon a good investment choice right now?\". This is stock related quesiton. However there is no Amazon stock price information in Redshift table. So it will answer \"I cannot provide stock analysis without stock price information.\" in the end. The agent will run the following process:\n",
    "\n",
    "1. is stock related query\n",
    "2. get company name\n",
    "3. get stock symbol\n",
    "4. get stock price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f165b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = zero_shot_agent(\"\\n\\nHuman: Is Amazon a good investment choice right now? \\n\\nAssistant:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ffe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e8ee",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cbc80",
   "metadata": {},
   "source": [
    "This is not stock related query. The agent will run the following process:\n",
    "\n",
    "1. is stock related query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = zero_shot_agent(\"\\n\\nHuman: What is SageMaker? \\n\\nAssistant:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ca2b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
