{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87dc259",
   "metadata": {},
   "source": [
    "# Generative AI-powered search with Amazon OpenSearch Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cfd51d",
   "metadata": {},
   "source": [
    "---\n",
    "### Using Scenario\n",
    "Form 10-K is a comprehensive report filed annually by a publicly traded company about its financial performance and is required by the U.S. Securities and Exchange Commission (SEC). Some of the information a company is required to document in the 10-K includes its history, organizational structure, financial statements, earnings per share, subsidiaries, executive compensation, and any other relevant data.\n",
    "\n",
    "The SEC mandates that all public companies file regular 10-Ks to keep investors aware of a company's financial condition and to allow them to have enough information before they buy or sell securities issued by that company. The 10-K can appear overly complex at first glance, complete with tables full of data and figures. However, it is so comprehensive that this filing is critical for investors to handle a company's financial position and prospects.\n",
    "\n",
    "Form 10-K is an annual report that provides a comprehensive analysis of the company's financial condition. The Form 10-K is comprised of several parts. These include:\n",
    "\n",
    "- 1 - Business-This describes the company's operations. \n",
    "- 1A - Risk Factors\n",
    "- 1B - Unresolved Staff Comments\n",
    "- 2 - Properties\n",
    "- 3 - Legal Proceedings\n",
    "- 4 - Mine Safety Disclosures\n",
    "- 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "- 6 - Selected Financial Data (prior to February 2021)\n",
    "- 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "- 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "- 8 - Financial Statements and Supplementary Data\n",
    "- 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "- 9A - Controls and Procedures\n",
    "- 9B - Other Information\n",
    "- 10 - Directors, Executive Officers and Corporate Governance\n",
    "- 11 - Executive Compensation\n",
    "- 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "- 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "- 14 - Principal Accountant Fees and Services\n",
    "- 15 - Exhibits and Financial Statement Schedules\n",
    "\n",
    "---\n",
    "\n",
    "Many investors rely of SEC filings to analyze the financial health of a company, and they can certainly be a treasure trove of valuable information. Keyword based search may return some irrelevant information. Even with semantic search, information is overwhelming. Can we leverage generative AI to help us on company financial statements interpertation?\n",
    "\n",
    "\n",
    "In this code talk session, we will show you how to modernize your search application to improve search relevance with Amazon OpenSearch while leveraging generative AI to improve search productivity. The code includes the following topics:\n",
    "- Comparison search relevance between keyword search and semantic search with Amazon OpenSearch.\n",
    "- How to leverage Retrieval Augmented Generation(RAG) improve search productivity.\n",
    "- How to build intelligent agent which orchestrate and execute multistep tasks to automate 10-K filings analysis.\n",
    "- OpenSearch vector store best practices\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Code Structure\n",
    "\n",
    "\n",
    "The code includes the following sections:\n",
    "- [Initialize](#Initialize)\n",
    "- [Part 1: Ingest unstructured data into OpenSearch](#Part-1:-Ingest-unstructured-data-into-OpenSearch)\n",
    "- [Part 2: Different appoach to search](#Part-2:-Different-appoach-to-search)\n",
    "    - [2.1 Keyword search](#2.1-Keyword-search)\n",
    "    - [2.2 Semantic/Vector search](#2.2-Semantic/Vector-search)\n",
    "    - [2.3 Retrieval Augmented Generation(RAG)](#2.3-Retrieval-Augmented-Generation(RAG))\n",
    "- [Part 3: AI agent powered search](#Part-3:-AI-agent-powered-search)\n",
    "    - [3.1 Prepare other tools used by AI agent](#3.1-Prepare-other-tools-used-by-AI-agent)\n",
    "        - [3.1.1 Ingest and query structured data in Redshift](#3.1.1-Ingest-and-query-structured-data-in-Redshift)\n",
    "        - [3.1.2 Download 10-K filing from SEC](#3.1.2-Download-10-K-filing-from-SEC)\n",
    "    - [3.2 Create AI agent](#3.2-Create-AI-agent)\n",
    "    - [3.3 Use AI agent](#3.3-Use-AI-agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31703e3d",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fa4b0",
   "metadata": {},
   "source": [
    "###  Install dependency Python library for OpenSearch, Redshift, Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a1c491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install opensearch-py\n",
    "%pip install torch\n",
    "%pip install requests-aws4auth\n",
    "%pip install boto3\n",
    "%pip install sqlalchemy\n",
    "%pip install sqlalchemy-redshift\n",
    "%pip install redshift_connector\n",
    "%pip install ipython-sql==0.4.1\n",
    "%pip install langchain==0.3.1\n",
    "%pip install langchain-aws==0.2.1\n",
    "%pip install langchain-community==0.3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa614bc",
   "metadata": {},
   "source": [
    "### Import library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1688f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import sagemaker,json\n",
    "from sagemaker.session import Session\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a732112",
   "metadata": {},
   "source": [
    "## Part 1: Ingest unstructured data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c83fe5",
   "metadata": {},
   "source": [
    "### Get SEC 10-K form files\n",
    "\n",
    "Lets download it and unzip it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9192e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wget https://ws-assets-prod-iad-r-sfo-f61fc67057535f1b.s3.us-west-1.amazonaws.com/df655552-1e61-4a6b-9dc4-c03eb94c6f75/10k-financial-filing.zip\n",
    "!unzip 10k-financial-filing.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994effa4",
   "metadata": {},
   "source": [
    "Read the dataset in JSON format and contruct pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff7403",
   "metadata": {},
   "source": [
    "### Load the data to OpenSearch\n",
    "OpenSearch is good with dynamic type inference and can perform full text search with fuzziness and type tolerance. Lets fetch the AOSS endpoint from the deployed CloudFormation template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62471bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "\n",
    "cfn = boto3.client('cloudformation')\n",
    "kms = boto3.client('secretsmanager')\n",
    "\n",
    "def get_cfn_outputs(stackname):\n",
    "    outputs = {}\n",
    "    for output in cfn.describe_stacks(StackName=stackname)['Stacks'][0]['Outputs']:\n",
    "        outputs[output['OutputKey']] = output['OutputValue']\n",
    "    return outputs\n",
    "\n",
    "## Setup variables to use for the rest of the demo\n",
    "cloudformation_stack_name = \"generative-ai-powered-search\"\n",
    "\n",
    "outputs = get_cfn_outputs(cloudformation_stack_name)\n",
    "\n",
    "aoss_endpoint = outputs['OpenSearchServerlessCollectionEndpoint']\n",
    "\n",
    "aoss_host = aoss_endpoint.split(\"//\")[1]\n",
    "\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3513aef",
   "metadata": {},
   "source": [
    "Lets create a client to OpenSearch Serverless and we use this for the entire workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "\n",
    "service = \"aoss\"\n",
    "aws_region = boto3.Session().region_name\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, aws_region, service)\n",
    "\n",
    "aos_client = OpenSearch(\n",
    "    hosts = [{\"host\": aoss_host, \"port\": 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b91db9",
   "metadata": {},
   "source": [
    "Let's create a new index with a name \"10k_finanical\". As you will recreate this index with different techniques, delete the index if any before creating. Just creating an empty index in OpenSearch, the index schema would be extened as and when it finds a new attribute with dynamic type inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c28384",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"10k_financial\"\n",
    "\n",
    "exist=False\n",
    "try:\n",
    "    aos_client.indices.get(index=index_name)\n",
    "    exist=True\n",
    "except Exception as e:\n",
    "    exist=False\n",
    "\n",
    "if exist:\n",
    "    print(\"delete existing index before creating new one\")\n",
    "    aos_client.indices.delete(index=index_name)\n",
    "else:\n",
    "    print(\"index does not exist.\")\n",
    "    \n",
    "aos_client.indices.create(index=index_name,ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8de9d0",
   "metadata": {},
   "source": [
    "Now you can load all the financial reports to the index you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89fad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from opensearchpy import helpers\n",
    "# Set the directory path\n",
    "directory_path =  \"extracted\"\n",
    "batch_size = 10\n",
    "# Initialize a list to store the documents\n",
    "documents = []\n",
    "\n",
    "# Iterate through the files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "    # Read the file contents\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_contents = file.read()\n",
    "    docJson = json.loads(file_contents)\n",
    "    docJson[\"_index\"] = index_name\n",
    "    documents.append(docJson)\n",
    "    # If the batch size is reached, index the documents\n",
    "    if len(documents) == batch_size:\n",
    "        aos_response= helpers.bulk(aos_client, documents)\n",
    "        print(f\"Indexed {len(documents)} documents.\")\n",
    "        documents = []\n",
    "\n",
    "# Index the remaining documents\n",
    "if documents:\n",
    "    aos_response= helpers.bulk(aos_client, documents)\n",
    "    print(f\"Indexed {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d53e5f5",
   "metadata": {},
   "source": [
    "you can check the total number of documents indexed into the OpenSearch index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131f864",
   "metadata": {},
   "source": [
    "## Part 2: Different appoach to search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1007fa",
   "metadata": {},
   "source": [
    "### 2.1 Keyword search\n",
    "---\n",
    "Keyword search refers to finding information one is looking for using terms or words, called \"query\", from among a large body of textual data. It uses various tokenization methods to split the actual text and score the results with the token statistics like, how many times the word exist in the document, how common it is across the entire corpus, proximity, etc. With these data structure, OpenSearch can handle fuzziness, and tolerate the typo mistakes in the search enables the users search with phonetically similar terms or not knowing the exact spelling( for example scientific names). It works great with exact matches\n",
    "\n",
    "Lets search for companies in the state of Illinois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb6d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\"],\n",
    "    \"query\": {\n",
    "        \"bool\" :{\n",
    "            \"filter\" : [{\n",
    "                    \"match\" :{\n",
    "                        \"state_location.keyword\" : \"IL\"\n",
    "                    }\n",
    "                }]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2bd4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89ec2a",
   "metadata": {},
   "source": [
    "You can search across fields and highlight them why they match the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\", \"item_1\"],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\" :[\n",
    "                {\n",
    "                    \"multi_match\" :{\n",
    "                        \"query\" : \"microchips\",\n",
    "                        \"fields\" :[\"item_1\"]\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d985fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "print (f\"Total documents found: {res['hits']['total']['value']}\")\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location'],hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dfeb69",
   "metadata": {},
   "source": [
    "You can also perform a phrase match where the words are together, with additional filters like companies located in California as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    \"_source\" : [\"company\", \"filing_date\", \"state_location\", \"item_1\"],\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\" :[\n",
    "                {\n",
    "                    \"match_phrase\" :{\n",
    "                        \"item_1\" : \"digital media\"\n",
    "                    }\n",
    "                }\n",
    "            ],\n",
    "            \"filter\" :[\n",
    "                {\n",
    "                    \"term\": {\n",
    "                        \"state_location.keyword\" : \"CA\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc1cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "print (f\"Total documents found: {res['hits']['total']['value']}\")\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['filing_date'],hit['_source']['state_location'],hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"filing_date\",\"state_location\", \"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f2447c",
   "metadata": {},
   "source": [
    "While the full text search works great with structural data with fuzziness, and typo tolerance, proximity searching, highlighting. However, When it comes to natural language, pure keyword search could result less relevant and a long tail of noise.\n",
    "\n",
    "Lets run the query and check the search result. Some irrelevant documents are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba47370",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What Microsoft's researh and development organization is responsible for?\"\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_1\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_*\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['item_1'], hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"item_1\",\"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeca9e9",
   "metadata": {},
   "source": [
    "Run the query and check the search result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d542ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets execute another query example\n",
    "query_text=\"What is Microsoft's main revenue?\"\n",
    "query={\n",
    "  \"size\": 10,\n",
    "  \"query\": {\n",
    "    \"match\": {\n",
    "      \"item_1\": query_text\n",
    "    }\n",
    "  },\n",
    "  \"highlight\" : {\n",
    "    \"pre_tags\" : [\"<em>\"],\n",
    "    \"post_tags\" : [\"</em>\"],\n",
    "    \"fields\" : {\n",
    "      \"item_1\" : {}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company'],hit['_source']['item_1'], hit['highlight']['item_1'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company\",\"item_1\",\"item_1_highlight\"])\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "display(query_result_df)\n",
    "\n",
    "# you can notice some irrelevant results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5407471f",
   "metadata": {},
   "source": [
    "These term statistics based retrieval on a large text corpus produced these results. \n",
    "![Keyword Search](./static/keyword-search-flow.png)\n",
    "\n",
    "And a segway to the world of vector search or semantic search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bd148",
   "metadata": {},
   "source": [
    "### Initialize embedding model to vectorize text data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019cb4a",
   "metadata": {},
   "source": [
    "### 2.2 Semantic/Vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895095ec",
   "metadata": {},
   "source": [
    "---\n",
    "In Vector search,documents and queries are represented as high-dimensional numerical vectors, rather than just as strings of text.\n",
    "\n",
    "The key idea behind vector search is that semantically similar documents or queries can be mapped to vectors that are close to each other in the vector space, even if the textual content doesn't have much lexical overlap.\n",
    "\n",
    "Here's a bit more detail on how vector search works:\n",
    "\n",
    "    Documents are converted into numerical vector representations using machine learning models like word embeddings or document embeddings. These models learn to map words, phrases, or entire documents into a high-dimensional vector space.\n",
    "\n",
    "    Queries are also converted into vector form, allowing them to be compared to the document vectors in this mathematical vector space.\n",
    "\n",
    "    Rather than doing a simple keyword match, the search engine calculates the similarity between the query vector and each document vector, often using a metric like cosine similarity.\n",
    "\n",
    "    The most similar document vectors are then returned as the search results, even if they don't contain the exact words from the query.\n",
    "\n",
    "This allows vector search to uncover semantically relevant content that would be missed by traditional text-based searches. It's especially useful for tasks like question answering, e-commerce search, and retrieval of similar documents or images.\n",
    "\n",
    "The underlying machine learning models need to be trained on large datasets, but vector search can significantly improve the quality and relevance of search results compared to purely lexical approaches.\n",
    "\n",
    "\n",
    "![Semantic Search](./static/semantic-search-flow.png)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "![Semantic Search Architecture](./static/semantic-search-architecture.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cf9a5d",
   "metadata": {},
   "source": [
    "**Embeddings** are numerical representations of data, typically used to convert complex, high-dimensional data into a lower-dimensional space where similar data points are closer together. In the context of natural language processing (NLP), embeddings are used to represent words, phrases, or sentences as vectors of real numbers. These vectors capture semantic relationships, meaning that words with similar meanings are represented by vectors that are close together in the embedding space.\n",
    "\n",
    "**Embedding models** are machine learning models that are trained to create these numerical representations. They learn to encode various types of data into embeddings that capture the essential characteristics and relationships within the data. For example, in NLP, embedding models like Word2Vec, GloVe, and BERT are trained on large text corpora to produce word embeddings. These embeddings can then be used for various downstream tasks, such as text classification, sentiment analysis, or machine translation. In this case we'll be using it for semantic similarity\n",
    "\n",
    "We use embedding model to convert questions into vector and use vector similiarity to search semantic similiar 10-K data. The following diagram shows the flow: \n",
    "\n",
    "<!-- ![Convert Text to Vector](./static/text2vector.png) -->\n",
    "\n",
    "---\n",
    "\n",
    "![opensearch vector store](./static/opensearch-vector-store.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the folder containing the JSON files\n",
    "folder_path = \"extracted\"\n",
    "\n",
    "# Initialize an empty list to store list of company 10-K filing file names\n",
    "company_filing_file_name_list = []\n",
    "\n",
    "#For this session, we only ingest few company information.\n",
    "company_list=[\"Alteryx, Inc.\",\n",
    "              \"MICROSTRATEGY Inc\", \n",
    "              \"Elastic N.V.\", \n",
    "              \"MongoDB, Inc.\", \n",
    "              \"Palo Alto Networks Inc\", \n",
    "              \"Okta, Inc.\",\n",
    "              \"Datadog, Inc.\", \n",
    "              \"Snowflake Inc.\",\n",
    "              \"SALESFORCE.COM, INC.\", \n",
    "              \"ORACLE CORP\",\n",
    "              \"MICROSOFT CORP\", \n",
    "              \"Palantir Technologies Inc.\"\n",
    "             ]\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.DataFrame([pd.read_json(file_path,typ='series')])\n",
    "        if df.iloc[0]['company'] in company_list:\n",
    "            company_filing_file_name_list.append(file_path)\n",
    "\n",
    "company_filing_file_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc400238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "aws_region = boto3.Session().region_name\n",
    "\n",
    "boto3_bedrock = boto3.client(service_name=\"bedrock-runtime\", endpoint_url=f\"https://bedrock-runtime.{aws_region}.amazonaws.com\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id='amazon.titan-embed-text-v2:0',client=boto3_bedrock)\n",
    "#bedrock_embeddings = BedrockEmbeddings(model_id='cohere.embed-multilingual-v3',client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b1562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(\"This is a content of the document\")\n",
    "result[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11708cbb",
   "metadata": {},
   "source": [
    "#### Get Cloud Formation stack output variables\n",
    "\n",
    "We also need to grab some key values from the infrastructure we provisioned using CloudFormation. To do this, we will list the outputs from the stack and store this in \"outputs\" to be used later.\n",
    "\n",
    "You can ignore any \"PythonDeprecationWarning\" warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4bb772",
   "metadata": {},
   "source": [
    "### Create a index in Amazon OpenSearch Service collection\n",
    "\n",
    "The OpenSearch k-NN plugin introduces a custom data type, the knn_vector, that allows users to ingest their k-NN vectors into an OpenSearch index and perform different kinds of k-NN search. \n",
    "\n",
    "<!-- ---\n",
    "#### OpenSearch Approximate Nearest Neighbor Algorithms and Engines\n",
    "![ANN algorithm](./static/ann-algorithm.png)\n",
    "\n",
    "--- -->\n",
    "\n",
    "<!-- #### HNSW parameter tuning\n",
    "![hnsw parameter tuning](./static/hnsw-parameter-tuning.png) -->\n",
    "\n",
    "<!-- ---\n",
    "\n",
    "#### IVF parameter tuning\n",
    "![ivf parameter tuning](./static/ivf-parameter-tuning.png)\n",
    "\n",
    "#### How to select the engine and algorithms\n",
    "![opensearch ann comparison](./static/opensearch-ann-selection.png)  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b3d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        #\"index.knn.space_type\": \"cosinesimil\"\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"item_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"store\": True,\n",
    "                \"method\": {\n",
    "                    \"name\": \"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                      \"ef_construction\": 128,\n",
    "                      \"m\": 24\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"item_content\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"company_name\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9e09e",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60657cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"10k_financial\"\n",
    "\n",
    "exist=False\n",
    "try:\n",
    "    aos_client.indices.get(index=index_name)\n",
    "    exist=True\n",
    "except Exception as e:\n",
    "    exist=False\n",
    "\n",
    "if exist:\n",
    "    print(\"delete existing index before creating new one\")\n",
    "    aos_client.indices.delete(index=index_name)\n",
    "else:\n",
    "    print(\"index does not exist.\")\n",
    "    \n",
    "aos_client.indices.create(index=index_name,body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7736b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=index_name)\n",
    "# you can verify the mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b9f03",
   "metadata": {},
   "source": [
    "###  Load the raw data into the Index\n",
    "Next, let's load the financial billing data into the index you've just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aeacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "import pandas\n",
    "\n",
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "\n",
    "class PandasDataFrameLoader(BaseLoader):\n",
    "    \n",
    "    def __init__(self,dataframe:pandas.DataFrame):\n",
    "        self.dataframe=dataframe\n",
    "        \n",
    "    def load(self) -> List[Document]:\n",
    "        docs = []\n",
    "        items=[\"item_1\",\"item_1A\",\"item_1B\",\"item_2\",\"item_3\",\"item_4\",\"item_5\",\"item_6\",\"item_7\",\"item_7A\",\"item_8\",\"item_9\",\"item_9A\", \"item_9B\", \"item_10\", \"item_11\", \"item_12\", \"item_13\", \"item_14\", \"item_15\"]\n",
    "        \n",
    "        for index, row in self.dataframe.iterrows():\n",
    "            metadata={}\n",
    "            # you can use as many metadata possible\n",
    "            metadata[\"cik\"]=row['cik']\n",
    "            metadata[\"company_name\"]=row['company']\n",
    "            metadata[\"filing_date\"]=row['filing_date']\n",
    "            for item in items:\n",
    "                content=row[item]\n",
    "                metadata['item'] = item\n",
    "                doc = Document(page_content=content,metadata=metadata)\n",
    "                #print(doc.metadata)\n",
    "                docs.append(doc)\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86dcbea",
   "metadata": {},
   "source": [
    "Use Bedrock embedding convert item content into vector and use OpenSearch bulk ingest to store data into OpenSearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41d3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from opensearchpy import helpers\n",
    "\n",
    "def ingest_downloaded_10k_into_opensearch(file_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    item_contents=[]\n",
    "    company_name=splitted_documents[0].metadata['company_name']\n",
    "    for doc in splitted_documents:\n",
    "        item_contents.append(doc.page_content)\n",
    "    \n",
    "    print(\"\\ncompany:\" + company_name + \", item count:\" + str(len(item_contents)))\n",
    "    start = time.time()\n",
    "    embedding_results = bedrock_embeddings.embed_documents(item_contents)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    #print(f\"total time elapsed for Bedrock embedding: {elapsed:.2f} seconds\")\n",
    "        \n",
    "    data = []\n",
    "    i=0\n",
    "    for content in item_contents:\n",
    "        data.append({\"_index\": index_name,  \"company_name\": company_name, \"item_content\":content, \"item_vector\":embedding_results[i]})\n",
    "        i = i+1\n",
    "    aos_response= helpers.bulk(aos_client, data)\n",
    "    print(f\"Bulk-inserted {aos_response[0]} items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e516be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data in to OpenSearch Serverless collection. Note: This would take some time to complete\n",
    "for file in company_filing_file_name_list:\n",
    "    ingest_downloaded_10k_into_opensearch(file)\n",
    "    print(\"Ingested :\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee126626",
   "metadata": {},
   "source": [
    "To validate the load, you can query the number of documents number in the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ad155",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5106147",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res['hits']['hits'][1]['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you can use the same queries where the full text search weren't return relevant results.\n",
    "query_text=\"What Microsoft's research and development organization is responsible for?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3e613",
   "metadata": {},
   "source": [
    "Run the query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ed55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1070e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text=\"What is Microsoft's main revenue?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e3fd3",
   "metadata": {},
   "source": [
    "Run the query and check the search result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7265807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bedrock_embeddings.embed_query(query_text)\n",
    "search_vector = result\n",
    "\n",
    "query={\n",
    "    \"size\": 10,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"item_vector\":{\n",
    "                \"vector\":search_vector,\n",
    "                \"k\":10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=index_name, body=query)\n",
    "query_result=[]\n",
    "for hit in res['hits']['hits']:\n",
    "    row=[hit['_id'],hit['_score'],hit['_source']['company_name'],hit['_source']['item_content']]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result,columns=[\"_id\",\"_score\",\"company_name\",\"item_content\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438d6347",
   "metadata": {},
   "source": [
    "### 2.3 Retrieval Augmented Generation(RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297cb878",
   "metadata": {},
   "source": [
    "You can leverage the Large Language Models to generate answers rather than provinding the document back to the user. By provinding these retrieved documents as context to generate answers, we minimizes the halucination. This method is called Retrieval Augmented Generation or simply RAG. In RAG, external data can be sourced from various data sources, such as document repositories, databases, or APIs. The first step is to convert the documents and the user query into a format that enables comparison and allows for performing relevancy search. To achieve comparability for relevancy search, a document collection (knowledge library) and the user-submitted query are transformed into numerical representations using embedding language models. These embeddings are essentially numerical representations of concepts in text.\n",
    "\n",
    "Next, based on the embedding of the user query, relevant text is identified in the document collection through similarity search in the embedding space. The prompt provided by the user is then combined with the searched relevant text and added to the context. This updated prompt, which includes relevant external data along with the original prompt, is sent to the LLM (Language Model) for processing. As a result, the model output becomes relevant and accurate due to the context containing the relevant external data.\n",
    "\n",
    "The major components of RAG, including embedding, vector databases, augmentation, and generation:\n",
    "\n",
    "\n",
    "- **Embedding**: Purpose: Embeddings transform text data into numerical vectors in a high-dimensional space. These vectors represent the semantic meaning of the text. Process: The embedding process typically uses pre-trained models (like BERT or a variant) to convert both the input queries and the documents in the database into dense vectors. Role in RAG: Embeddings are crucial for the retrieval component as they allow the model to compute the similarity between the query and the documents in the database efficiently.\n",
    "- **Vector Database**: Function: A vector database stores the embeddings of a large collection of documents or passages. Construction: It is created by processing a vast corpus (like Wikipedia or other specialized datasets) through an embedding model. Usage in RAG: When a query comes in, the model searches this database to find the documents whose embeddings are most similar to the embedding of the query.\n",
    "- **Retrieval (Augmentation)**: Mechanism: The retrieval part of RAG functions by taking the input query, converting it into a vector using embeddings, and then searching the vector database to retrieve relevant documents. Result: It augments the original query with additional context by selecting documents or passages that are semantically related to the query. This augmented information is essential for generating more informed responses.\n",
    "- **Generation**: Integration with a Language Model: The generative component, often a large language model like Amazon Titan Text, receives both the original query and the retrieved documents. Response Generation: It synthesizes information from these inputs to produce a coherent and contextually appropriate response. \n",
    "- **Training and Fine-Tuning**: This component is generally pre-trained on vast amounts of text and may be further fine-tuned to optimize its performance for specific tasks or datasets.\n",
    "- **End-to-End Training (Optional)**: Joint Optimization: In RAG, both retrieval and generation components can be fine-tuned together, allowing the system to optimize the selection of documents and the generation of responses simultaneously. Feedback Loop: The model learns not only to generate relevant responses but also to retrieve the most useful documents for any given query.\n",
    "\n",
    "---\n",
    "### Architecture\n",
    "\n",
    "![RAG](./static/RAG_Architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_index_name=\"10k_financial_embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516a932",
   "metadata": {},
   "outputs": [],
   "source": [
    "exist=False\n",
    "try:\n",
    "    aos_client.indices.get(index=langchain_index_name)\n",
    "    exist=True\n",
    "except Exception as e:\n",
    "    exist=False\n",
    "\n",
    "if exist:\n",
    "    print(\"delete existing index before creating new one\")\n",
    "    aos_client.indices.delete(index=langchain_index_name)\n",
    "else:\n",
    "    print(\"index does not exist.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "from typing import Callable\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "os_domain_ep = 'https://'+aoss_host\n",
    "\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key, aws_region, service, session_token=credentials.token)\n",
    "\n",
    "\n",
    "def ingest_10k_into_opensearch_with_langchain(file_name):\n",
    "    df = pd.DataFrame([pd.read_json(file_name,typ='series')])\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 8000, chunk_overlap = 200)\n",
    "    pd_loader = PandasDataFrameLoader(df)\n",
    "    documents = pd_loader.load()\n",
    "    splitted_documents = text_splitter.split_documents(documents)\n",
    "    \n",
    "    OpenSearchVectorSearch.from_documents(\n",
    "                index_name = langchain_index_name,\n",
    "                documents=splitted_documents,\n",
    "                embedding=bedrock_embeddings,\n",
    "                opensearch_url=os_domain_ep,\n",
    "                http_auth=awsauth,\n",
    "                timeout=600,\n",
    "                use_ssl=True,\n",
    "                verify_certs=True,\n",
    "                connection_class=RequestsHttpConnection,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a18ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## In this step, you're indexing the selected companies 10K files in to Amazon OpenSearch Serverless with LangChain\n",
    "## This will take a while to load all the chunks\n",
    "\n",
    "for file in company_filing_file_name_list:\n",
    "    ingest_10k_into_opensearch_with_langchain(file)\n",
    "    print(\"Ingested :\" + file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c77644",
   "metadata": {},
   "outputs": [],
   "source": [
    "aos_client.indices.get(index=langchain_index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb70ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimiliarOpenSearchVectorSearch(OpenSearchVectorSearch):\n",
    "    \n",
    "    def relevance_score(self, distance: float) -> float:\n",
    "        return distance\n",
    "    \n",
    "    def _select_relevance_score_fn(self) -> Callable[[float], float]:\n",
    "        return self.relevance_score\n",
    "\n",
    "\n",
    "open_search_vector_store = SimiliarOpenSearchVectorSearch(\n",
    "                                    index_name=langchain_index_name,\n",
    "                                    embedding_function=bedrock_embeddings,\n",
    "                                    opensearch_url=os_domain_ep,\n",
    "                                    http_auth=awsauth,\n",
    "                                    timeout=600,\n",
    "                                    use_ssl=True,\n",
    "                                    verify_certs=True,\n",
    "                                    connection_class=RequestsHttpConnection,\n",
    "                                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0981fa91",
   "metadata": {},
   "source": [
    "Initialize Bedrock LLM model with Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws import BedrockLLM, ChatBedrock\n",
    "\n",
    "#bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-haiku-20240307-v1:0\", client=boto3_bedrock)\n",
    "bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=boto3_bedrock)\n",
    "#bedrock_llm = ChatBedrock(model_id=\"anthropic.claude-3-opus-20240229-v1:0\", client=boto3_bedrock)\n",
    "\n",
    "bedrock_llm.model_kwargs = {\"temperature\":0.001,\"top_k\":300,\"top_p\":1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a212b804",
   "metadata": {},
   "source": [
    "#### Note: This session's prompt is desinged for Claude 3. Output result may be different if use other LLMs, for example guardrails impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ec073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "import langchain\n",
    "\n",
    "bedrock_retriever = open_search_vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\n",
    "        'k': 5,\n",
    "        'score_threshold': 0.005\n",
    "    }\n",
    ")\n",
    "rag_qa = RetrievalQA.from_chain_type(\n",
    "    llm=bedrock_llm,\n",
    "    retriever=bedrock_retriever,\n",
    "    chain_type=\"stuff\" #stuff, refine, map_reduce, and map_rerank\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cd703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What Microsoft's research and development organization is responsible for?\"\n",
    "\n",
    "langchain.debug=True\n",
    "result = rag_qa({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result:\" + result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d01915",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=\"What is Microsoft main revenue?\"\n",
    "\n",
    "langchain.debug=False\n",
    "result = rag_qa({\"query\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb75d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result:\" + result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40648cdd",
   "metadata": {},
   "source": [
    "## Part 3: AI agent powered search\n",
    "\n",
    "![standard rag limitation](./static/rag-limitation.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524ec42",
   "metadata": {},
   "source": [
    "![advanced rag ](./static/advanced-rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a90985",
   "metadata": {},
   "source": [
    "### What is an AI agent ?\n",
    "An agentic employs a chain-of-thought reasoning process, where the LLM is prompted to think gradually through a question, interleaving its reasoning with the ability to use external tools such as search engines and APIs. This allows the LLM to retrieve relevant information that can help answer partial aspects of the question, ultimately leading to a more comprehensive and accurate final response. This approach is inspired by the \"Reason and Act\" (ReAct) design introduced in the paper [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629)  which aims to synergize the reasoning capabilities of language models with the ability to interact with external resources and take actions. By combining these two facets, an agentic LLM assistant can provide more informed and well-rounded answers to complex user queries.\n",
    "\n",
    "![agent components](./static/agent-components.png)\n",
    "\n",
    "### Why build an AI agent?\n",
    "In today's digital landscape, enterprises are inundated with a vast array of data sources, ranging from traditional PDF documents to complex SQL and NoSQL databases, and everything in between. While this wealth of information holds immense potential for gaining valuable insights and driving operational efficiency, the sheer volume and diversity of data can often pose significant challenges in terms of accessibility and utilization.\n",
    "\n",
    "This is where the power of agentic LLM assistants comes into play. By leveraging progress in LLM design patterns such as Reason and Act (ReAct) and other traditional or novel design patterns, these intelligent assistants are capable of integrating with an enterprise's diverse data sources. Through the development of specialized tools tailored to each data source and the ability of LLM agents to identify the right tool for a given question, agentic LLM assistants can simplify how you navigate and extract relevant information, regardless of its origin or structure.\n",
    "\n",
    "This enables a rich, multi-source conversation that promises to unlock the full potential of the entreprise data, enabling data-driven decision-making, enhancing operational efficiency, and ultimately driving productivity and growth.\n",
    "\n",
    "![agent powered search advantage](./static/agent-powered-search-advantage.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a928610e",
   "metadata": {},
   "source": [
    "### AI Agent powered search reference architecture\n",
    "\n",
    "![AI Agent powered search reference architecture](./static/reference-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63eff43",
   "metadata": {},
   "source": [
    "\n",
    "### Lab Architecture\n",
    "\n",
    "For demo purpose, we use SageMaker notebook run the code, the following is the overall architecture of this lab:\n",
    "\n",
    "![AI Agent powered search architecture](./static/architecture.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc1107",
   "metadata": {},
   "source": [
    "\n",
    "### Data Flow\n",
    "\n",
    "The user submit query, first AI agent will judge if the query is financial statements related. If so, AI agent will use vector search to get similiar financial statements for this company from OpenSearch. If there is no financial statements for this company, AI agent will download the data from internet by calling SEC API, ingest the data into OpenSearch and do the search again. If there is related financial statements, AI agent will see if the query is stock price related question. If so, AI agent will query Redshift database to get company's stock price data. LLM will generate the response with all collected data. Overall data flow is like following:\n",
    "\n",
    "![AI Agent powered search data flow](./static/ai-agent-search-data-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac42c010",
   "metadata": {},
   "source": [
    "### 3.1 Prepare other tools used by AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bcf6e3",
   "metadata": {},
   "source": [
    "#### 3.1.1 Ingest and query structured data in Redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f3c50d",
   "metadata": {},
   "source": [
    "Get Redshift Serverless username, password and endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms = boto3.client('secretsmanager')\n",
    "\n",
    "redshift_serverless_credentials = json.loads(kms.get_secret_value(SecretId=outputs['RedshiftServerlessSecret'])['SecretString'])\n",
    "redshift_serverless_username=redshift_serverless_credentials['username']\n",
    "redshift_serverless_password=redshift_serverless_credentials['password']\n",
    "redshift_serverless_endpoint =  outputs['RedshiftServerlessEndpoint']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6c619",
   "metadata": {},
   "source": [
    "Create `stock_symbol` table and populate the table from S3. We will use this table to query company stock ticker by company name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "from sqlalchemy.engine.url import URL\n",
    "from sqlalchemy.orm import Session\n",
    "%reload_ext sql\n",
    "%config SqlMagic.displaylimit = 25\n",
    "\n",
    "connect_to_db = URL.create(\n",
    "drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "host=redshift_serverless_endpoint, \n",
    "port=5439,\n",
    "database='dev',\n",
    "username=redshift_serverless_username,\n",
    "password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "%sql $connect_to_db\n",
    "%sql select current_user, version();\n",
    "\n",
    "%sql CREATE TABLE IF NOT EXISTS public.stock_symbol (stock_symbol text PRIMARY KEY, company_name text NOT NULL);\n",
    "\n",
    "stock_price_bucket = outputs[\"s3BucketStock\"]\n",
    "s3_location = f's3://{stock_price_bucket}/stock-price/'\n",
    "print(s3_location)\n",
    "!aws s3 sync ./stock-price/ $s3_location\n",
    "\n",
    "stock_symbol_s3_location = f's3://{stock_price_bucket}/stock-price/stock_symbol.csv'\n",
    "quoted_stock_symbol_s3_location = \"'\" + stock_symbol_s3_location + \"'\"\n",
    "\n",
    "%sql COPY STOCK_SYMBOL FROM $quoted_stock_symbol_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "\n",
    "\n",
    "url = URL.create(\n",
    "    drivername='redshift+redshift_connector', # indicate redshift_connector driver and dialect will be used\n",
    "    host=redshift_serverless_endpoint, \n",
    "    port=5439,\n",
    "    database='dev',\n",
    "    username=redshift_serverless_username,\n",
    "    password=redshift_serverless_password\n",
    ")\n",
    "\n",
    "engine = sa.create_engine(url)\n",
    "redshift_connection = engine.connect()\n",
    "    \n",
    "def query_stock_ticker(company_name):\n",
    "    strSQL = \"SELECT stock_symbol FROM stock_symbol WHERE lower(company_name) ILIKE '%\" + company_name + \"%'\"\n",
    "    stock_ticker=''\n",
    "    try:\n",
    "        result = redshift_connection.execute(strSQL)\n",
    "        df = pd.DataFrame(result)\n",
    "        stock_ticker=df['stock_symbol'][0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return stock_ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34411033",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stock_ticker(\"Amazon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5982d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql CREATE TABLE IF NOT EXISTS public.stock_price (stock_date DATE, stock_symbol text, open_price DECIMAL, high_price DECIMAL, low_price DECIMAL, close_price DECIMAL, adjusted_close_price DECIMAL, volume DECIMAL);\n",
    "\n",
    "msft_s3_location = f's3://{stock_price_bucket}/stock-price/MSFT.csv'\n",
    "quoted_msft_s3_location = \"'\" + msft_s3_location + \"'\"\n",
    "print(quoted_msft_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "crm_s3_location = f's3://{stock_price_bucket}/stock-price/CRM.csv'\n",
    "quoted_crm_s3_location = \"'\" + crm_s3_location + \"'\"\n",
    "print(quoted_crm_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "orcl_s3_location = f's3://{stock_price_bucket}/stock-price/ORCL.csv'\n",
    "quoted_orcl_s3_location = \"'\" + orcl_s3_location + \"'\"\n",
    "print(quoted_orcl_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "snow_s3_location = f's3://{stock_price_bucket}/stock-price/SNOW.csv'\n",
    "quoted_snow_s3_location = \"'\" + snow_s3_location + \"'\"\n",
    "print(quoted_snow_s3_location)\n",
    "print(\"---------\")\n",
    "\n",
    "%sql COPY STOCK_PRICE FROM $quoted_msft_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_crm_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_orcl_s3_location iam_role default IGNOREHEADER 1 CSV;\n",
    "%sql COPY STOCK_PRICE FROM $quoted_snow_s3_location iam_role default IGNOREHEADER 1 CSV;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80c21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from public.stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84643882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_stock_price(stock_ticker):\n",
    "    strSQL = \"SELECT stock_date, stock_symbol, open_price, high_price, low_price, close_price FROM public.stock_price WHERE stock_symbol ='\" + stock_ticker + \"' limit 100\"\n",
    "    try:\n",
    "        result = redshift_connection.execute(strSQL)\n",
    "        stock_price = pd.DataFrame(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return stock_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad4d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_stock_price('MSFT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd10bb",
   "metadata": {},
   "source": [
    "#### 3.1.2 Download 10-K filing from SEC\n",
    "---\n",
    "https://sec-api.io\n",
    "\n",
    "Create a new account and get free API key.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sec-api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78970fd",
   "metadata": {},
   "source": [
    "##### Replace your sec-api key in the following line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624456f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_api_key=\"{security_api_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f944edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_api import ExtractorApi, QueryApi\n",
    "import json\n",
    "import os\n",
    "\n",
    "def get_filings(ticker):\n",
    "    global sec_api_key\n",
    "\n",
    "    # Finding Recent Filings with QueryAPI\n",
    "    queryApi = QueryApi(api_key=sec_api_key)\n",
    "    query = {\n",
    "      \"query\": f\"ticker:{ticker} AND formType:\\\"10-K\\\"\",\n",
    "      \"from\": \"0\",\n",
    "      \"size\": \"1\",\n",
    "      \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
    "    }\n",
    "    response = queryApi.get_filings(query)\n",
    "\n",
    "    # Getting 10-K URL\n",
    "    filing_url = response[\"filings\"][0][\"linkToFilingDetails\"]\n",
    "    filing_type=response['filings'][0]['formType']\n",
    "    cik=response['filings'][0]['cik']\n",
    "    company=response['filings'][0]['companyName']\n",
    "    filing_date=response['filings'][0]['filedAt']\n",
    "    period_of_report=response['filings'][0]['periodOfReport']\n",
    "    filing_html_index=response['filings'][0]['linkToFilingDetails']\n",
    "    complete_text_filing_link=response['filings'][0]['linkToTxt']\n",
    "\n",
    "    # Extracting Text with ExtractorAPI\n",
    "    extractorApi = ExtractorApi(api_key=sec_api_key)\n",
    "    \n",
    "    one_text = extractorApi.get_section(filing_url, \"1\", \"text\")       #Section 1 - Business\n",
    "    onea_text = extractorApi.get_section(filing_url, \"1A\", \"text\")     # Section 1A - Risk Factors\n",
    "    oneb_text = extractorApi.get_section(filing_url, \"1B\", \"text\")     # Section 1B - Unresolved Staff Comments\n",
    "    two_text = extractorApi.get_section(filing_url, \"2\", \"text\")       # Section 2 - Properties\n",
    "    three_text = extractorApi.get_section(filing_url, \"3\", \"text\")     # Section 3 - Legal Proceedings\n",
    "    four_text = extractorApi.get_section(filing_url, \"4\", \"text\")      # Section 4 - Mine Safety Disclosures\n",
    "    five_text = extractorApi.get_section(filing_url, \"5\", \"text\")      # Section 5 - Market for Registrant’s Common Equity, Related Stockholder Matters and Issuer Purchases of Equity Securities\n",
    "    six_text = extractorApi.get_section(filing_url, \"6\", \"text\")       # Section 6 - Selected Financial Data (prior to February 2021)\n",
    "    seven_text = extractorApi.get_section(filing_url, \"7\", \"text\")     # Section 7 - Management’s Discussion and Analysis of Financial Condition and Results of Operations\n",
    "    sevena_text = extractorApi.get_section(filing_url, \"7A\", \"text\")   # Section 7A - Quantitative and Qualitative Disclosures about Market Risk\n",
    "    eight_text = extractorApi.get_section(filing_url, \"8\", \"text\")     # Section 8 - Financial Statements and Supplementary Data\n",
    "    nine_text = extractorApi.get_section(filing_url, \"9\", \"text\")      # Section 9 - Changes in and Disagreements with Accountants on Accounting and Financial Disclosure\n",
    "    ninea_text = extractorApi.get_section(filing_url, \"9A\", \"text\")    # Section 9A - Controls and Procedures\n",
    "    nineb_text = extractorApi.get_section(filing_url, \"9B\", \"text\")    # Section 9B - Other Information\n",
    "    ten_text = extractorApi.get_section(filing_url, \"10\", \"text\")      # Section 10 - Directors, Executive Officers and Corporate Governance\n",
    "    eleven_text = extractorApi.get_section(filing_url, \"11\", \"text\")   # Section 11 - Executive Compensation\n",
    "    twelve_text = extractorApi.get_section(filing_url, \"12\", \"text\")   # Section 12 - Security Ownership of Certain Beneficial Owners and Management and Related Stockholder Matters\n",
    "    thirteen_text = extractorApi.get_section(filing_url, \"13\", \"text\") # Section 13 - Certain Relationships and Related Transactions, and Director Independence\n",
    "    fourteen_text = extractorApi.get_section(filing_url, \"14\", \"text\") # Section 14 - Principal Accountant Fees and Services\n",
    "    fifteen_text = extractorApi.get_section(filing_url, \"15\", \"text\")  # Section 15 - Exhibits and Financial Statement Schedules\n",
    "    \n",
    "    data = {}\n",
    "    data['filing_url'] = filing_url\n",
    "    data['filing_type'] = filing_type\n",
    "    data['cik'] = cik\n",
    "    data['company'] = company\n",
    "    data['filing_date'] = filing_date\n",
    "    data['period_of_report'] = period_of_report\n",
    "    data['filing_html_index'] = filing_html_index\n",
    "    data['complete_text_filing_link'] = complete_text_filing_link\n",
    "    \n",
    "    \n",
    "    data['item_1'] = one_text\n",
    "    data['item_1A'] = onea_text\n",
    "    data['item_1B'] = oneb_text\n",
    "    data['item_2'] = two_text\n",
    "    data['item_3'] = three_text\n",
    "    data['item_4'] = four_text\n",
    "    data['item_5'] = five_text\n",
    "    data['item_6'] = six_text\n",
    "    data['item_7'] = seven_text\n",
    "    data['item_7A'] = sevena_text\n",
    "    data['item_8'] = eight_text\n",
    "    data['item_9'] = nine_text\n",
    "    data['item_9A'] = ninea_text\n",
    "    data['item_9B'] = nineb_text\n",
    "    data['item_10'] = ten_text\n",
    "    data['item_11'] = eleven_text\n",
    "    data['item_12'] = twelve_text\n",
    "    data['item_13'] = thirteen_text\n",
    "    data['item_14'] = fourteen_text\n",
    "    data['item_15'] = fifteen_text\n",
    "    \n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(\"./download_filings\"):\n",
    "        os.makedirs(\"./download_filings\")\n",
    "    \n",
    "    try:\n",
    "        file_name = filing_url.split(\"/\")[-2] + \"-\" + filing_url.split(\"/\")[-1].split(\".\")[0]+\".json\"\n",
    "        download_to = \"./download_filings/\" + file_name\n",
    "        with open(download_to, \"w\") as f:\n",
    "          json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "    except Exception as e:\n",
    "        print(\"Problem with {url}\".format(url=url))\n",
    "        print(e)\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e2230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloaded_file=get_filings(\"AMZN\")\n",
    "#ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cf641d",
   "metadata": {},
   "source": [
    "### 3.2 Create AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25aed0",
   "metadata": {},
   "source": [
    "#### Define methods used by AI agent\n",
    "\n",
    "One popular architecture for building agents is ReAct. ReAct combines reasoning and acting in an iterative process - in fact the name \"ReAct\" stands for \"Reason\" and \"Act\".\n",
    "\n",
    "The general flow looks like this:\n",
    "\n",
    "- The model will \"think\" about what step to take in response to an input and any previous observations.\n",
    "- The model will then choose an action from available tools (or choose to respond to the user).\n",
    "- The model will generate arguments to that tool.\n",
    "- The agent runtime (executor) will parse out the chosen tool and call it with the generated arguments.\n",
    "- The executor will return the results of the tool call back to the model as an observation.\n",
    "- This process repeats until the agent chooses to respond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85bf6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import time\n",
    "\n",
    "def is_financial_statement_related_query(human_input):\n",
    "    #template = \"\"\"You are a helpful assistant to judge if the human input is stock related question.\n",
    "    #If it is stock related, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\"\"\"\n",
    "    template = \"\"\"You are a helpful assistant to judge if the human input is trying to analyze company financial statement.\n",
    "    If the human input is financial statement related question, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\n",
    "    \"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return stock_related\n",
    "\n",
    "def is_stock_related_query(human_input):\n",
    "    #template = \"\"\"You are a helpful assistant to judge if the human input is stock related question.\n",
    "    #If it is stock related, answer \\\"yes\\\". Otherwise answer \\\"no\\\".\"\"\"\n",
    "    template = \"\"\"\n",
    "    You are a helpful assistant to judge if the human input is stock related question. \n",
    "    If the human innput is stock related question, return \"yes\".Otherwise return \"no\".\n",
    "    \"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "    stock_related = llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return stock_related\n",
    "\n",
    "def get_company_name(human_input):\n",
    "    template = \"\"\"You are a helpful assistant who extract company name from the human input.Please only output the company\"\"\"\n",
    "    human_template = \"{text}\"\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", template),\n",
    "        (\"human\", human_template),\n",
    "    ])\n",
    "\n",
    "    llm_chain = LLMChain(\n",
    "        llm=bedrock_llm,\n",
    "        prompt=chat_prompt\n",
    "    )\n",
    "\n",
    "    company_name=llm_chain({\"text\":human_input})['text'].strip()\n",
    "    return company_name\n",
    "    \n",
    "def semantic_search_and_check(human_input, k=10,with_post_filter=True):\n",
    "\n",
    "    company_name=get_company_name(human_input)\n",
    "    \n",
    "    search_vector = bedrock_embeddings.embed_query(human_input)\n",
    "\n",
    "    no_post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    post_filter_search_query={\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"item_vector\":{\n",
    "                    \"vector\":search_vector,\n",
    "                    \"k\":k\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"post_filter\": {\n",
    "           \"match\": { \n",
    "               \"company_name\":company_name\n",
    "           }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    search_query=no_post_filter_search_query\n",
    "    if with_post_filter:\n",
    "        search_query=post_filter_search_query\n",
    "    \n",
    "    res = aos_client.search(index=index_name, \n",
    "                       body=search_query,\n",
    "                       stored_fields=[\"company_name\",\"item_category\",\"item_content\"])\n",
    "    \n",
    "    query_result=[]\n",
    "    for hit in res['hits']['hits']:\n",
    "        hit_company=hit['fields']['company_name'][0]\n",
    "        print(\"\\nsemantic search hit company: \" + hit_company)\n",
    "        row=[hit['fields']['company_name'][0], hit['fields']['item_content'][0]]\n",
    "        query_result.append(row)\n",
    "\n",
    "    query_result_df = pd.DataFrame(data=query_result,columns=[\"company_name\",\"company_financial_statements\"])\n",
    "    return query_result_df\n",
    "\n",
    "def search_for_similiar_content_in_10k_filing(human_input):\n",
    "    company_statements = semantic_search_and_check(human_input)\n",
    "    return company_statements\n",
    "\n",
    "def search_financial_statements_for_company(company_financial_statements_query):\n",
    "    company_statements = semantic_search_and_check(company_financial_statements_query)\n",
    "    return company_statements\n",
    "\n",
    "def get_stock_ticker(human_input):\n",
    "    company_name=get_company_name(human_input)\n",
    "    company_ticker = query_stock_ticker(company_name)\n",
    "    return company_ticker\n",
    "\n",
    "def get_stock_price(stock_ticker):\n",
    "    stock_price = query_stock_price(stock_ticker)\n",
    "    return stock_price\n",
    "\n",
    "def download_10k_filing_from_sec_and_ingest_into_opensearch(stock_ticker):\n",
    "    result = \"download failed.\"\n",
    "    try:\n",
    "        #downloaded_file=get_filings(stock_ticker)\n",
    "        downloaded_file=\"000101872424000008-amzn-20231231.json\"\n",
    "        ingest_downloaded_10k_into_opensearch(\"./download_filings/\" + downloaded_file)\n",
    "        time.sleep(60) #wait the data can be searchable\n",
    "        result=\"download succeeded.\"\n",
    "    except Exception as e:\n",
    "        result = \"download failed.\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e4087",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "Uncomment the line `downloaded_file=get_filings(company_stock_ticker)` if you have sec-api security key so that you can download 10-K from SEC. In the meanwhile, comment the line 'downloaded_file=\"000101872424000008-amzn-20231231.json\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06f721",
   "metadata": {},
   "source": [
    "#### Define tools for financial statements analysis AI agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed114181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "annual_report_tools=[\n",
    "    Tool(\n",
    "        name=\"is_financial_statement_related_query\",\n",
    "        func=is_financial_statement_related_query,\n",
    "        description=\"\"\"\n",
    "        Use this tool when you need to know whether user input query is financial statement analysis related query. Human orginal query is the input to this tool. This tool output is whether human input is financial statement analysis related or not. \n",
    "        If the query is not finance statement related, please answer \\\"I am finiancial statement ansysis assitant. I can not answer question which is not finance related.\\\" and terminate the dialog.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"search_financial_statements_for_company\",\n",
    "        func=search_financial_statements_for_company,\n",
    "        description=\"\"\"\n",
    "        Use this tool to get financial statement of the company. This tool output is company financial statements.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_ticker\",\n",
    "        func=get_stock_ticker,\n",
    "        description=\"Use this tool when you need to get the company stock ticker. Human orginal query is the input to this tool. This tool will output company stock ticker.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"download_10k_filing_from_sec_and_ingest_into_opensearch\",\n",
    "        func=download_10k_filing_from_sec_and_ingest_into_opensearch,\n",
    "        description=\"\"\"\n",
    "        Use this tool to download company financial statements from internet. Company stock ticker is the input to this tool. The tool output is download succeed or not.\n",
    "        Use this tool if and only if \"search_financial_statements_for_company\" output result is empty. After downloading financial statements, you must use \"search_financial_statements_for_company\" tool to search financial statements again.\n",
    "        \"\"\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"is_stock_related_query\",\n",
    "        func=is_stock_related_query,\n",
    "        description=\"Use this tool when you need to know whether user input query is stock related query. Human orginal query is the input to this tool. This tool output is whether human input is stock related or not.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"get_stock_price\",\n",
    "        func=get_stock_price,\n",
    "        description=\"\"\"\n",
    "        Use this tool to get company stock price data. Company stock ticker is the input to this tool. This tool will output company historic stock price. The output includes 'stock_date', 'stock_ticker', 'open_price', 'high_price', 'low_price', 'close_price' of the company in the latest 100 days.\n",
    "        This tool is mandatory to use if the input query is both finance statement related and stock related. If the output of \"get_stock_price\" is empty, please answer \\\"I cannot provide stock analysis without stock price information.\\\" and terminate the dialog.\n",
    "        \"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a089d5",
   "metadata": {},
   "source": [
    "#### Define prompt for financial statements analysis AI agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfe0d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "system_message = f\"\"\"\n",
    "You are finiancial analyst assistant and you will analyze company financial statements and stock data. \n",
    "Leverage the <conversation_history> to avoid duplicating work when answering questions.\n",
    "\n",
    "Available tools:\n",
    "<tools>\n",
    "{{tools}}\n",
    "</tools>\n",
    "\n",
    "\n",
    "To answer, first review the <conversation_history>. If insufficient use tool(s) with the following format:\n",
    "<thinking>Think about which tool(s) to use and why. \"get_stock_price\" tool is mandatory to use if the input query is both finance statements related and stock related.</thinking>\n",
    "<tool>tool_name</tool>\n",
    "<tool_input>input</tool_input>\n",
    "<observation>response</observation>\n",
    "\n",
    "When you are done, provide a final answer in markdown within <final_answer></final_answer>.\n",
    "If <user_input> is stock related and the output of \"get_stock_price\" tool is empty, respond directly within <final_answer> with the exact content \\\"I cannot provide stock analysis without stock price information.\\\".\n",
    "Otherwise, use the following format to organize your <final_answer>:\n",
    "\n",
    "Summary:\n",
    "...\n",
    "\n",
    "Support points:\n",
    "Support point 1: ...\n",
    "Support point 2: ...\n",
    "Support point 3: ...\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "<conversation_history>\n",
    "{chat_history}\n",
    "</conversation_history>\n",
    "\n",
    "User input message:\n",
    "<user_input>\n",
    "{input}\n",
    "</user_input>\n",
    "\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "\n",
    "# Construct the prompt from the messages\n",
    "messages = [\n",
    "    (\"system\", system_message),\n",
    "    (\"human\", user_message),\n",
    "]\n",
    "\n",
    "financial_statements_analysis_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafdd5e9",
   "metadata": {},
   "source": [
    "#### Define memory for financial statements analysis AI agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56da29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import DynamoDBChatMessageHistory\n",
    "from uuid import uuid4\n",
    "\n",
    "dynamo = boto3.client('dynamodb')\n",
    "\n",
    "history_table_name = 'conversation-history-memory'\n",
    "\n",
    "try:\n",
    "    response = dynamo.describe_table(TableName=history_table_name)\n",
    "    print(\"The table \"+history_table_name+\" exists\")\n",
    "except dynamo.exceptions.ResourceNotFoundException:\n",
    "    print(\"The table \"+history_table_name+\" does not exist\")\n",
    "    \n",
    "    dynamo.create_table(\n",
    "    TableName=history_table_name,\n",
    "    AttributeDefinitions=[\n",
    "        {\n",
    "            'AttributeName': 'SessionId',\n",
    "            'AttributeType': 'S',\n",
    "        }\n",
    "    ],\n",
    "    KeySchema=[\n",
    "        {\n",
    "            'AttributeName': 'SessionId',\n",
    "            'KeyType': 'HASH',\n",
    "        }\n",
    "    ],\n",
    "    ProvisionedThroughput={\n",
    "        'ReadCapacityUnits': 5,\n",
    "        'WriteCapacityUnits': 5,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    response = dynamo.describe_table(TableName=history_table_name) \n",
    "    \n",
    "    while response[\"Table\"][\"TableStatus\"] == 'CREATING':\n",
    "        time.sleep(1)\n",
    "        print('.', end='')\n",
    "        response = dynamo.describe_table(TableName=history_table_name) \n",
    "\n",
    "    print(\"\\ndynamo DB Table, '\"+response['Table']['TableName']+\"' is created\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10032dc",
   "metadata": {},
   "source": [
    "#### Create financial statements analysis AI agent AI using defined Memory,  LLM, tools and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d4a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_xml_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "\n",
    "def create_new_memory_with_session(session_id):\n",
    "    chat_memory = DynamoDBChatMessageHistory(table_name=history_table_name,session_id=session_id)    \n",
    "    return chat_memory\n",
    "\n",
    "def get_agentic_chatbot_conversation_chain(session_id, verbose=True):\n",
    "    chat_memory=create_new_memory_with_session(session_id)\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        # Change the human_prefix from Human to something else\n",
    "        # to not conflict with Human keyword in Anthropic Claude model.\n",
    "        human_prefix=\"Hu\",\n",
    "        chat_memory=chat_memory,\n",
    "        return_messages=False)\n",
    "\n",
    "    agent = create_xml_agent(\n",
    "        bedrock_llm,\n",
    "        annual_report_tools,\n",
    "        financial_statements_analysis_prompt,\n",
    "        stop_sequence=[\"</tool_input>\", \"</final_answer>\"]\n",
    "    )\n",
    "\n",
    "    agent_chain = AgentExecutor(\n",
    "        agent=agent,\n",
    "        tools=annual_report_tools,\n",
    "        return_intermediate_steps=False,\n",
    "        verbose=True,\n",
    "        memory=memory,\n",
    "        handle_parsing_errors=\"Check your output and make sure it conforms!\"\n",
    "    )\n",
    "    return agent_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d9655",
   "metadata": {},
   "source": [
    "### 3.3 Use financial statements analysis AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b2dac4",
   "metadata": {},
   "source": [
    "#### Example 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f2a6f",
   "metadata": {},
   "source": [
    "Query is \"Per Microsoft financial statements, what Microsoft's research and development organization is responsible for?\". \n",
    "\n",
    "The data flow is like following:\n",
    "\n",
    "![example 1](./static/example-1-data-flow.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "\n",
    "langchain.debug=False\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": \"Per Microsoft financial statements, what Microsoft's research and development organization is responsible for?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df626aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a55cb9b",
   "metadata": {},
   "source": [
    "#### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6998c94c",
   "metadata": {},
   "source": [
    "Query is \"Is Microsoft a good investment choice right now?\". \n",
    "\n",
    "The data flow is like following:\n",
    "\n",
    "![example 2](./static/example-2-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": \"Is Microsoft a good investment choice right now?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb04015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bcdc1",
   "metadata": {},
   "source": [
    "#### Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b476fd42",
   "metadata": {},
   "source": [
    "Query is \"Compare Oracle and Microsoft company financial statements\"\n",
    "\n",
    "The data flow is like following:\n",
    "\n",
    "![example 3](./static/example-3-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74991f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": \"Compare Oracle and Microsoft company financial statements\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83fdd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2455e8ee",
   "metadata": {},
   "source": [
    "#### Example 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90cbc80",
   "metadata": {},
   "source": [
    "Query is \"Is Amazon a good investment choice right now?\"\n",
    "\n",
    "The data flow is like following:\n",
    "\n",
    "![example 4](./static/example-4-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d31570",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": \"Is Amazon a good investment choice right now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78afd5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786fb3b",
   "metadata": {},
   "source": [
    "#### Example 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd52d96",
   "metadata": {},
   "source": [
    "Query is \"What is OpenSearch?\"\n",
    "\n",
    "The data flow is like following:\n",
    "\n",
    "![example 5](./static/example-5-data-flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bddbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = str(uuid4())\n",
    "conversation_chain = get_agentic_chatbot_conversation_chain(session_id=session_id)\n",
    "response=conversation_chain.invoke({\"input\": \"What is OpenSearch?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
